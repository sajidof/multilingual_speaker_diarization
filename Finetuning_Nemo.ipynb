{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":329771,"status":"ok","timestamp":1717453450966,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"HFcCps7p_20f","outputId":"62028b80-1c26-41fa-e174-61400da1e5de"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'NeMo'...\n","remote: Enumerating objects: 161523, done.\u001b[K\n","remote: Counting objects: 100% (2731/2731), done.\u001b[K\n","remote: Compressing objects: 100% (1566/1566), done.\u001b[K\n","remote: Total 161523 (delta 1804), reused 1790 (delta 1145), pack-reused 158792\u001b[K\n","Receiving objects: 100% (161523/161523), 251.83 MiB | 12.88 MiB/s, done.\n","Resolving deltas: 100% (121220/121220), done.\n","/content/NeMo\n","\u001b[33mDEPRECATION: git+https://github.com/NVIDIA/NeMo.git@main#egg=nemo_toolkit[all] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n","\u001b[0mCollecting nemo_toolkit[all]\n","  Cloning https://github.com/NVIDIA/NeMo.git (to revision main) to /tmp/pip-install-31qns9mw/nemo-toolkit_d4ecc0b91a784f09af0f0dfe568ff640\n","  Running command git clone --filter=blob:none --quiet https://github.com/NVIDIA/NeMo.git /tmp/pip-install-31qns9mw/nemo-toolkit_d4ecc0b91a784f09af0f0dfe568ff640\n","  Resolved https://github.com/NVIDIA/NeMo.git to commit bd014d9d71a258da6c69c80df8244a9598c752f3\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting fiddle (from nemo_toolkit[all])\n","  Downloading fiddle-0.3.0-py3-none-any.whl (419 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub\u003e=0.20.3 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (0.23.2)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (0.58.1)\n","Requirement already satisfied: numpy\u003e=1.22 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (1.25.2)\n","Collecting onnx\u003e=1.7.0 (from nemo_toolkit[all])\n","  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (2.8.2)\n","Collecting ruamel.yaml (from nemo_toolkit[all])\n","  Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m668.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (1.2.2)\n","Requirement already satisfied: setuptools\u003e=65.5.1 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (67.7.2)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (2.15.2)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (1.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (2.3.0+cu121)\n","Requirement already satisfied: tqdm\u003e=4.41.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (4.66.4)\n","Collecting wget (from nemo_toolkit[all])\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (1.14.1)\n","Collecting black~=24.3 (from nemo_toolkit[all])\n","  Downloading black-24.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting click==8.0.2 (from nemo_toolkit[all])\n","  Downloading click-8.0.2-py3-none-any.whl (97 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting isort\u003c6.0.0,\u003e5.1.0 (from nemo_toolkit[all])\n","  Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting parameterized (from nemo_toolkit[all])\n","  Downloading parameterized-0.9.0-py2.py3-none-any.whl (20 kB)\n","Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (7.4.4)\n","Collecting pytest-mock (from nemo_toolkit[all])\n","  Downloading pytest_mock-3.14.0-py3-none-any.whl (9.9 kB)\n","Collecting pytest-runner (from nemo_toolkit[all])\n","  Downloading pytest_runner-6.0.1-py3-none-any.whl (7.2 kB)\n","Requirement already satisfied: sphinx in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (5.0.2)\n","Collecting sphinxcontrib-bibtex (from nemo_toolkit[all])\n","  Downloading sphinxcontrib_bibtex-2.6.2-py3-none-any.whl (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting wandb (from nemo_toolkit[all])\n","  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (2.2.1)\n","Collecting hydra-core\u003c=1.3.2,\u003e1.3 (from nemo_toolkit[all])\n","  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting omegaconf\u003c=2.3 (from nemo_toolkit[all])\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pytorch-lightning\u003e=2.2.1 (from nemo_toolkit[all])\n","  Downloading pytorch_lightning-2.2.5-py3-none-any.whl (802 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchmetrics\u003e=0.11.0 (from nemo_toolkit[all])\n","  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers\u003c=4.40.2,\u003e=4.36.0 (from nemo_toolkit[all])\n","  Downloading transformers-4.40.2-py3-none-any.whl (9.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting webdataset\u003e=0.2.86 (from nemo_toolkit[all])\n","  Downloading webdataset-0.2.86-py3-none-any.whl (70 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets (from nemo_toolkit[all])\n","  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (7.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (2.0.3)\n","Collecting sacremoses\u003e=0.0.43 (from nemo_toolkit[all])\n","  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sentencepiece\u003c1.0.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (0.1.99)\n","Collecting braceexpand (from nemo_toolkit[all])\n","  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (0.6.2)\n","Collecting einops (from nemo_toolkit[all])\n","  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting g2p-en (from nemo_toolkit[all])\n","  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (7.7.1)\n","Collecting jiwer (from nemo_toolkit[all])\n","  Downloading jiwer-3.0.4-py3-none-any.whl (21 kB)\n","Collecting kaldi-python-io (from nemo_toolkit[all])\n","  Downloading kaldi-python-io-1.2.2.tar.gz (8.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting kaldiio (from nemo_toolkit[all])\n","  Downloading kaldiio-2.18.0-py3-none-any.whl (28 kB)\n","Collecting lhotse\u003e=1.22.0 (from nemo_toolkit[all])\n","  Downloading lhotse-1.23.0-py3-none-any.whl (772 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.4/772.4 kB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: librosa\u003e=0.10.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (0.10.2.post1)\n","Collecting marshmallow (from nemo_toolkit[all])\n","  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (3.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (24.0)\n","Collecting pyannote.core (from nemo_toolkit[all])\n","  Downloading pyannote.core-5.0.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyannote.metrics (from nemo_toolkit[all])\n","  Downloading pyannote.metrics-3.2.1-py3-none-any.whl (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.4/51.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydub (from nemo_toolkit[all])\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting pyloudnorm (from nemo_toolkit[all])\n","  Downloading pyloudnorm-0.1.1-py3-none-any.whl (9.6 kB)\n","Collecting resampy (from nemo_toolkit[all])\n","  Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (1.11.4)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (0.12.1)\n","Collecting sox (from nemo_toolkit[all])\n","  Downloading sox-1.5.0.tar.gz (63 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting texterrors (from nemo_toolkit[all])\n","  Downloading texterrors-0.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting accelerated-scan (from nemo_toolkit[all])\n","  Downloading accelerated_scan-0.2.0-py3-none-any.whl (11 kB)\n","Collecting boto3 (from nemo_toolkit[all])\n","  Downloading boto3-1.34.118-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting causal-conv1d==1.2.0.post2 (from nemo_toolkit[all])\n","  Downloading causal_conv1d-1.2.0.post2.tar.gz (7.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting faiss-cpu (from nemo_toolkit[all])\n","  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fasttext (from nemo_toolkit[all])\n","  Downloading fasttext-0.9.2.tar.gz (68 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting flask-restful (from nemo_toolkit[all])\n","  Downloading Flask_RESTful-0.3.10-py2.py3-none-any.whl (26 kB)\n","Collecting ftfy (from nemo_toolkit[all])\n","  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (5.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (3.9.0)\n","Collecting ijson (from nemo_toolkit[all])\n","  Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (0.42.1)\n","Collecting markdown2 (from nemo_toolkit[all])\n","  Downloading markdown2-2.4.13-py2.py3-none-any.whl (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nltk\u003e=3.6.5 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (3.8.1)\n","Collecting opencc\u003c1.1.7 (from nemo_toolkit[all])\n","  Downloading OpenCC-1.1.6-cp310-cp310-manylinux1_x86_64.whl (778 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.3/778.3 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pangu (from nemo_toolkit[all])\n","  Downloading pangu-4.0.6.1-py3-none-any.whl (6.4 kB)\n","Collecting rapidfuzz (from nemo_toolkit[all])\n","  Downloading rapidfuzz-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rouge-score (from nemo_toolkit[all])\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting sacrebleu (from nemo_toolkit[all])\n","  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sentence-transformers (from nemo_toolkit[all])\n","  Downloading sentence_transformers-3.0.0-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.7/224.7 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorstore\u003c0.1.46 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (0.1.45)\n","Collecting zarr (from nemo_toolkit[all])\n","  Downloading zarr-2.18.2-py3-none-any.whl (210 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.2/210.2 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting attrdict (from nemo_toolkit[all])\n","  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n","Collecting kornia (from nemo_toolkit[all])\n","  Downloading kornia-0.7.2-py2.py3-none-any.whl (825 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pypinyin (from nemo_toolkit[all])\n","  Downloading pypinyin-0.51.0-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pypinyin-dict (from nemo_toolkit[all])\n","  Downloading pypinyin_dict-0.8.0-py2.py3-none-any.whl (9.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting progress\u003e=1.5 (from nemo_toolkit[all])\n","  Downloading progress-1.6.tar.gz (7.8 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tabulate\u003e=0.8.7 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (0.9.0)\n","Collecting textdistance\u003e=4.1.5 (from nemo_toolkit[all])\n","  Downloading textdistance-4.6.2-py3-none-any.whl (31 kB)\n","Collecting addict (from nemo_toolkit[all])\n","  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n","Collecting clip (from nemo_toolkit[all])\n","  Downloading clip-0.2.0.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting decord (from nemo_toolkit[all])\n","  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting diffusers\u003e=0.19.3 (from nemo_toolkit[all])\n","  Downloading diffusers-0.28.0-py3-none-any.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting einops-exts (from nemo_toolkit[all])\n","  Downloading einops_exts-0.0.4-py3-none-any.whl (3.9 kB)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[all]) (2.31.6)\n","Collecting nerfacc\u003e=0.5.3 (from nemo_toolkit[all])\n","  Downloading nerfacc-0.5.3-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting open-clip-torch (from nemo_toolkit[all])\n","  Downloading open_clip_torch-2.24.0-py3-none-any.whl (1.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting PyMCubes (from nemo_toolkit[all])\n","  Downloading PyMCubes-0.1.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.3/274.3 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting taming-transformers (from nemo_toolkit[all])\n","  Downloading taming_transformers-0.0.1-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchdiffeq (from nemo_toolkit[all])\n","  Downloading torchdiffeq-0.2.4-py3-none-any.whl (32 kB)\n","Collecting torchsde (from nemo_toolkit[all])\n","  Downloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trimesh (from nemo_toolkit[all])\n","  Downloading trimesh-4.4.0-py3-none-any.whl (694 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.6/694.6 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nemo-text-processing (from nemo_toolkit[all])\n","  Downloading nemo_text_processing-1.0.2-py3-none-any.whl (2.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ninja (from causal-conv1d==1.2.0.post2-\u003enemo_toolkit[all])\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting mypy-extensions\u003e=0.4.3 (from black~=24.3-\u003enemo_toolkit[all])\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Collecting pathspec\u003e=0.9.0 (from black~=24.3-\u003enemo_toolkit[all])\n","  Downloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n","Requirement already satisfied: platformdirs\u003e=2 in /usr/local/lib/python3.10/dist-packages (from black~=24.3-\u003enemo_toolkit[all]) (4.2.2)\n","Requirement already satisfied: tomli\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black~=24.3-\u003enemo_toolkit[all]) (2.0.1)\n","Requirement already satisfied: typing-extensions\u003e=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black~=24.3-\u003enemo_toolkit[all]) (4.12.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers\u003e=0.19.3-\u003enemo_toolkit[all]) (7.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers\u003e=0.19.3-\u003enemo_toolkit[all]) (3.14.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers\u003e=0.19.3-\u003enemo_toolkit[all]) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers\u003e=0.19.3-\u003enemo_toolkit[all]) (2.31.0)\n","Requirement already satisfied: safetensors\u003e=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers\u003e=0.19.3-\u003enemo_toolkit[all]) (0.4.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers\u003e=0.19.3-\u003enemo_toolkit[all]) (9.4.0)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.20.3-\u003enemo_toolkit[all]) (2023.6.0)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.20.3-\u003enemo_toolkit[all]) (6.0.1)\n","Collecting antlr4-python3-runtime==4.9.* (from hydra-core\u003c=1.3.2,\u003e1.3-\u003enemo_toolkit[all])\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","INFO: pip is looking at multiple versions of jiwer to determine which version is compatible with other requirements. This could take a while.\n","Collecting jiwer (from nemo_toolkit[all])\n","  Downloading jiwer-3.0.3-py3-none-any.whl (21 kB)\n","  Downloading jiwer-3.0.2-py3-none-any.whl (21 kB)\n","  Downloading jiwer-3.0.1-py3-none-any.whl (21 kB)\n","  Downloading jiwer-3.0.0-py3-none-any.whl (21 kB)\n","  Downloading jiwer-2.6.0-py3-none-any.whl (20 kB)\n","  Downloading jiwer-2.5.2-py3-none-any.whl (15 kB)\n","Collecting rapidfuzz (from nemo_toolkit[all])\n","  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: audioread\u003e=2.1.9 in /usr/local/lib/python3.10/dist-packages (from lhotse\u003e=1.22.0-\u003enemo_toolkit[all]) (3.0.1)\n","Collecting cytoolz\u003e=0.10.1 (from lhotse\u003e=1.22.0-\u003enemo_toolkit[all])\n","  Downloading cytoolz-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting intervaltree\u003e=3.1.0 (from lhotse\u003e=1.22.0-\u003enemo_toolkit[all])\n","  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting lilcom\u003e=1.1.0 (from lhotse\u003e=1.22.0-\u003enemo_toolkit[all])\n","  Downloading lilcom-1.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (87 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.1/87.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: joblib\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa\u003e=0.10.0-\u003enemo_toolkit[all]) (1.4.2)\n","Requirement already satisfied: decorator\u003e=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa\u003e=0.10.0-\u003enemo_toolkit[all]) (4.4.2)\n","Requirement already satisfied: pooch\u003e=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa\u003e=0.10.0-\u003enemo_toolkit[all]) (1.8.1)\n","Requirement already satisfied: soxr\u003e=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa\u003e=0.10.0-\u003enemo_toolkit[all]) (0.3.7)\n","Requirement already satisfied: lazy-loader\u003e=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa\u003e=0.10.0-\u003enemo_toolkit[all]) (0.4)\n","Requirement already satisfied: msgpack\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa\u003e=0.10.0-\u003enemo_toolkit[all]) (1.0.8)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003enemo_toolkit[all]) (1.2.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003enemo_toolkit[all]) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003enemo_toolkit[all]) (4.52.4)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003enemo_toolkit[all]) (1.4.5)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003enemo_toolkit[all]) (3.1.2)\n","Requirement already satisfied: rich\u003e=12 in /usr/local/lib/python3.10/dist-packages (from nerfacc\u003e=0.5.3-\u003enemo_toolkit[all]) (13.7.1)\n","Requirement already satisfied: llvmlite\u003c0.42,\u003e=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba-\u003enemo_toolkit[all]) (0.41.1)\n","Requirement already satisfied: protobuf\u003e=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx\u003e=1.7.0-\u003enemo_toolkit[all]) (3.20.3)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil-\u003enemo_toolkit[all]) (1.16.0)\n","Collecting lightning-utilities\u003e=0.8.0 (from pytorch-lightning\u003e=2.2.1-\u003enemo_toolkit[all])\n","  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-\u003enemo_toolkit[all]) (3.5.0)\n","Requirement already satisfied: cffi\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile-\u003enemo_toolkit[all]) (1.16.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-\u003enemo_toolkit[all]) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-\u003enemo_toolkit[all]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-\u003enemo_toolkit[all]) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch-\u003enemo_toolkit[all])\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch-\u003enemo_toolkit[all])\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch-\u003enemo_toolkit[all])\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch-\u003enemo_toolkit[all])\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch-\u003enemo_toolkit[all])\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch-\u003enemo_toolkit[all])\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch-\u003enemo_toolkit[all])\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch-\u003enemo_toolkit[all])\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch-\u003enemo_toolkit[all])\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch-\u003enemo_toolkit[all])\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch-\u003enemo_toolkit[all])\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch-\u003enemo_toolkit[all]) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107-\u003etorch-\u003enemo_toolkit[all])\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tokenizers\u003c0.20,\u003e=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers\u003c=4.40.2,\u003e=4.36.0-\u003enemo_toolkit[all]) (0.19.1)\n","Collecting botocore\u003c1.35.0,\u003e=1.34.118 (from boto3-\u003enemo_toolkit[all])\n","  Downloading botocore-1.34.118-py3-none-any.whl (12.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath\u003c2.0.0,\u003e=0.7.1 (from boto3-\u003enemo_toolkit[all])\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer\u003c0.11.0,\u003e=0.10.0 (from boto3-\u003enemo_toolkit[all])\n","  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow\u003e=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets-\u003enemo_toolkit[all]) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets-\u003enemo_toolkit[all]) (0.6)\n","Collecting dill\u003c0.3.9,\u003e=0.3.0 (from datasets-\u003enemo_toolkit[all])\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting requests (from diffusers\u003e=0.19.3-\u003enemo_toolkit[all])\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash (from datasets-\u003enemo_toolkit[all])\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets-\u003enemo_toolkit[all])\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets-\u003enemo_toolkit[all]) (3.9.5)\n","Collecting pybind11\u003e=2.2 (from fasttext-\u003enemo_toolkit[all])\n","  Using cached pybind11-2.12.0-py3-none-any.whl (234 kB)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from fiddle-\u003enemo_toolkit[all]) (1.4.0)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from fiddle-\u003enemo_toolkit[all]) (0.20.3)\n","Collecting libcst (from fiddle-\u003enemo_toolkit[all])\n","  Downloading libcst-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aniso8601\u003e=0.82 (from flask-restful-\u003enemo_toolkit[all])\n","  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Flask\u003e=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-restful-\u003enemo_toolkit[all]) (2.2.5)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from flask-restful-\u003enemo_toolkit[all]) (2023.4)\n","Requirement already satisfied: wcwidth\u003c0.3.0,\u003e=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy-\u003enemo_toolkit[all]) (0.2.13)\n","Collecting distance\u003e=0.1.3 (from g2p-en-\u003enemo_toolkit[all])\n","  Downloading Distance-0.1.3.tar.gz (180 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pydantic\u003e=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect-\u003enemo_toolkit[all]) (2.7.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown-\u003enemo_toolkit[all]) (4.12.3)\n","Requirement already satisfied: ipykernel\u003e=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets-\u003enemo_toolkit[all]) (5.5.6)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets-\u003enemo_toolkit[all]) (0.2.0)\n","Requirement already satisfied: traitlets\u003e=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets-\u003enemo_toolkit[all]) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets-\u003enemo_toolkit[all]) (3.6.6)\n","Requirement already satisfied: ipython\u003e=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets-\u003enemo_toolkit[all]) (7.34.0)\n","Requirement already satisfied: jupyterlab-widgets\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets-\u003enemo_toolkit[all]) (3.0.11)\n","Collecting kornia-rs\u003e=0.1.0 (from kornia-\u003enemo_toolkit[all])\n","  Downloading kornia_rs-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m89.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cdifflib (from nemo-text-processing-\u003enemo_toolkit[all])\n","  Downloading cdifflib-1.2.6.tar.gz (11 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting pynini==2.1.5 (from nemo-text-processing-\u003enemo_toolkit[all])\n","  Downloading pynini-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.3/161.3 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Cython\u003e=0.29 in /usr/local/lib/python3.10/dist-packages (from pynini==2.1.5-\u003enemo-text-processing-\u003enemo_toolkit[all]) (3.0.10)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open-clip-torch-\u003enemo_toolkit[all]) (0.18.0+cu121)\n","Collecting timm (from open-clip-torch-\u003enemo_toolkit[all])\n","  Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tzdata\u003e=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003enemo_toolkit[all]) (2024.1)\n","Requirement already satisfied: sortedcontainers\u003e=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core-\u003enemo_toolkit[all]) (2.4.0)\n","Collecting pyannote.database\u003e=4.0.1 (from pyannote.metrics-\u003enemo_toolkit[all])\n","  Downloading pyannote.database-5.1.0-py3-none-any.whl (48 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.1/48.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docopt\u003e=0.6.2 (from pyannote.metrics-\u003enemo_toolkit[all])\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: future\u003e=0.16.0 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm-\u003enemo_toolkit[all]) (0.18.3)\n","Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest-\u003enemo_toolkit[all]) (2.0.0)\n","Requirement already satisfied: pluggy\u003c2.0,\u003e=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest-\u003enemo_toolkit[all]) (1.5.0)\n","Requirement already satisfied: exceptiongroup\u003e=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest-\u003enemo_toolkit[all]) (1.2.1)\n","Collecting ruamel.yaml.clib\u003e=0.2.7 (from ruamel.yaml-\u003enemo_toolkit[all])\n","  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting portalocker (from sacrebleu-\u003enemo_toolkit[all])\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Collecting colorama (from sacrebleu-\u003enemo_toolkit[all])\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu-\u003enemo_toolkit[all]) (4.9.4)\n","Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (1.0.8)\n","Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (1.0.6)\n","Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (1.0.1)\n","Requirement already satisfied: sphinxcontrib-htmlhelp\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (2.0.5)\n","Requirement already satisfied: sphinxcontrib-serializinghtml\u003e=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (1.1.10)\n","Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (1.0.7)\n","Requirement already satisfied: Pygments\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (2.16.1)\n","Requirement already satisfied: docutils\u003c0.19,\u003e=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (0.18.1)\n","Requirement already satisfied: snowballstemmer\u003e=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (2.2.0)\n","Requirement already satisfied: babel\u003e=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (2.15.0)\n","Requirement already satisfied: alabaster\u003c0.8,\u003e=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (0.7.16)\n","Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx-\u003enemo_toolkit[all]) (1.4.1)\n","Collecting docutils\u003c0.19,\u003e=0.14 (from sphinx-\u003enemo_toolkit[all])\n","  Downloading docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.5/575.5 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pybtex\u003e=0.24 (from sphinxcontrib-bibtex-\u003enemo_toolkit[all])\n","  Downloading pybtex-0.24.0-py2.py3-none-any.whl (561 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.4/561.4 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pybtex-docutils\u003e=1.0.0 (from sphinxcontrib-bibtex-\u003enemo_toolkit[all])\n","  Downloading pybtex_docutils-1.0.3-py3-none-any.whl (6.4 kB)\n","Requirement already satisfied: grpcio\u003e=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003enemo_toolkit[all]) (1.64.0)\n","Requirement already satisfied: google-auth\u003c3,\u003e=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003enemo_toolkit[all]) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib\u003c2,\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003enemo_toolkit[all]) (1.2.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003enemo_toolkit[all]) (3.6)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003enemo_toolkit[all]) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard-\u003enemo_toolkit[all]) (3.0.3)\n","Collecting plac (from texterrors-\u003enemo_toolkit[all])\n","  Downloading plac-1.4.3-py2.py3-none-any.whl (22 kB)\n","Collecting loguru (from texterrors-\u003enemo_toolkit[all])\n","  Downloading loguru-0.7.2-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from texterrors-\u003enemo_toolkit[all]) (2.4.0)\n","Collecting Levenshtein (from texterrors-\u003enemo_toolkit[all])\n","  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trampoline\u003e=0.1.2 (from torchsde-\u003enemo_toolkit[all])\n","  Downloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\n","Collecting docker-pycreds\u003e=0.4.0 (from wandb-\u003enemo_toolkit[all])\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting gitpython!=3.1.29,\u003e=1.0.0 (from wandb-\u003enemo_toolkit[all])\n","  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb-\u003enemo_toolkit[all]) (5.9.5)\n","Collecting sentry-sdk\u003e=1.0.0 (from wandb-\u003enemo_toolkit[all])\n","  Downloading sentry_sdk-2.3.1-py2.py3-none-any.whl (289 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting setproctitle (from wandb-\u003enemo_toolkit[all])\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Collecting asciitree (from zarr-\u003enemo_toolkit[all])\n","  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting numcodecs\u003e=0.10.0 (from zarr-\u003enemo_toolkit[all])\n","  Downloading numcodecs-0.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fasteners (from zarr-\u003enemo_toolkit[all])\n","  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n","Requirement already satisfied: urllib3!=2.2.0,\u003c3,\u003e=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore\u003c1.35.0,\u003e=1.34.118-\u003eboto3-\u003enemo_toolkit[all]) (2.0.7)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi\u003e=1.0-\u003esoundfile-\u003enemo_toolkit[all]) (2.22)\n","Requirement already satisfied: toolz\u003e=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz\u003e=0.10.1-\u003elhotse\u003e=1.22.0-\u003enemo_toolkit[all]) (0.12.1)\n","Requirement already satisfied: itsdangerous\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask\u003e=0.8-\u003eflask-restful-\u003enemo_toolkit[all]) (2.2.0)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets-\u003enemo_toolkit[all]) (1.3.1)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets-\u003enemo_toolkit[all]) (23.2.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets-\u003enemo_toolkit[all]) (1.4.1)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets-\u003enemo_toolkit[all]) (6.0.5)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets-\u003enemo_toolkit[all]) (1.9.4)\n","Requirement already satisfied: async-timeout\u003c5.0,\u003e=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-\u003edatasets-\u003enemo_toolkit[all]) (4.0.3)\n","Collecting gitdb\u003c5,\u003e=4.0.1 (from gitpython!=3.1.29,\u003e=1.0.0-\u003ewandb-\u003enemo_toolkit[all])\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003enemo_toolkit[all]) (5.3.3)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003enemo_toolkit[all]) (0.4.0)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003enemo_toolkit[all]) (4.9)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib\u003c2,\u003e=0.5-\u003etensorboard-\u003enemo_toolkit[all]) (1.3.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel\u003e=4.5.1-\u003eipywidgets-\u003enemo_toolkit[all]) (6.1.12)\n","Requirement already satisfied: tornado\u003e=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel\u003e=4.5.1-\u003eipywidgets-\u003enemo_toolkit[all]) (6.3.3)\n","Collecting jedi\u003e=0.16 (from ipython\u003e=4.0.0-\u003eipywidgets-\u003enemo_toolkit[all])\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,\u003c3.1.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003enemo_toolkit[all]) (3.0.45)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.1.7)\n","Requirement already satisfied: pexpect\u003e4.3 in /usr/local/lib/python3.10/dist-packages (from ipython\u003e=4.0.0-\u003eipywidgets-\u003enemo_toolkit[all]) (4.9.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch-\u003enemo_toolkit[all]) (2.1.5)\n","Collecting typer\u003e=0.12.1 (from pyannote.database\u003e=4.0.1-\u003epyannote.metrics-\u003enemo_toolkit[all])\n","  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting latexcodec\u003e=1.0.4 (from pybtex\u003e=0.24-\u003esphinxcontrib-bibtex-\u003enemo_toolkit[all])\n","  Downloading latexcodec-3.0.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: annotated-types\u003e=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003e=1.9.1-\u003einflect-\u003enemo_toolkit[all]) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003e=1.9.1-\u003einflect-\u003enemo_toolkit[all]) (2.18.3)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ediffusers\u003e=0.19.3-\u003enemo_toolkit[all]) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ediffusers\u003e=0.19.3-\u003enemo_toolkit[all]) (3.7)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ediffusers\u003e=0.19.3-\u003enemo_toolkit[all]) (2024.2.2)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich\u003e=12-\u003enerfacc\u003e=0.5.3-\u003enemo_toolkit[all]) (3.0.0)\n","Requirement already satisfied: mpmath\u003c1.4.0,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch-\u003enemo_toolkit[all]) (1.3.0)\n","Requirement already satisfied: notebook\u003e=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (6.5.5)\n","Requirement already satisfied: soupsieve\u003e1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4-\u003egdown-\u003enemo_toolkit[all]) (2.5)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata-\u003ediffusers\u003e=0.19.3-\u003enemo_toolkit[all]) (3.19.0)\n","INFO: pip is looking at multiple versions of levenshtein to determine which version is compatible with other requirements. This could take a while.\n","Collecting Levenshtein (from texterrors-\u003enemo_toolkit[all])\n","  Downloading Levenshtein-0.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading Levenshtein-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading Levenshtein-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading Levenshtein-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.9/172.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of requests[socks] to determine which version is compatible with other requirements. This could take a while.\n","Requirement already satisfied: PySocks!=1.5.7,\u003e=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ediffusers\u003e=0.19.3-\u003enemo_toolkit[all]) (1.7.1)\n","Collecting smmap\u003c6,\u003e=3.0.1 (from gitdb\u003c5,\u003e=4.0.1-\u003egitpython!=3.1.29,\u003e=1.0.0-\u003ewandb-\u003enemo_toolkit[all])\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Requirement already satisfied: parso\u003c0.9.0,\u003e=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi\u003e=0.16-\u003eipython\u003e=4.0.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.8.4)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich\u003e=12-\u003enerfacc\u003e=0.5.3-\u003enemo_toolkit[all]) (0.1.2)\n","Requirement already satisfied: pyzmq\u003c25,\u003e=17 in /usr/local/lib/python3.10/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (24.0.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (23.1.0)\n","Requirement already satisfied: jupyter-core\u003e=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (5.7.2)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (5.10.4)\n","Requirement already satisfied: nbconvert\u003e=5 in /usr/local/lib/python3.10/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (6.5.4)\n","Requirement already satisfied: nest-asyncio\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (1.6.0)\n","Requirement already satisfied: Send2Trash\u003e=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (1.8.3)\n","Requirement already satisfied: terminado\u003e=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.20.0)\n","Requirement already satisfied: nbclassic\u003e=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (1.1.0)\n","Requirement already satisfied: ptyprocess\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect\u003e4.3-\u003eipython\u003e=4.0.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.7.0)\n","Requirement already satisfied: pyasn1\u003c0.7.0,\u003e=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003c3,\u003e=1.6.3-\u003etensorboard-\u003enemo_toolkit[all]) (0.6.0)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c2,\u003e=0.5-\u003etensorboard-\u003enemo_toolkit[all]) (3.2.2)\n","Collecting shellingham\u003e=1.3.0 (from typer\u003e=0.12.1-\u003epyannote.database\u003e=4.0.1-\u003epyannote.metrics-\u003enemo_toolkit[all])\n","  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: notebook-shim\u003e=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic\u003e=0.4.7-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.2.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert\u003e=5-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (6.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert\u003e=5-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.7.1)\n","Requirement already satisfied: entrypoints\u003e=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert\u003e=5-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.4)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert\u003e=5-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.3.0)\n","Requirement already satisfied: mistune\u003c2,\u003e=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert\u003e=5-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.8.4)\n","Requirement already satisfied: nbclient\u003e=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert\u003e=5-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.10.0)\n","Requirement already satisfied: pandocfilters\u003e=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert\u003e=5-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert\u003e=5-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (1.3.0)\n","Requirement already satisfied: fastjsonschema\u003e=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (2.19.1)\n","Requirement already satisfied: jsonschema\u003e=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (4.19.2)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (21.2.0)\n","Requirement already satisfied: jsonschema-specifications\u003e=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (2023.12.1)\n","Requirement already satisfied: referencing\u003e=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.35.1)\n","Requirement already satisfied: rpds-py\u003e=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003e=2.6-\u003enbformat-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.18.1)\n","Requirement already satisfied: jupyter-server\u003c3,\u003e=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim\u003e=0.2.3-\u003enbclassic\u003e=0.4.7-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (1.24.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach-\u003enbconvert\u003e=5-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (0.5.1)\n","Requirement already satisfied: anyio\u003c4,\u003e=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server\u003c3,\u003e=1.8-\u003enotebook-shim\u003e=0.2.3-\u003enbclassic\u003e=0.4.7-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server\u003c3,\u003e=1.8-\u003enotebook-shim\u003e=0.2.3-\u003enbclassic\u003e=0.4.7-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (1.8.0)\n","Requirement already satisfied: sniffio\u003e=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio\u003c4,\u003e=3.1.0-\u003ejupyter-server\u003c3,\u003e=1.8-\u003enotebook-shim\u003e=0.2.3-\u003enbclassic\u003e=0.4.7-\u003enotebook\u003e=4.4.1-\u003ewidgetsnbextension~=3.6.0-\u003eipywidgets-\u003enemo_toolkit[all]) (1.3.1)\n","Building wheels for collected packages: causal-conv1d, antlr4-python3-runtime, progress, clip, fasttext, kaldi-python-io, nemo_toolkit, rouge-score, sox, wget, distance, docopt, intervaltree, asciitree, cdifflib\n","  Building wheel for causal-conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for causal-conv1d: filename=causal_conv1d-1.2.0.post2-cp310-cp310-linux_x86_64.whl size=45620210 sha256=ead934ec497af2911cf140847ff9015a01b8f0116a1e6f35b4915b27fc7f8f0c\n","  Stored in directory: /root/.cache/pip/wheels/eb/8f/52/646c36c652677964016059dd0845960d162668451aeaaf4533\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=600bb810629755de957a4b35470bf89e22d28c6a0c626ac6ecc25edd8d5bd46b\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for progress: filename=progress-1.6-py3-none-any.whl size=9614 sha256=55c3c469d8f50ede0a3f46fdf79a26469995a2328719c0acd6885d7e5f74959b\n","  Stored in directory: /root/.cache/pip/wheels/a2/68/5f/c339b20a41659d856c93ccdce6a33095493eb82c3964aac5a1\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-0.2.0-py3-none-any.whl size=6989 sha256=a7f4da0e8ddad6ccce56483d4b9b123b468ce37f145b2679a5b42dfa2f2d2b9c\n","  Stored in directory: /root/.cache/pip/wheels/7f/5c/e6/2c0fdb453a3569188864b17e9676bea8b3b7e160c037117869\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4227139 sha256=e94e7d0aea1a42a7f4d03d37c4163aa2a4e3647ba9a9d4685ea16c7fcf42de2d\n","  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n","  Building wheel for kaldi-python-io (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kaldi-python-io: filename=kaldi_python_io-1.2.2-py3-none-any.whl size=8949 sha256=c22be248913a54e3e8fd2aae46ebeb903e8ed9ce3a0dc1be72ecede95fdb3a32\n","  Stored in directory: /root/.cache/pip/wheels/b7/23/5f/49d3a826be576faf61d84e8028e1914bb36a5586ee2613b087\n","  Building wheel for nemo_toolkit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nemo_toolkit: filename=nemo_toolkit-2.0.0rc1-py3-none-any.whl size=3718732 sha256=aa210ee05f2de2f4b4246c7d8c76113677e6c06ef8525b09cc62b73ac316acfe\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-27gdwfsa/wheels/6c/d2/4f/1572b895b6a4dbd9fdf534c882d9bc6e94e700a6db5bb20423\n","  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=920e370a43dfddae0dac7beb40f1109b90ab26b741f05ddc7659a9caa4d91f31\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","  Building wheel for sox (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sox: filename=sox-1.5.0-py3-none-any.whl size=40038 sha256=913fdfbf32656015c77346e787341de0cbf932000779fbc1cd6ad8279fc9bdc2\n","  Stored in directory: /root/.cache/pip/wheels/74/e7/7b/8033be3ec5e4994595d01269fc9657c8fd83a0dcbf8536666a\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=6257d76774eacca4e51c2bac8909629254bd9e1b09fffaae3291d6111d46e400\n","  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n","  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16258 sha256=6b6f93b36e105e4bdb7b320ce389b9b06120ece7a302d09a7f7b7db817521334\n","  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=7070b4d8b1255764fbabdd43e19a7aadfc4d8e2773981cc7a0fc1d32553da33e\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26096 sha256=4023484590fedb6898922e383bc7b51c9023e733c0fc6ee3d32276a40dfe89a4\n","  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n","  Building wheel for asciitree (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5034 sha256=5d9758abd76f571a9ec683ea5f6bc70c5914a3dbc08400bce588d075c1950391\n","  Stored in directory: /root/.cache/pip/wheels/7f/4e/be/1171b40f43b918087657ec57cf3b81fa1a2e027d8755baa184\n","  Building wheel for cdifflib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cdifflib: filename=cdifflib-1.2.6-cp310-cp310-linux_x86_64.whl size=27684 sha256=1e13f85caf40051b93a81dbd08e33cae0502dfbe4b1b0a6d9953d902915f21ef\n","  Stored in directory: /root/.cache/pip/wheels/87/a7/fd/8061e24ed08689045cb6d1ca303768dc463b20a5a338174841\n","Successfully built causal-conv1d antlr4-python3-runtime progress clip fasttext kaldi-python-io nemo_toolkit rouge-score sox wget distance docopt intervaltree asciitree cdifflib\n","Installing collected packages: wget, trampoline, pydub, progress, plac, pangu, opencc, ninja, ijson, docopt, distance, clip, braceexpand, asciitree, antlr4-python3-runtime, aniso8601, addict, xxhash, webdataset, trimesh, textdistance, sox, smmap, shellingham, setproctitle, sentry-sdk, ruamel.yaml.clib, requests, rapidfuzz, pytest-runner, pypinyin, pynini, pybind11, portalocker, pathspec, parameterized, onnx, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numcodecs, mypy-extensions, marshmallow, markdown2, loguru, lilcom, lightning-utilities, libcst, latexcodec, kornia-rs, kaldiio, kaldi-python-io, jmespath, jedi, isort, intervaltree, ftfy, fasteners, faiss-cpu, einops, docutils, docker-pycreds, dill, decord, cytoolz, colorama, click, cdifflib, attrdict, zarr, sacremoses, sacrebleu, ruamel.yaml, resampy, pytest-mock, pypinyin-dict, PyMCubes, pyloudnorm, pybtex, pyannote.core, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, Levenshtein, jiwer, hydra-core, gitdb, fiddle, fasttext, einops-exts, botocore, black, typer, texterrors, s3transfer, rouge-score, pybtex-docutils, nvidia-cusolver-cu12, lhotse, gitpython, flask-restful, diffusers, wandb, transformers, sphinxcontrib-bibtex, pyannote.database, g2p-en, datasets, boto3, torchsde, torchmetrics, torchdiffeq, sentence-transformers, pyannote.metrics, nerfacc, nemo_toolkit, nemo-text-processing, kornia, causal-conv1d, accelerated-scan, timm, pytorch-lightning, taming-transformers, open-clip-torch\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.18.1\n","    Uninstalling docutils-0.18.1:\n","      Successfully uninstalled docutils-0.18.1\n","  Attempting uninstall: click\n","    Found existing installation: click 8.1.7\n","    Uninstalling click-8.1.7:\n","      Successfully uninstalled click-8.1.7\n","  Attempting uninstall: typer\n","    Found existing installation: typer 0.9.4\n","    Uninstalling typer-0.9.4:\n","      Successfully uninstalled typer-0.9.4\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.41.1\n","    Uninstalling transformers-4.41.1:\n","      Successfully uninstalled transformers-4.41.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","spacy 3.7.4 requires typer\u003c0.10.0,\u003e=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer\u003c0.10.0,\u003e=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Levenshtein-0.22.0 PyMCubes-0.1.4 accelerated-scan-0.2.0 addict-2.4.0 aniso8601-9.0.1 antlr4-python3-runtime-4.9.3 asciitree-0.3.3 attrdict-2.0.1 black-24.4.2 boto3-1.34.118 botocore-1.34.118 braceexpand-0.1.7 causal-conv1d-1.2.0.post2 cdifflib-1.2.6 click-8.0.2 clip-0.2.0 colorama-0.4.6 cytoolz-0.12.3 datasets-2.19.2 decord-0.6.0 diffusers-0.28.0 dill-0.3.8 distance-0.1.3 docker-pycreds-0.4.0 docopt-0.6.2 docutils-0.17.1 einops-0.8.0 einops-exts-0.0.4 faiss-cpu-1.8.0 fasteners-0.19 fasttext-0.9.2 fiddle-0.3.0 flask-restful-0.3.10 ftfy-6.2.0 g2p-en-2.1.0 gitdb-4.0.11 gitpython-3.1.43 hydra-core-1.3.2 ijson-3.2.3 intervaltree-3.1.0 isort-5.13.2 jedi-0.19.1 jiwer-2.5.2 jmespath-1.0.1 kaldi-python-io-1.2.2 kaldiio-2.18.0 kornia-0.7.2 kornia-rs-0.1.3 latexcodec-3.0.0 lhotse-1.23.0 libcst-1.4.0 lightning-utilities-0.11.2 lilcom-1.7 loguru-0.7.2 markdown2-2.4.13 marshmallow-3.21.2 multiprocess-0.70.16 mypy-extensions-1.0.0 nemo-text-processing-1.0.2 nemo_toolkit-2.0.0rc1 nerfacc-0.5.3 ninja-1.11.1.1 numcodecs-0.12.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 omegaconf-2.3.0 onnx-1.16.1 open-clip-torch-2.24.0 opencc-1.1.6 pangu-4.0.6.1 parameterized-0.9.0 pathspec-0.12.1 plac-1.4.3 portalocker-2.8.2 progress-1.6 pyannote.core-5.0.0 pyannote.database-5.1.0 pyannote.metrics-3.2.1 pybind11-2.12.0 pybtex-0.24.0 pybtex-docutils-1.0.3 pydub-0.25.1 pyloudnorm-0.1.1 pynini-2.1.5 pypinyin-0.51.0 pypinyin-dict-0.8.0 pytest-mock-3.14.0 pytest-runner-6.0.1 pytorch-lightning-2.2.5 rapidfuzz-2.13.7 requests-2.32.3 resampy-0.4.3 rouge-score-0.1.2 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.8 s3transfer-0.10.1 sacrebleu-2.4.2 sacremoses-0.1.1 sentence-transformers-3.0.0 sentry-sdk-2.3.1 setproctitle-1.3.3 shellingham-1.5.4 smmap-5.0.1 sox-1.5.0 sphinxcontrib-bibtex-2.6.2 taming-transformers-0.0.1 textdistance-4.6.2 texterrors-0.4.4 timm-1.0.3 torchdiffeq-0.2.4 torchmetrics-1.4.0.post0 torchsde-0.2.6 trampoline-0.1.2 transformers-4.40.2 trimesh-4.4.0 typer-0.12.3 wandb-0.17.0 webdataset-0.2.86 wget-3.2 xxhash-3.4.1 zarr-2.18.2\n","/content\n"]}],"source":["\"\"\"\n","You can run either this notebook locally (if you have all the dependencies and a GPU) or on Google Colab.\n","\n","Instructions for setting up Colab are as follows:\n","1. Open a new Python 3 notebook.\n","2. Import this notebook from GitHub (File -\u003e Upload Notebook -\u003e \"GITHUB\" tab -\u003e copy/paste GitHub URL)\n","3. Connect to an instance with a GPU (Runtime -\u003e Change runtime type -\u003e select \"GPU\" for hardware accelerator)\n","4. Run this cell to set up dependencies.\n","5. Restart the runtime (Runtime -\u003e Restart Runtime) for any upgraded packages to take effect\n","\"\"\"\n","\n","NEMO_DIR_PATH = \"NeMo\"\n","BRANCH = 'main'\n","\n","! git clone https://github.com/NVIDIA/NeMo\n","%cd NeMo\n","! python -m pip install git+https://github.com/NVIDIA/NeMo.git@$BRANCH#egg=nemo_toolkit[all]\n","%cd .."]},{"cell_type":"markdown","metadata":{"id":"doUGod27_20h"},"source":["# Speaker Diarization Training"]},{"cell_type":"markdown","metadata":{"id":"bZl2GFvY_20i"},"source":["## Neural Diarizer in Speaker Diarization Pipeline"]},{"cell_type":"markdown","metadata":{"id":"oOPkVJZm_20j"},"source":["\u003cimg src=\"images/diar_pipeline.png\" alt=\"diar_pipeline\" style=\"width: 800px;\"/\u003e"]},{"cell_type":"markdown","metadata":{"id":"l4-_rmMv_20k"},"source":["Speaker diarization system needs to capture the characteristics of unseen speakers from the given audio recording and generate speaker-homogeneous segments which belong to corresponding speaker labels. During the speaker diarization process, the number of speakers should be estimated, then the audio segments should be assigned to a few of speaker labels.\n","\n","While clustering algorithms can also assign segments to speaker groups, overlap-aware diarization cannot be done with clustering based diarizer since one segment is only assigned to one speaker label. However, we can use the clustering result to create initial speaker profiles and train a neural model that generates overlap-aware speaker labels by comparing the input audio signal with the initial speaker profiles. In the NeMo speaker diarization toolkit, we refer to such neural modules as **neural diarizer**.\n","\n","The Multi-scale Diarization Decoder (MSDD) model is a type of neural diarizer we can use in the NeMo speaker diarization pipeline. This tutorial shows how to train MSDD on a small toy dataset. By using MSDD on top of clustering diarizer, we can obtain the following benefits:\n","\n","- **Improved diarization accuracy**: Compared to clustering diarizer, MSDD could achieve a lower diarization error rate (DER)\n","- **Overlap aware diarization**: Speaker diarization results in clustering diarizer do not include speech overlaps\n","- **Model training on actual multispeaker dataset**: Unlike training a speaker embedding model, we can train or finetune a neural model on an actual speaker diarization dataset where multiple speakers are recorded in a single audio file."]},{"cell_type":"markdown","metadata":{"id":"6d9-NKzs_20k"},"source":["### Training and inference of Multi-scale Diarization Decoder\n","\n","When it comes to the speaker diarization problem, MSDD model employs a divide-and-conquer strategy where a pairwise model is employed for both training and inference. The following figure explains how a pairwise model is employed for training and inference."]},{"cell_type":"markdown","metadata":{"id":"PRboGZ-1_20l"},"source":["\u003cimg src=\"images/msdd_train_and_infer.png\" alt=\"MSDD_train_infer\" style=\"width: 800px;\"/\u003e"]},{"cell_type":"markdown","metadata":{"id":"f5-FYxQY_20l"},"source":["Here are itemized descriptions of noteworthy features of the MSDD model.\n","\n","#### Training\n","\n","- **Oracle VAD, multi-scale segmentation for training**   \n","In a training setup, we use oracle VAD from ground-truth annotation files (RTTM files) and perform multiscale segmentation. After we obtain timestamps for each and every segment, we feed multi-scale timestamps and raw audio signals into a computational graph where the speaker embedding extractor and neural diarizer is trained.  \n","\n","   \n","- **MSDD inputs for training process**  \n","During training, we employ oracle clustering result (ground-truth speaker labels in the annotation file) to calculate the cluster-average embeddings. Subsequently, we calculate binary cross-entropy loss which calculates a loss value for each timestep and each speaker.\n","\n","\n","- **End-to-end training: from raw audio to speaker label**   \n","The training approach we employ can be considered as end-to-end training since the input to the computational graph is raw audio signal and the outputs are speaker labels. The end-to-end training is depicted in a dotted box in the above figure. We can either freeze the speaker embedding model or train it jointly depending on the tasks.   \n","\n","\n","- **Pairwise (two-speaker) unit model**   \n","While training the MSDD model, we use a two-speaker dataset for a two speaker model. For this pairwise training, we clean the source dataset to have only two speakers by splitting the annotation.   \n","\n","\n","- **Split training samples**  \n","Since we have finite GPU memory for training, we break down the training audio samples into short audio samples. We set step-count, and step-count indicates a unit of decision for speaker label estimation. We set step-count (e.g., `step_count=50`) when we create training datasets and use the step-count for training.    "]},{"cell_type":"markdown","metadata":{"id":"rWVcKFpx_20n"},"source":["#### Inference\n","\n","- **Multi-scale clustering**  \n","In inference mode, we apply multi-scale clustering for obtaining speaker profiles that are represented by cluster-average embedding.   \n","\n","\n","- **Divide-and-conquer approach with pairwise (two-speaker) unit model**   \n","We retrieve all possible pairs from the estimated number of speakers and average the results. For example, if there are four speakers `(A, B, C, D)`, we extract 6 pairs: `(A,B)`, `(A,C)`, `(A,D)`, `(B,C)`, `(B,D)`, `(C,D)`. Finally, the sigmoid outputs are averaged. In this way, MSDD can deal with a flexible number of speakers using a pairwise model.\n","\n","\n","- **Split inference samples**  \n","As in the training process, we can also break down the target samples for inference. While we can do inference on whole input audio at once, split inference generally gives an improved performance. It is recommended to use the same step-count you used for training the MSDD model (e.g., `diar_window_length=50`) for your inference configurations."]},{"cell_type":"markdown","metadata":{"id":"8JTO0n8u_20n"},"source":["### Input and Output of Multi-scale Diarization Decoder"]},{"cell_type":"markdown","metadata":{"id":"zmSElSbw_20o"},"source":["While using an MSDD model as neural diarizer has a few benefits, MSDD models require a clustering result to obtain initial speaker profiles as references for performing overlap-aware speaker diarization inference.  Here are descriptions for input and output of the MSDD model."]},{"cell_type":"markdown","metadata":{"id":"ewhSly6i_20o"},"source":["#### Input: Clustering as Initialization\n","\n","MSDD model is a diarizer model that accepts two different data inputs:\n","\n"," 1. Cluster-average embeddings\n"," 2. Multi-scale embedding sequence\n","\n","The two input signals are depicted in the following figure."]},{"cell_type":"markdown","metadata":{"id":"s9PkW9M7_20o"},"source":["\u003cimg src=\"images/msdd_inputs.png\" alt=\"MSDD_inputs\" style=\"width: 600px;\"/\u003e"]},{"cell_type":"markdown","metadata":{"id":"Z_HMx6Z0_20p"},"source":["By initializing the diarization task with a clustering algorithm, we can estimate the number of speakers and cluster-average embeddings. Thus, the cluster-average embeddings provide the speaker profile of each speaker. The cluster-average embeddings we provide can be regarded as reference signals for providing seed speaker profiles.\n","\n","Once we obtain the fixed (or estimated) number of speakers, the speaker diarization problem becomes a binary classification task where we need to estimate whether a certain speaker's speech exists or not at a given timestep.  "]},{"cell_type":"markdown","metadata":{"id":"dU0T32mK_20p"},"source":["#### Output: Sigmoid Output and Binary Cross-entropy Loss"]},{"cell_type":"markdown","metadata":{"id":"sxvTw5Ox_20p"},"source":["\u003cimg src=\"images/msdd_output_loss.png\" alt=\"MSDD_output_loss\" style=\"width: 600px;\"/\u003e"]},{"cell_type":"markdown","metadata":{"id":"VTHmk6zt_20p"},"source":["The above figure depicts the inputs and outputs of the MSDD model. As an output from MSDD, sigmoid values for each speaker are generated. These sigmoid values are independent from the other speakers and indicate the simulated probability of the corresponding speaker's speech signal at the given step. During the training process, binary cross-entropy (BCE) is calculated for each individual sigmoid value and summed up to calculate the total loss for optimization."]},{"cell_type":"markdown","metadata":{"id":"ZmgbooLG_20q"},"source":["## Example Data Creation\n","\n","- Please skip this section and go directly to [Prepare Training data for MSDD](#Prepare-Training-data-for-MSDD) section if you have your own speaker diarization dataset.\n","\n","In this tutorial, we use [NeMo Multispeaker Simulator](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tools/Multispeaker_Simulator.ipynb) and the Librispeech corpus to generate a toy training dataset for demonstration purpose. You can replace the simulated dataset with your own datasets if you have proper speaker annotations (RTTM files) for the dataset. If you do not have access to any speaker diarization datasets, you can use [NeMo Multispeaker Simulator](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tools/Multispeaker_Simulator.ipynb) by generating a good amount of data samples to meet your needs.\n","\n","For more details regarding data simulator, please follow the descriptions in [NeMo Multispeaker Simulator](https://github.com/NVIDIA/NeMo/blob/main/tutorials/tools/Multispeaker_Simulator.ipynb) and we will not cover configurations and detailed process of data simulation in this tutorial.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32217,"status":"ok","timestamp":1717302382005,"user":{"displayName":"Annie Villalta","userId":"01597448361855550417"},"user_tz":420},"id":"gC8nF-P0_20q","outputId":"2cdf836c-f8af-473f-efd4-35532927b032"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libsndfile1 is already the newest version (1.0.31-2ubuntu0.1).\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","The following additional packages will be installed:\n","  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox3 libwavpack1\n","Suggested packages:\n","  libsox-fmt-all\n","The following NEW packages will be installed:\n","  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox3 libwavpack1 sox\n","0 upgraded, 7 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 617 kB of archives.\n","After this operation, 1,764 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 sox amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [104 kB]\n","Fetched 617 kB in 0s (2,737 kB/s)\n","Selecting previously unselected package libopencore-amrnb0:amd64.\n","(Reading database ... 121918 files and directories currently installed.)\n","Preparing to unpack .../0-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n","Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n","Selecting previously unselected package libopencore-amrwb0:amd64.\n","Preparing to unpack .../1-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n","Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n","Selecting previously unselected package libsox3:amd64.\n","Preparing to unpack .../2-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Selecting previously unselected package libsox-fmt-alsa:amd64.\n","Preparing to unpack .../3-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Selecting previously unselected package libwavpack1:amd64.\n","Preparing to unpack .../4-libwavpack1_5.4.0-1build2_amd64.deb ...\n","Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n","Selecting previously unselected package libsox-fmt-base:amd64.\n","Preparing to unpack .../5-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Selecting previously unselected package sox.\n","Preparing to unpack .../6-sox_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n","Unpacking sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n","Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n","Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n","Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Setting up sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mCollecting unidecode\n","  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mRequirement already satisfied: matplotlib\u003e=3.3.2 in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.2) (1.2.1)\n","Requirement already satisfied: cycler\u003e=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.2) (0.12.1)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.2) (4.51.0)\n","Requirement already satisfied: kiwisolver\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.2) (1.4.5)\n","Requirement already satisfied: numpy\u003e=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.2) (1.25.2)\n","Requirement already satisfied: packaging\u003e=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.2) (24.0)\n","Requirement already satisfied: pillow\u003e=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.2) (9.4.0)\n","Requirement already satisfied: pyparsing\u003e=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.2) (3.1.2)\n","Requirement already satisfied: python-dateutil\u003e=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib\u003e=3.3.2) (2.8.2)\n","Requirement already satisfied: six\u003e=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil\u003e=2.7-\u003ematplotlib\u003e=3.3.2) (1.16.0)\n"]}],"source":["# Install dependencies for data simulator\n","!apt-get install sox libsndfile1 ffmpeg\n","!pip install wget\n","!pip install unidecode\n","!pip install \"matplotlib\u003e=3.3.2\""]},{"cell_type":"markdown","metadata":{"id":"Hnzef5JO_20r"},"source":["#### Data Simulation Step 1:  Download Required Resources\n","\n","We need to download the LibriSpeech corpus and corresponding word alignments for generating synthetic multi-speaker audio sessions. In addition, we need to download necessary data cleaning scripts from NeMo git."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"srOKIYZS_20r"},"outputs":[],"source":["import os\n","NEMO_DIR_PATH = \"NeMo\"\n","BRANCH = 'main'\n","\n","# download scripts if not already there\n","if not os.path.exists('NeMo/scripts'):\n","  print(\"Downloading necessary scripts\")\n","  !mkdir -p NeMo/scripts/dataset_processing\n","  !mkdir -p NeMo/scripts/speaker_tasks\n","  !wget -P NeMo/scripts/dataset_processing/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/scripts/dataset_processing/get_librispeech_data.py\n","  !wget -P NeMo/scripts/speaker_tasks/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/scripts/speaker_tasks/create_alignment_manifest.py\n","  !wget -P NeMo/scripts/speaker_tasks/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/scripts/speaker_tasks/create_msdd_train_dataset.py\n","  !wget -P NeMo/scripts/speaker_tasks/ https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/scripts/speaker_tasks/pathfiles_to_diarize_manifest.py"]},{"cell_type":"markdown","metadata":{"id":"Y1CSLLfB_20s"},"source":["Now that we have downloaded all the necessary scripts for data creation and preparation, we can start the data simulation step by downloading the LibriSpeech corpus."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PsdJAuR2_20s"},"outputs":[],"source":["!mkdir -p LibriSpeech\n","!python {NEMO_DIR_PATH}/scripts/dataset_processing/get_librispeech_data.py \\\n","  --data_root LibriSpeech \\\n","  --data_sets dev_clean"]},{"cell_type":"markdown","metadata":{"id":"wA7Zjnej_20t"},"source":["We can get the forced word alignments data for the LibriSpeech corpus from [this repository.](https://github.com/CorentinJ/librispeech-alignments). Full forced alignments data can be downloaded at [google drive link for alignments data](https://drive.google.com/file/d/1WYfgr31T-PPwMcxuAq09XZfHQO5Mw8fE/view?usp=sharing). We will download only a subset of forced alignment data containing dev-clean part."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o_rbeqMH_20t"},"outputs":[],"source":["!wget -nc https://dldata-public.s3.us-east-2.amazonaws.com/LibriSpeech_Alignments.tar.gz\n","!tar -xzf LibriSpeech_Alignments.tar.gz\n","!rm -f LibriSpeech_Alignments.tar.gz"]},{"cell_type":"markdown","metadata":{"id":"K6-YIA-n_20t"},"source":["#### Data Simulation Step 2:  Produce Manifest File with Forced Alignments\n","\n","We will merge the LibriSpeech manifest files and LibriSpeech forced alignments into one manifest file for ease of use when generating synthetic data. Create alignment files by running the following script.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hY4CcsW8_20u"},"outputs":[],"source":["!python NeMo/scripts/speaker_tasks/create_alignment_manifest.py \\\n","  --input_manifest_filepath LibriSpeech/dev_clean.json \\\n","  --base_alignment_path LibriSpeech_Alignments \\\n","  --output_manifest_filepath ./dev-clean-align.json \\\n","  --ctm_output_directory ./ctm_out \\\n","  --libri_dataset_split dev-clean"]},{"cell_type":"markdown","metadata":{"id":"Yuvtvm54_20u"},"source":["#### Data Simulation Step 3:  Set data simulation parameters"]},{"cell_type":"markdown","metadata":{"id":"sa0TTJvn_20u"},"source":["Now that we have downloaded all the sources we need for data creation, we need to download data simulator configurations in `.yaml` format. Download the YAML file and download `data_simulator.py` script from NeMo repository."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":584,"status":"ok","timestamp":1717314959987,"user":{"displayName":"Annie Villalta","userId":"01597448361855550417"},"user_tz":420},"id":"CF4_CBBH_20u","outputId":"e50a075b-59ed-4a58-f393-0104ab3d07f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-06-02 07:55:59--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/tools/speech_data_simulator/conf/data_simulator.yaml\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9132 (8.9K) [text/plain]\n","Saving to: ‘/content/conf/data_simulator.yaml’\n","\n","\rdata_simulator.yaml   0%[                    ]       0  --.-KB/s               \rdata_simulator.yaml 100%[===================\u003e]   8.92K  --.-KB/s    in 0s      \n","\n","2024-06-02 07:55:59 (80.4 MB/s) - ‘/content/conf/data_simulator.yaml’ saved [9132/9132]\n","\n","data_simulator:\n","  manifest_filepath: ???\n","  sr: 16000\n","  random_seed: 42\n","  multiprocessing_chunksize: 10000\n","  session_config:\n","    num_speakers: 4\n","    num_sessions: 60\n","    session_length: 600\n","  session_params:\n","    max_audio_read_sec: 20.0\n","    sentence_length_params:\n","    - 0.4\n","    - 0.05\n","    dominance_var: 0.11\n","    min_dominance: 0.05\n","    turn_prob: 0.875\n","    min_turn_prob: 0.5\n","    mean_silence: 0.15\n","    mean_silence_var: 0.01\n","    per_silence_var: 900\n","    per_silence_min: 0.0\n","    per_silence_max: -1\n","    mean_overlap: 0.1\n","    mean_overlap_var: 0.01\n","    per_overlap_var: 900\n","    per_overlap_min: 0.0\n","    per_overlap_max: -1\n","    start_window: true\n","    window_type: hamming\n","    window_size: 0.05\n","    start_buffer: 0.1\n","    split_buffer: 0.1\n","    release_buffer: 0.1\n","    normalize: true\n","    normalization_type: equal\n","    normalization_var: 0.1\n","    min_volume: 0.75\n","    max_volume: 1.25\n","    end_buffer: 0.5\n","  outputs:\n","    output_dir: ???\n","    output_filename: multispeaker_session\n","    overwrite_output: true\n","    output_precision: 3\n","  background_noise:\n","    add_bg: false\n","    background_manifest: null\n","    num_noise_files: 10\n","    snr: 60\n","    snr_min: null\n","    snr_max: null\n","  segment_augmentor:\n","    add_seg_aug: false\n","    augmentor:\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","  session_augmentor:\n","    add_sess_aug: false\n","    augmentor:\n","      white_noise:\n","        prob: 1.0\n","        min_level: -90\n","        max_level: -46\n","  speaker_enforcement:\n","    enforce_num_speakers: true\n","    enforce_time:\n","    - 0.25\n","    - 0.75\n","  segment_manifest:\n","    window: 0.5\n","    shift: 0.25\n","    step_count: 50\n","    deci: 3\n","  rir_generation:\n","    use_rir: false\n","    toolkit: pyroomacoustics\n","    room_config:\n","      room_sz:\n","      - - 2\n","        - 3\n","      - - 2\n","        - 3\n","      - - 2\n","        - 3\n","      pos_src:\n","      - - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","      - - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","      - - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","      - - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","      noise_src_pos:\n","      - 1.5\n","      - 1.5\n","      - 2\n","    mic_config:\n","      num_channels: 2\n","      pos_rcv:\n","      - - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","      - - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","        - - 0.5\n","          - 1.5\n","      orV_rcv: null\n","      mic_pattern: omni\n","    absorbtion_params:\n","      abs_weights:\n","      - 0.9\n","      - 0.9\n","      - 0.9\n","      - 0.9\n","      - 0.9\n","      - 0.9\n","      T60: 0.1\n","      att_diff: 15.0\n","      att_max: 60.0\n","\n"]}],"source":["from omegaconf import OmegaConf\n","import os\n","ROOT = os.getcwd()\n","conf_dir = os.path.join(ROOT,'conf')\n","!mkdir -p $conf_dir\n","CONFIG_PATH = os.path.join(conf_dir, 'data_simulator.yaml')\n","if not os.path.exists(CONFIG_PATH):\n","  !wget -P $conf_dir https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/tools/speech_data_simulator/conf/data_simulator.yaml\n","\n","config = OmegaConf.load(CONFIG_PATH)\n","print(OmegaConf.to_yaml(config))"]},{"cell_type":"markdown","metadata":{"id":"EmZvtkPo_20v"},"source":["#### Data Simulation Step 4:   Generate Simulated Audio Session\n","\n","We will generate a set of example sessions with the following specifications:\n","\n","- 3 example sessions for train  \n","- 3 example sessions for validation\n","- 2-speakers in each session\n","- 60 seconds of recordings\n","\n","We need to setup different seed for train and validation sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RM-Sj36y_20v"},"outputs":[],"source":["from nemo.collections.asr.data.data_simulation import MultiSpeakerSimulator\n","\n","# Generate train set\n","ROOT = os.getcwd()\n","data_dir = os.path.join(ROOT,'simulated_train')\n","config.data_simulator.random_seed=10\n","config.data_simulator.manifest_filepath=\"./dev-clean-align.json\"\n","config.data_simulator.outputs.output_dir=data_dir\n","config.data_simulator.session_config.num_sessions=3\n","config.data_simulator.session_config.num_speakers=2\n","config.data_simulator.session_config.session_length=60\n","config.data_simulator.background_noise.add_bg=False\n","\n","lg = MultiSpeakerSimulator(cfg=config)\n","lg.generate_sessions()\n","\n","# Generate validation set\n","data_dir = os.path.join(ROOT,'simulated_valid')\n","config.data_simulator.random_seed=20\n","config.data_simulator.outputs.output_dir=data_dir\n","\n","lg = MultiSpeakerSimulator(cfg=config)\n","lg.generate_sessions()"]},{"cell_type":"markdown","metadata":{"id":"CCG0V8XU_20w"},"source":["Now that parameter setting is done, generate the samples by launching `generate_sessions()`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zA63PQxh_20w"},"outputs":[],"source":["lg = MultiSpeakerSimulator(cfg=config)\n","lg.generate_sessions()"]},{"cell_type":"markdown","metadata":{"id":"xZ8ba6Hb_20w"},"source":["### Data preparation step 5: Listen to and Visualize Session\n","\n","Listen to the audio and visualize the corresponding speaker timestamps (recorded in a RTTM file for each session)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sgogG8SR_20x","scrolled":true},"outputs":[],"source":["import os\n","import wget\n","import IPython\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import librosa\n","from nemo.collections.asr.parts.utils.speaker_utils import rttm_to_labels, labels_to_pyannote_object\n","\n","ROOT = os.getcwd()\n","data_dir = os.path.join(ROOT,'simulated_train')\n","audio = os.path.join(data_dir,'multispeaker_session_0.wav')\n","rttm = os.path.join(data_dir,'multispeaker_session_0.rttm')\n","\n","sr = 16000\n","signal, sr = librosa.load(audio,sr=sr)\n","\n","fig,ax = plt.subplots(1,1)\n","fig.set_figwidth(20)\n","fig.set_figheight(2)\n","plt.plot(np.arange(len(signal)),signal,'gray')\n","fig.suptitle('Synthetic Audio Session', fontsize=16)\n","plt.xlabel('Time (s)', fontsize=18)\n","plt.yticks([], [])\n","ax.margins(x=0)\n","a,_ = plt.xticks()\n","plt.xticks(a[:-1],a[:-1]/sr);\n","IPython.display.Audio(audio)"]},{"cell_type":"markdown","metadata":{"id":"3ae_l2rL_20x"},"source":["We can visually check the ground-truth file of the first sample by running the following commands. We can see that it has plenty of overlap between two speakers."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jbaaaEpx_20x"},"outputs":[],"source":["# display speaker labels for reference\n","labels = rttm_to_labels(rttm)\n","reference = labels_to_pyannote_object(labels)\n","reference"]},{"cell_type":"markdown","metadata":{"id":"jvbfO9wD_20y"},"source":["You can check that corresponding RTTM files are generated as ground-truth labels for training and evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HIbOIC69_20y"},"outputs":[],"source":["!cat simulated_train/multispeaker_session_0.rttm | head -10"]},{"cell_type":"markdown","metadata":{"id":"rxgFkfnF_20y"},"source":["### Data preparation step 6: Check out the created files\n","\n","The following files are generated from data simulator:\n","\n","* _wav files_ (one per audio session) - the output audio sessions\n","* _rttm files_ (one per audio session) - the speaker timestamps for the corresponding audio session (used for diarization training)\n","* _list files_ (one per file type per batch of sessions) - a list of generated files of the given type (e.g., wav, rttm), used primarily for manifest creation\n","\n","Check if the files we need are generated by running the following commands."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TQMA_2fJ_20z"},"outputs":[],"source":["print(\"\\n Training audio files:\")\n","!ls simulated_train/*.wav\n","print(\"\\n Training audio files:\")\n","!ls simulated_train/*.rttm\n","print(\"\\n Training RTTM list content:\")\n","!cat simulated_train/synthetic_wav.list\n","print(\"\\n Training RTTM list content:\")\n","!cat simulated_train/synthetic_rttm.list\n","\n","print(\"\\n Validation audio files:\")\n","!ls simulated_valid/*.wav\n","print(\"\\n Validation audio files:\")\n","!ls simulated_valid/*.rttm\n","print(\"\\n Validation RTTM list content:\")\n","!cat simulated_valid/synthetic_wav.list\n","print(\"\\n Validation RTTM list content:\")\n","!cat simulated_valid/synthetic_rttm.list"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26037,"status":"ok","timestamp":1717453776904,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"KBR2KgU1COIv","outputId":"70f2da25-e49a-4cd2-e4df-9b6c3fc986e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"c2-Eod0B_20z"},"source":["## Prepare Training Data for MSDD"]},{"cell_type":"markdown","metadata":{"id":"ebrTRLjT_20z"},"source":["Now that we have datasets for both train and validation (dev), we can start preparing and cleaning the data samples for training. Make sure you have the following list of files:\n","\n","**Training set**\n","\n","- Train audio files `.wav`\n","- A train audio list file `.list`\n","- Train RTTM files `.rttm`\n","- A train RTTM list content `.list`\n","\n","**Validation set**  \n","\n","- Validation audio files `.wav`\n","- A validation audio list file `.list`\n","- Validation RTTM files `.rttm`\n","- A validation RTTM list file `.list`\n","\n","\n","Based on these files, we need to create manifest files containing data samples we have. If you don't have a `.list` file, you need to create a `.list` file for the `.wav` files and `.rttm` files."]},{"cell_type":"markdown","metadata":{"id":"GDijn1FgODdn"},"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":487,"status":"ok","timestamp":1717453735072,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"nUHuQivVOD2Q","outputId":"6473417f-211a-442a-e3b6-815087b344e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["NeMo  sample_data\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2440,"status":"ok","timestamp":1717454011671,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"i4bxCuleDhQG","outputId":"b27efdaf-148f-48cb-c67f-74d59ea95aab"},"outputs":[{"name":"stdout","output_type":"stream","text":["drive  NeMo  sample_data\n"]}],"source":["# Creating split for training and validation\n","import os\n","from sklearn.model_selection import train_test_split\n","import shutil\n","\n","# Define the input directory\n","\n","input_dir = 'drive/Shareddrives/CS224S/CS224S_Final_Project/data/all_audio'\n","output_dir = 'drive/Shareddrives/CS224S/CS224S_Final_Project/data/splits/multilingual'\n","\n","!ls\n","#input_dir = '/content/drive/My Drive/CS224S_Final_Project/data/all_audio'\n","#output_dir = '/content/drive/My Drive/CS224S_Final_Project/data/splits/multilingual'\n","\n","# List all files in the input directory\n","files = [f for f in os.listdir(input_dir) if os.path.isfile(os.path.join(input_dir, f))]\n","\n","# Split the files into training and validation sets\n","train_files, temp_files = train_test_split(files, test_size=0.3, random_state=1337)\n","test_files, val_files = train_test_split(temp_files, test_size=0.33, random_state=1337)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":1611,"status":"ok","timestamp":1717454015106,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"o_yvO3DiXuT7"},"outputs":[],"source":["# Writting .list files for audio\n","\n","# Define the output .lst file paths\n","train_lst_file = '/content/drive/My Drive/CS224S_Final_Project/data/splits/Multilingual/train_audio.lst'\n","test_lst_file = '/content/drive/My Drive/CS224S_Final_Project/data/splits/Multilingual/test_audio.lst'\n","val_lst_file = '/content/drive/My Drive/CS224S_Final_Project/data/splits/Multilingual/val_audio.lst'\n","\n","# Function to write file names to .lst file\n","def write_lst_file(file_list, lst_file):\n","    with open(lst_file, 'w') as f:\n","        for file_name in file_list:\n","            f.write('/content/drive/MyDrive/CS224S_Final_Project/data/all_audio' + '/' + file_name + '\\n')\n","\n","# Write file names to .lst files\n","write_lst_file(train_files, train_lst_file)\n","write_lst_file(val_files, val_lst_file)\n","write_lst_file(test_files, test_lst_file)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1400,"status":"ok","timestamp":1717454018698,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"r1HG71_vZv4n"},"outputs":[],"source":["# Writting .list files for rttm\n","# Define the output .lst file paths\n","train_lst_file = '/content/drive/My Drive/CS224S_Final_Project/data/splits/Multilingual/train_rttm.lst'\n","test_lst_file = '/content/drive/My Drive/CS224S_Final_Project/data/splits/Multilingual/test_rttm.lst'\n","val_lst_file = '/content/drive/My Drive/CS224S_Final_Project/data/splits/Multilingual/val_rttm.lst'\n","\n","# Function to write file names to .lst file\n","def write_lst_file(file_list, lst_file):\n","    with open(lst_file, 'w') as f:\n","        for file_name in file_list:\n","            file_name = file_name.replace('.wav','.rttm')\n","            f.write('/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed' + '/' + file_name + '\\n')\n","\n","# Write file names to .lst files\n","write_lst_file(train_files, train_lst_file)\n","write_lst_file(val_files, val_lst_file)\n","write_lst_file(test_files, test_lst_file)"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":62702,"status":"ok","timestamp":1717454081783,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"-YD-yK0n_200"},"outputs":[],"source":["# Define the path to the JSON file\n","train_manifest = '/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_manifest.json'\n","\n","# Open the file in write mode\n","with open(train_manifest, 'w') as f:\n","    pass  # Do nothing\n","\n","# create a NeMo manifest (.json) file for training dataset\n","!python NeMo/scripts/speaker_tasks/pathfiles_to_diarize_manifest.py \\\n","  --paths2audio_files='/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_audio.lst' \\\n","  --paths2rttm_files='/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm.lst' \\\n","  --manifest_filepath={train_manifest}\n","\n","val_manifest = '/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_manifest.json'\n","\n","# Open the file in write mode\n","with open(val_manifest, 'w') as f:\n","    pass  # Do nothing\n","\n","# create a NeMo manifest (.json) file for validation (dev) dataset\n","!python NeMo/scripts/speaker_tasks/pathfiles_to_diarize_manifest.py \\\n","  --paths2audio_files='/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_audio.lst' \\\n","  --paths2rttm_files='/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm.lst' \\\n","  --manifest_filepath={val_manifest}"]},{"cell_type":"markdown","metadata":{"id":"u8cGMkk4_200"},"source":["If you print the content of the created manifest file, you can see that `.rttm` files in the list and `.wav` files are grouped together in the generated manifest files."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":194,"status":"ok","timestamp":1717454081969,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"RzKujDog_200","outputId":"7f63834d-15a9-4cc7-a001-9ad6171af00e"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n"," An example line in training dataset manifest file:\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/1001lv01.wav\", \"offset\": 0, \"duration\": null, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 3, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/1001lv01.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","\n"," An example line in validation Dataset manifest file:\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/1001lv05.wav\", \"offset\": 0, \"duration\": null, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 3, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/1001lv05.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n"]}],"source":["print(\"\\n An example line in training dataset manifest file:\")\n","!cat '/content/drive/My Drive/CS224S_Final_Project/data/splits/Multilingual/train_manifest.json'| head -1\n","print(\"\\n An example line in validation Dataset manifest file:\")\n","!cat '/content/drive/My Drive/CS224S_Final_Project/data/splits/Multilingual/val_manifest.json'| head -1"]},{"cell_type":"markdown","metadata":{"id":"R16JNmN9_200"},"source":["Now that we have input a standard manifest file, we need to break down each audio clip into short audio clips so that we can put several samples in a batch.\n","\n","Before we generate a manifest file and RTTM files for training MSDD, you have to determine:\n","\n","- `window`: the window length of the base scale (the shortest scale)\n","- `shift`: the hop-length of the base scale (the shortest scale)\n","- `step_count`: how many decision steps in one data sample\n","\n","Note that these numbers should match the parameters in the configurations for your desired MSDD model. If you want to train with new parameters (`window`, `shift` and `step_count`), you need to make new manifest files with the new parameters."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35018,"status":"ok","timestamp":1717454402512,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"K0naCHwy_201","outputId":"4f5d7271-84ae-4951-c565-cf22ff114bb5"},"outputs":[{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-06-03 22:35:00 speaker_utils:93] Number of files to diarize: 98\n","[NeMo I 2024-06-03 22:35:00 create_msdd_train_dataset:88] Creating split RTTM files.\n","100% 98/98 [03:04\u003c00:00,  1.88s/it]\n","[NeMo I 2024-06-03 22:38:50 create_msdd_train_dataset:159] Creating subsegments.\n","[NeMo I 2024-06-03 22:39:31 speaker_utils:93] Number of files to diarize: 14\n","[NeMo I 2024-06-03 22:39:31 create_msdd_train_dataset:88] Creating split RTTM files.\n","100% 14/14 [00:30\u003c00:00,  2.19s/it]\n","[NeMo I 2024-06-03 22:40:08 create_msdd_train_dataset:159] Creating subsegments.\n"]}],"source":["# Define the path to new JSON file\n","new_train_manifest = '/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/manifest_train_50step.json'\n","\n","# Open the file in write mode\n","with open(new_train_manifest, 'w') as f:\n","    pass  # Do nothing\n","\n","# create a manifest (.json) file for training dataset\n","!python NeMo/scripts/speaker_tasks/create_msdd_train_dataset.py \\\n","  --input_manifest_path='/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_manifest.json' \\\n","  --output_manifest_path='/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/manifest_train_50step.json' \\\n","  --pairwise_rttm_output_folder='/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm_output_folder' \\\n","  --window 0.5 \\\n","  --shift 0.25 \\\n","  --step_count 50\n","\n","new_val_manifest = '/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/manifest_val_50step.json'\n","\n","# Open the file in write mode\n","with open(new_val_manifest, 'w') as f:\n","    pass  # Do nothing\n","\n","# create a manifest (.json) file for validation (dev) dataset\n","!python NeMo/scripts/speaker_tasks/create_msdd_train_dataset.py \\\n","  --input_manifest_path='/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_manifest.json' \\\n","  --output_manifest_path='/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/manifest_val_50step.json' \\\n","  --pairwise_rttm_output_folder='/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm_output_folder' \\\n","  --window 0.5 \\\n","  --shift 0.25 \\\n","  --step_count 50"]},{"cell_type":"markdown","metadata":{"id":"7cfc9BnI_201"},"source":["Now that we broke down the training and validation dataset into 50-step samples, let's checkout how the output manifest files look like. We used 0.25 second of shift length so in theory, if there is no silence or pause in the data, the length of data sample should be `step_count*shift` which is `50*0.25=12.5` second in the example we used. However, since there are pauses between the segments in practice, the final lengths of data samples are longer than 12.5 second."]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":227,"status":"ok","timestamp":1717454402731,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"UAUJUmnA_201","outputId":"4343485c-7e12-4cc7-d6cb-8f7f607992bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Training Dataset:\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/TK09101800.wav\", \"offset\": 1087.53, \"duration\": 226.79, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 4, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm_output_folder/TK09101800.S_SS.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/TK09101800.wav\", \"offset\": 1313.82, \"duration\": 90.69, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 4, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm_output_folder/TK09101800.S_SS.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/TK09101800.wav\", \"offset\": 1404.01, \"duration\": 78.37, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 4, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm_output_folder/TK09101800.S_SS.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/TK09101800.wav\", \"offset\": 1481.88, \"duration\": 242.84, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 4, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm_output_folder/TK09101800.S_SS.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/TK09101800.wav\", \"offset\": 1724.22, \"duration\": 82.61, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 4, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm_output_folder/TK09101800.S_SS.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/TK09101800.wav\", \"offset\": 1806.33, \"duration\": 145.49, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 4, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm_output_folder/TK09101800.S_SS.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/TK09101800.wav\", \"offset\": 1951.32, \"duration\": 91.96, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 4, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm_output_folder/TK09101800.S_SS.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/TK09101800.wav\", \"offset\": 2042.78, \"duration\": 157.28, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 4, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm_output_folder/TK09101800.S_SS.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/TK09101800.wav\", \"offset\": 2199.56, \"duration\": 194.21, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 4, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm_output_folder/TK09101800.S_SS.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/TK09101800.wav\", \"offset\": 2393.27, \"duration\": 207.54, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 4, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_rttm_output_folder/TK09101800.S_SS.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","\n","Validation Dataset:\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/CC11241853.wav\", \"offset\": 1744.24, \"duration\": 13.43, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 6, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm_output_folder/CC11241853.SS_O.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/CC11241853.wav\", \"offset\": 1757.17, \"duration\": 18.57, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 6, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm_output_folder/CC11241853.SS_O.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/CC11241853.wav\", \"offset\": 1775.24, \"duration\": 30.42, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 6, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm_output_folder/CC11241853.SS_O.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/CC11241853.wav\", \"offset\": 1805.16, \"duration\": 21.33, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 6, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm_output_folder/CC11241853.SS_O.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/CC11241853.wav\", \"offset\": 1825.99, \"duration\": 84.55, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 6, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm_output_folder/CC11241853.SS_O.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/CC11241853.wav\", \"offset\": 1910.04, \"duration\": 17.66, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 6, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm_output_folder/CC11241853.SS_O.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/CC11241853.wav\", \"offset\": 1927.2, \"duration\": 13.16, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 6, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm_output_folder/CC11241853.SS_O.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/CC11241853.wav\", \"offset\": 1939.86, \"duration\": 26.49, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 6, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm_output_folder/CC11241853.SS_O.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/CC11241853.wav\", \"offset\": 1965.85, \"duration\": 16.08, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 6, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm_output_folder/CC11241853.SS_O.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n","{\"audio_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/all_audio/CC11241853.wav\", \"offset\": 1981.43, \"duration\": 13.59, \"label\": \"infer\", \"text\": \"-\", \"num_speakers\": 6, \"rttm_filepath\": \"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_rttm_output_folder/CC11241853.SS_O.rttm\", \"uem_filepath\": null, \"ctm_filepath\": null}\n"]}],"source":["print(\"\\nTraining Dataset:\")\n","!cat '/content/drive/My Drive/CS224S_Final_Project/data/splits/Multilingual/manifest_train_50step.json' | tail -10\n","print(\"\\nValidation Dataset:\")\n","!cat '/content/drive/My Drive/CS224S_Final_Project/data/splits/Multilingual/manifest_val_50step.json' | tail -10"]},{"cell_type":"markdown","metadata":{"id":"i6crIjur_202"},"source":["## Train an MSDD Model"]},{"cell_type":"markdown","metadata":{"id":"f3sNmF_D_202"},"source":["Now that we have prepared all the necessary dataset, we can train an MSDD model on the prepared dataset. Download YAML file for training form NeMo repository and load the configuration into `config` variable."]},{"cell_type":"markdown","metadata":{"id":"hFnxSrXFuGUS"},"source":["Script to Find Empty RTTM files"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717454402732,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"g8r4QEc2aOmz","outputId":"10ff456d-4b8a-48cf-d660-4b9ecca00b84"},"outputs":[{"name":"stdout","output_type":"stream","text":["Empty RTTM files found:\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7001jp103.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7004jp404.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7002jp205.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7002jp203.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/2010cz306.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7002jp202.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/5003lv06.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7001jp101.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7003jp303.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7004jp401.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7001jp106.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7003jp301.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7001jp102.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7004jp402.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7004jp403.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/2004cz202.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/2004cz206.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7001jp104.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7003jp304.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7002jp206.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7002jp201.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7004jp407.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7003jp306.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7003jp305.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7002jp204.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7004jp405.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7001jp105.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7004jp406.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/2004cz205.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/2004cz203.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/7003jp302.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/1004lv202.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/2004cz201.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/2004cz204.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/3002lv03.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/3002lv02.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/4012nl406.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/1004lv101.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/3001lv105.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/2001cz106.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/3002lv05.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/3002lv01.rttm\n","/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed/3002lv04.rttm\n"]}],"source":["import os\n","\n","def check_empty_rttm_files(rttm_dir):\n","    # List to store names of empty RTTM files\n","    empty_files = []\n","\n","    # Loop through all files in the RTTM directory\n","    for root, _, files in os.walk(rttm_dir):\n","        for file in files:\n","            if file.endswith('.rttm'):\n","                file_path = os.path.join(root, file)\n","\n","                # Check if the file is empty\n","                if os.path.getsize(file_path) == 0:\n","                    empty_files.append(file_path)\n","\n","    return empty_files\n","\n","rttm_dir = '/content/drive/MyDrive/CS224S_Final_Project/data/all_annotations/rttm_dir_fixed'  # Replace with your RTTM directory path\n","\n","# Get the list of empty RTTM files\n","empty_rttm_files = check_empty_rttm_files(rttm_dir)\n","\n","if empty_rttm_files:\n","    print(\"Empty RTTM files found:\")\n","    for file in empty_rttm_files:\n","        print(file)\n","else:\n","    print(\"No empty RTTM files found.\")\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5929,"status":"ok","timestamp":1717454408660,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"6hhLA4UY_202","outputId":"cd4b1811-42f8-4e29-e1f1-fc4de6b58142"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2024-06-03 22:40:20--  https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/neural_diarizer/msdd_5scl_15_05_50Povl_256x3x32x2.yaml\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5621 (5.5K) [text/plain]\n","Saving to: ‘conf/msdd_5scl_15_05_50Povl_256x3x32x2.yaml’\n","\n","\r          msdd_5scl   0%[                    ]       0  --.-KB/s               \rmsdd_5scl_15_05_50P 100%[===================\u003e]   5.49K  --.-KB/s    in 0s      \n","\n","2024-06-03 22:40:21 (75.0 MB/s) - ‘conf/msdd_5scl_15_05_50Povl_256x3x32x2.yaml’ saved [5621/5621]\n","\n","name: MultiscaleDiarDecoder\n","sample_rate: 16000\n","num_workers: 20\n","batch_size: 7\n","model:\n","  diarizer:\n","    out_dir: null\n","    oracle_vad: true\n","    speaker_embeddings:\n","      model_path: ???\n","      parameters:\n","        window_length_in_sec:\n","        - 1.5\n","        - 1.25\n","        - 1.0\n","        - 0.75\n","        - 0.5\n","        shift_length_in_sec:\n","        - 0.75\n","        - 0.625\n","        - 0.5\n","        - 0.375\n","        - 0.25\n","        multiscale_weights:\n","        - 1\n","        - 1\n","        - 1\n","        - 1\n","        - 1\n","        save_embeddings: true\n","  num_workers: ${num_workers}\n","  max_num_of_spks: 2\n","  scale_n: 5\n","  soft_label_thres: 0.5\n","  emb_batch_size: 0\n","  train_ds:\n","    manifest_filepath: ???\n","    emb_dir: ???\n","    sample_rate: ${sample_rate}\n","    num_spks: ${model.max_num_of_spks}\n","    soft_label_thres: ${model.soft_label_thres}\n","    labels: null\n","    batch_size: ${batch_size}\n","    emb_batch_size: ${model.emb_batch_size}\n","    shuffle: true\n","  validation_ds:\n","    manifest_filepath: ???\n","    emb_dir: ???\n","    sample_rate: ${sample_rate}\n","    num_spks: ${model.max_num_of_spks}\n","    soft_label_thres: ${model.soft_label_thres}\n","    labels: null\n","    batch_size: 2\n","    emb_batch_size: ${model.emb_batch_size}\n","    shuffle: false\n","  test_ds:\n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: ${model.max_num_of_spks}\n","    soft_label_thres: ${model.soft_label_thres}\n","    labels: null\n","    batch_size: 2\n","    shuffle: false\n","    seq_eval_mode: false\n","  preprocessor:\n","    _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor\n","    normalize: per_feature\n","    window_size: 0.025\n","    sample_rate: ${sample_rate}\n","    window_stride: 0.01\n","    window: hann\n","    features: 80\n","    n_fft: 512\n","    frame_splicing: 1\n","    dither: 1.0e-05\n","  msdd_module:\n","    _target_: nemo.collections.asr.modules.msdd_diarizer.MSDD_module\n","    num_spks: ${model.max_num_of_spks}\n","    hidden_size: 256\n","    num_lstm_layers: 3\n","    dropout_rate: 0.5\n","    cnn_output_ch: 32\n","    conv_repeat: 2\n","    emb_dim: 192\n","    scale_n: ${model.scale_n}\n","    weighting_scheme: conv_scale_weight\n","    context_vector_type: cos_sim\n","  loss:\n","    _target_: nemo.collections.asr.losses.bce_loss.BCELoss\n","    weight: null\n","  optim:\n","    name: adam\n","    lr: 0.001\n","    weight_decay: 0.001\n","    sched:\n","      name: CosineAnnealing\n","      min_lr: 1.0e-05\n","trainer:\n","  devices: 1\n","  accelerator: gpu\n","  max_epochs: 200\n","  max_steps: -1\n","  num_nodes: 1\n","  strategy: ddp\n","  accumulate_grad_batches: 1\n","  deterministic: true\n","  enable_checkpointing: false\n","  logger: false\n","  log_every_n_steps: 1\n","  val_check_interval: 1.0\n","exp_manager:\n","  exp_dir: null\n","  name: ${name}\n","  create_tensorboard_logger: true\n","  create_checkpoint_callback: true\n","  create_wandb_logger: false\n","  checkpoint_callback_params:\n","    monitor: val_loss\n","    mode: min\n","    save_top_k: 30\n","    every_n_epochs: 1\n","  wandb_logger_kwargs:\n","    name: null\n","    project: null\n","\n"]}],"source":["import nemo\n","import nemo.collections.asr as nemo_asr\n","from omegaconf import OmegaConf\n","\n","NEMO_ROOT = os.getcwd()\n","!mkdir conf\n","!wget -P conf https://raw.githubusercontent.com/NVIDIA/NeMo/$BRANCH/examples/speaker_tasks/diarization/conf/neural_diarizer/msdd_5scl_15_05_50Povl_256x3x32x2.yaml\n","MODEL_CONFIG = os.path.join(NEMO_ROOT,'conf/msdd_5scl_15_05_50Povl_256x3x32x2.yaml')\n","config = OmegaConf.load(MODEL_CONFIG)\n","print(OmegaConf.to_yaml(config))"]},{"cell_type":"markdown","metadata":{"id":"oXRKq7fm_203"},"source":["Setup the `manifest_filepath` for `train_ds` and `validation_ds` by feeding the `json` file paths from `create_msdd_train_dataset.py`."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1717454408660,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"AuvBdQ4y_203"},"outputs":[],"source":["config.model.train_ds.manifest_filepath = new_train_manifest\n","config.model.validation_ds.manifest_filepath = new_val_manifest"]},{"cell_type":"markdown","metadata":{"id":"7N9NwGf5_203"},"source":["### Train MSDD with frozen speaker embedding model"]},{"cell_type":"markdown","metadata":{"id":"G9U2r6ZQ_203"},"source":["Provide a batch size number for training in `config.model.batch_size`. In a batch, we will assign the given number of split samples (in this example, 50 step-size). Note that you might need to change this batch size if the following batch size maxes out your GPU memory size.\n","\n","`config.model.emb_batch_size` determines the number of embedding vectors attached to a computational graph. This means that\n","If you want to freeze the speaker embedding extractor, you should set `emb_batch_size=0`.\n","If you want to jointly optimize speaker embedding extractor, you need to assign an adequate number that does not max out the GPU memory."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1717454408661,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"ejlir2pg_204"},"outputs":[],"source":["config.batch_size=5\n","config.model.emb_batch_size=0"]},{"cell_type":"markdown","metadata":{"id":"FKUUcfbi_204"},"source":["Provide paths to the temporary folders for saving timestamp data during training."]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1717454408661,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"1d9S4JY9_204"},"outputs":[],"source":["config.model.train_ds.emb_dir=\"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps\"\n","config.model.validation_ds.emb_dir=\"/content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps\""]},{"cell_type":"markdown","metadata":{"id":"ghuBWcFz_204"},"source":["Setup a speaker embedding model that will be used for speaker embedding extraction. We will use `titanet_large` model checkpoint from NGC. Note that this speaker embedding model will be saved together in a `.ckpt` file whenever pytorch lightning trainer saves checkpoint."]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":197,"status":"ok","timestamp":1717454408857,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"4r-HVUDQ_205"},"outputs":[],"source":["config.model.diarizer.speaker_embeddings.model_path=\"titanet_large\"\n","config.trainer.max_epochs = 5\n","config.trainer.strategy = 'auto'"]},{"cell_type":"markdown","metadata":{"id":"PwUQi_o5_205"},"source":["We will use `pytorch_lightning` and train a model instance from class `EncDecDiarLabelModel`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"jRnvPLJQ_205"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n","INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n","INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n","INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n","INFO:pytorch_lightning.utilities.rank_zero:`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-06-03 22:40:21 exp_manager:341] ExpManager schema\n","[NeMo I 2024-06-03 22:40:21 exp_manager:342] {'explicit_log_dir': None, 'exp_dir': None, 'name': None, 'version': None, 'use_datetime_version': True, 'resume_if_exists': False, 'resume_past_end': False, 'resume_ignore_no_checkpoint': False, 'resume_from_checkpoint': None, 'create_tensorboard_logger': True, 'summary_writer_kwargs': None, 'create_wandb_logger': False, 'wandb_logger_kwargs': None, 'create_mlflow_logger': False, 'mlflow_logger_kwargs': {'experiment_name': None, 'tracking_uri': None, 'tags': None, 'save_dir': './mlruns', 'prefix': '', 'artifact_location': None, 'run_id': None, 'log_model': False}, 'create_dllogger_logger': False, 'dllogger_logger_kwargs': {'verbose': False, 'stdout': False, 'json_file': './dllogger.json'}, 'create_clearml_logger': False, 'clearml_logger_kwargs': {'project': None, 'task': None, 'connect_pytorch': False, 'model_name': None, 'tags': None, 'log_model': False, 'log_cfg': False, 'log_metrics': False}, 'create_neptune_logger': False, 'neptune_logger_kwargs': None, 'create_checkpoint_callback': True, 'checkpoint_callback_params': {'filepath': None, 'dirpath': None, 'filename': None, 'monitor': 'val_loss', 'verbose': True, 'save_last': True, 'save_top_k': 3, 'save_weights_only': False, 'mode': 'min', 'auto_insert_metric_name': True, 'every_n_epochs': 1, 'every_n_train_steps': None, 'train_time_interval': None, 'prefix': None, 'postfix': '.nemo', 'save_best_model': False, 'always_save_nemo': False, 'save_nemo_on_train_end': True, 'model_parallel_size': None, 'save_on_train_epoch_end': False, 'async_save': False}, 'create_early_stopping_callback': False, 'early_stopping_callback_params': {'monitor': 'val_loss', 'mode': 'min', 'min_delta': 0.001, 'patience': 10, 'verbose': True, 'strict': True, 'check_finite': True, 'stopping_threshold': None, 'divergence_threshold': None, 'check_on_train_epoch_end': None, 'log_rank_zero_only': False}, 'create_preemption_callback': True, 'files_to_copy': None, 'log_step_timing': True, 'step_timing_kwargs': {'reduction': 'mean', 'sync_cuda': False, 'buffer_size': 1}, 'log_local_rank_0_only': False, 'log_global_rank_0_only': False, 'disable_validation_on_resume': True, 'ema': {'enable': False, 'decay': 0.999, 'cpu_offload': False, 'validate_original_weights': False, 'every_n_steps': 1}, 'max_time_per_run': None, 'seconds_to_sleep': 5.0}\n","[NeMo I 2024-06-03 22:40:21 exp_manager:400] Experiments will be logged at /content/nemo_experiments/MultiscaleDiarDecoder/2024-06-03_22-40-21\n","[NeMo I 2024-06-03 22:40:21 exp_manager:860] TensorboardLogger has been set up\n","[NeMo I 2024-06-03 22:41:54 collections:1056] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-06-03 22:41:54 collections:1060] Total 21333 session files loaded accounting to # 21333 audio clips\n","[NeMo I 2024-06-03 22:41:55 speaker_utils:93] Number of files to diarize: 21333\n","[NeMo I 2024-06-03 22:41:55 speaker_utils:1468] Extracting oracle VAD timestamps and saving at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps/speaker_outputs\n","[NeMo I 2024-06-03 22:50:52 speaker_utils:1486] Subsegmentation for timestamp extracted for: scale-0 at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-06-03 22:50:52 speaker_utils:1507] Extracting timestamps from /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps/speaker_outputs/subsegments_scale0.json for multiscale subsegmentation.\n","[NeMo I 2024-06-03 22:51:02 speaker_utils:1486] Subsegmentation for timestamp extracted for: scale-1 at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-06-03 22:51:02 speaker_utils:1507] Extracting timestamps from /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps/speaker_outputs/subsegments_scale1.json for multiscale subsegmentation.\n","[NeMo I 2024-06-03 22:51:14 speaker_utils:1486] Subsegmentation for timestamp extracted for: scale-2 at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-06-03 22:51:14 speaker_utils:1507] Extracting timestamps from /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps/speaker_outputs/subsegments_scale2.json for multiscale subsegmentation.\n","[NeMo I 2024-06-03 22:51:30 speaker_utils:1486] Subsegmentation for timestamp extracted for: scale-3 at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-06-03 22:51:30 speaker_utils:1507] Extracting timestamps from /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps/speaker_outputs/subsegments_scale3.json for multiscale subsegmentation.\n","[NeMo I 2024-06-03 22:51:54 speaker_utils:1486] Subsegmentation for timestamp extracted for: scale-4 at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-06-03 22:51:54 speaker_utils:1507] Extracting timestamps from /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/train_time_stamps/speaker_outputs/subsegments_scale4.json for multiscale subsegmentation.\n","[NeMo I 2024-06-03 22:52:15 collections:1056] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-06-03 22:52:15 collections:1060] Total 3666 session files loaded accounting to # 3666 audio clips\n","[NeMo I 2024-06-03 22:52:15 speaker_utils:93] Number of files to diarize: 3666\n","[NeMo I 2024-06-03 22:52:15 speaker_utils:1468] Extracting oracle VAD timestamps and saving at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps/speaker_outputs\n","[NeMo I 2024-06-03 22:53:37 speaker_utils:1486] Subsegmentation for timestamp extracted for: scale-0 at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-06-03 22:53:37 speaker_utils:1507] Extracting timestamps from /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps/speaker_outputs/subsegments_scale0.json for multiscale subsegmentation.\n","[NeMo I 2024-06-03 22:53:39 speaker_utils:1486] Subsegmentation for timestamp extracted for: scale-1 at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-06-03 22:53:39 speaker_utils:1507] Extracting timestamps from /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps/speaker_outputs/subsegments_scale1.json for multiscale subsegmentation.\n","[NeMo I 2024-06-03 22:53:41 speaker_utils:1486] Subsegmentation for timestamp extracted for: scale-2 at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-06-03 22:53:41 speaker_utils:1507] Extracting timestamps from /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps/speaker_outputs/subsegments_scale2.json for multiscale subsegmentation.\n","[NeMo I 2024-06-03 22:53:44 speaker_utils:1486] Subsegmentation for timestamp extracted for: scale-3 at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-06-03 22:53:44 speaker_utils:1507] Extracting timestamps from /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps/speaker_outputs/subsegments_scale3.json for multiscale subsegmentation.\n","[NeMo I 2024-06-03 22:53:49 speaker_utils:1486] Subsegmentation for timestamp extracted for: scale-4 at /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-06-03 22:53:49 speaker_utils:1507] Extracting timestamps from /content/drive/MyDrive/CS224S_Final_Project/data/splits/Multilingual/val_time_stamps/speaker_outputs/subsegments_scale4.json for multiscale subsegmentation.\n","[NeMo I 2024-06-03 22:53:49 features:305] PADDING: 16\n","[NeMo I 2024-06-03 22:53:50 msdd_models:203] Loading pretrained titanet_large model from NGC\n","[NeMo I 2024-06-03 22:53:50 cloud:68] Downloading from: https://api.ngc.nvidia.com/v2/models/nvidia/nemo/titanet_large/versions/v1/files/titanet-l.nemo to /root/.cache/torch/NeMo/NeMo_2.0.0rc1/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n","[NeMo I 2024-06-03 22:53:52 common:826] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-06-03 22:53:52 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 64\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      noise:\n","        manifest_path: /manifests/noise/rir_noise_manifest.json\n","        prob: 0.5\n","        min_snr_db: 0\n","        max_snr_db: 15\n","      speed:\n","        prob: 0.5\n","        sr: 16000\n","        resample_type: kaiser_fast\n","        min_speed_rate: 0.95\n","        max_speed_rate: 1.05\n","    num_workers: 15\n","    pin_memory: true\n","    \n","[NeMo W 2024-06-03 22:53:52 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n","    sample_rate: 16000\n","    labels: null\n","    batch_size: 128\n","    shuffle: false\n","    num_workers: 15\n","    pin_memory: true\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-06-03 22:53:52 features:305] PADDING: 16\n","[NeMo I 2024-06-03 22:53:53 save_restore_connector:263] Model EncDecSpeakerLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_2.0.0rc1/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n"]}],"source":["import pytorch_lightning as pl\n","from nemo.collections.asr.models import EncDecDiarLabelModel\n","from nemo.utils.exp_manager import exp_manager\n","\n","trainer = pl.Trainer(**config.trainer)\n","exp_manager(trainer, config.get(\"exp_manager\", None))\n","msdd_model = EncDecDiarLabelModel(cfg=config.model, trainer=trainer)"]},{"cell_type":"markdown","metadata":{"id":"_WBeB-Kq_206"},"source":["Before we start training, let's check a few of the weights in the speaker embedding model in `msdd_model.msdd._speaker_model`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"4s3Td32F_206"},"outputs":[{"data":{"text/plain":["tensor([[-0.0577,  0.4153, -0.0502]], device='cuda:0')"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["msdd_model.msdd._speaker_model.state_dict()[\"encoder.encoder.0.mconv.0.conv.weight\"][0,:,:]"]},{"cell_type":"markdown","metadata":{"id":"G8olSEBU_206"},"source":["If you successfully ran the previous step, now it is ready to initiate a training session of MSDD. Launch `trainer.fit()` function for `msdd_model`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"CGWoBGxm_207"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-06-03 22:54:01 modelPT:770] Optimizer config = Adam (\n","    Parameter Group 0\n","        amsgrad: False\n","        betas: (0.9, 0.999)\n","        capturable: False\n","        differentiable: False\n","        eps: 1e-08\n","        foreach: None\n","        fused: None\n","        lr: 0.001\n","        maximize: False\n","        weight_decay: 0.001\n","    )\n","[NeMo I 2024-06-03 22:54:01 lr_scheduler:923] Scheduler \"\u003cnemo.core.optim.lr_scheduler.CosineAnnealing object at 0x7a8c7e562950\u003e\" \n","    will be used during training (effective maximum steps = 21335) - \n","    Parameters : \n","    (min_lr: 1.0e-05\n","    max_steps: 21335\n","    )\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.callbacks.model_summary:\n","  | Name            | Type                              | Params\n","----------------------------------------------------------------------\n","0 | preprocessor    | AudioToMelSpectrogramPreprocessor | 0     \n","1 | msdd            | MSDD_module                       | 31.1 M\n","2 | loss            | BCELoss                           | 0     \n","3 | _accuracy_test  | MultiBinaryAccuracy               | 0     \n","4 | _accuracy_train | MultiBinaryAccuracy               | 0     \n","5 | _accuracy_valid | MultiBinaryAccuracy               | 0     \n","----------------------------------------------------------------------\n","31.1 M    Trainable params\n","0         Non-trainable params\n","31.1 M    Total params\n","124.451   Total estimated model params size (MB)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b425c3e059be459eb2dadf3017c787b0","version_major":2,"version_minor":0},"text/plain":["Sanity Checking: |          | 0/? [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"RuntimeError","evalue":"stack expects each tensor to be equal size, but got [211920, 2] at entry 0 and [209008, 2914] at entry 1","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-20-50c0c1bd3834\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsdd_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainerStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 544\u001b[0;31m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[1;32m    545\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         )\n\u001b[0;32m--\u003e 580\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;31m# RUN THE TRAINER\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 987\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;31m# ----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1029\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0misolate_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1031\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1060\u001b[0;31m             \u001b[0mval_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_callback_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"on_sanity_check_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py\u001b[0m in \u001b[0;36m_decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mcontext_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mcontext_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 182\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mloop_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                     \u001b[0mdataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 128\u001b[0;31m                     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_fetcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mprevious_dataloader_idx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0;31m# the dataloader has changed, notify the logger connector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# this will run only when no pre-fetching was done.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 133\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# the iterator is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_profiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 60\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u003e\u001b[0m \u001b[0m_ITERATOR_RETURN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 341\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Sequential\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 142\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# try the next iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nemo/collections/asr/data/audio_to_diar_label.py\u001b[0m in \u001b[0;36mmsdd_train_collate_fn\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmsdd_train_collate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 787\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_msdd_train_collate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nemo/collections/asr/data/audio_to_diar_label.py\u001b[0m in \u001b[0;36m_msdd_train_collate_fn\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mtargets_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_tgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 673\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m     \u001b[0mfeature_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_length_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mms_seg_timestamps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mms_seg_timestamps_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [211920, 2] at entry 0 and [209008, 2914] at entry 1"]}],"source":["trainer.fit(msdd_model)"]},{"cell_type":"markdown","metadata":{"id":"wAZum_lj_207"},"source":["In this way, you can train an MSDD model and use `.ckpt` files saved during training process."]},{"cell_type":"markdown","metadata":{"id":"j86VVBjz_207"},"source":["Let's check the weights in speaker embedding model again and see if the numbers are changed."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eIXei_fx_208"},"outputs":[],"source":["msdd_model.msdd._speaker_model.state_dict()[\"encoder.encoder.0.mconv.0.conv.weight\"][0,:,:]"]},{"cell_type":"markdown","metadata":{"id":"j6KuTKEi_208"},"source":["### Train MSDD and speaker embedding model together"]},{"cell_type":"markdown","metadata":{"id":"LUHMt-aA_208"},"source":["In this time, let's attach a few speaker embeddings to a graph and jointly train the speaker embedding mode."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qWJplYiS_209"},"outputs":[],"source":["config.model.emb_batch_size = 100 # choose the largest number that does not max out GPU memory.\n","config.trainer.max_epochs = 5"]},{"cell_type":"markdown","metadata":{"id":"yjV4YxRo_209"},"source":["Setup another trainer and initiate a training session with the new parameters."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Q4nd1xAw_209"},"outputs":[],"source":["trainer = pl.Trainer(**config.trainer)\n","exp_manager(trainer, config.get(\"exp_manager\", None))\n","msdd_model = EncDecDiarLabelModel(cfg=config.model, trainer=trainer)\n","trainer.fit(msdd_model)"]},{"cell_type":"markdown","metadata":{"id":"pkM3qYTa_209"},"source":["Let's check whether there is a change in the weights."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"50LuOl28_20-"},"outputs":[],"source":["msdd_model.msdd._speaker_model.state_dict()[\"encoder.encoder.0.mconv.0.conv.weight\"][0,:,:]"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.7"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}