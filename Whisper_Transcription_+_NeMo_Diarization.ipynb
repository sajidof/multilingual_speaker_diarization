{"cells":[{"cell_type":"markdown","metadata":{"id":"eCmjcOc9yEtQ"},"source":["# Installing Dependencies"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57982,"status":"ok","timestamp":1717520496245,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"Tn1c-CoDv2kw","outputId":"48d6d666-8216-4f48-d4ba-5d13f8a0188f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/m-bain/whisperX.git@78dcfaab51005aa703ee21375f81ed31bc248560\n","  Cloning https://github.com/m-bain/whisperX.git (to revision 78dcfaab51005aa703ee21375f81ed31bc248560) to /tmp/pip-req-build-okyuozg6\n","  Running command git clone --filter=blob:none --quiet https://github.com/m-bain/whisperX.git /tmp/pip-req-build-okyuozg6\n","  Running command git rev-parse -q --verify 'sha^78dcfaab51005aa703ee21375f81ed31bc248560'\n","  Running command git fetch -q https://github.com/m-bain/whisperX.git 78dcfaab51005aa703ee21375f81ed31bc248560\n","  Running command git checkout -q 78dcfaab51005aa703ee21375f81ed31bc248560\n","  Resolved https://github.com/m-bain/whisperX.git to commit 78dcfaab51005aa703ee21375f81ed31bc248560\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (2.3.0+cu121)\n","Requirement already satisfied: torchaudio>=2 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (2.3.0+cu121)\n","Requirement already satisfied: faster-whisper==1.0.0 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (1.0.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (4.39.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (2.0.3)\n","Requirement already satisfied: setuptools>=65 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (67.7.2)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (3.8.1)\n","Requirement already satisfied: pyannote.audio==3.1.1 in /usr/local/lib/python3.10/dist-packages (from whisperx==3.1.1) (3.1.1)\n","Requirement already satisfied: av==11.* in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (11.0.0)\n","Requirement already satisfied: ctranslate2<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (4.2.1)\n","Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (0.23.2)\n","Requirement already satisfied: tokenizers<0.16,>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (0.15.2)\n","Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==1.0.0->whisperx==3.1.1) (1.18.0)\n","Requirement already satisfied: asteroid-filterbanks>=0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.4.0)\n","Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.8.0)\n","Requirement already satisfied: lightning>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.2.5)\n","Requirement already satisfied: omegaconf<3.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.3.0)\n","Requirement already satisfied: pyannote.core>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (5.0.0)\n","Requirement already satisfied: pyannote.database>=5.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (5.1.0)\n","Requirement already satisfied: pyannote.metrics>=3.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (3.2.1)\n","Requirement already satisfied: pyannote.pipeline>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.1)\n","Requirement already satisfied: pytorch-metric-learning>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.5.0)\n","Requirement already satisfied: rich>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (13.7.1)\n","Requirement already satisfied: semver>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.2)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.1)\n","Requirement already satisfied: speechbrain>=0.5.14 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (1.0.0)\n","Requirement already satisfied: tensorboardX>=2.6 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (2.6.2.2)\n","Requirement already satisfied: torch-audiomentations>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (0.11.1)\n","Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.0.post0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (4.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->whisperx==3.1.1) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->whisperx==3.1.1) (12.5.40)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx==3.1.1) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx==3.1.1) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx==3.1.1) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->whisperx==3.1.1) (4.66.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx==3.1.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx==3.1.1) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx==3.1.1) (2024.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->whisperx==3.1.1) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx==3.1.1) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx==3.1.1) (6.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx==3.1.1) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->whisperx==3.1.1) (0.4.3)\n","Requirement already satisfied: lightning-utilities<2.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (0.11.2)\n","Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.10/dist-packages (from lightning>=2.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.0.7)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf<3.0,>=2.1->pyannote.audio==3.1.1->whisperx==3.1.1) (4.9.3)\n","Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (15.0.1)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (3.20.3)\n","Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.4.0)\n","Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.core>=5.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.11.4)\n","Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.3)\n","Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.2)\n","Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.6.2)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.9.0)\n","Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.7.1)\n","Requirement already satisfied: optuna>=3.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (3.6.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->whisperx==3.1.1) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (2.16.1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.16.0)\n","Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.2)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.1.99)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->whisperx==3.1.1) (1.3.0)\n","Requirement already satisfied: julius<0.3,>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.2.7)\n","Requirement already satisfied: librosa>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.10.2.post1)\n","Requirement already satisfied: torch-pitch-shift>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->whisperx==3.1.1) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx==3.1.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx==3.1.1) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx==3.1.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->whisperx==3.1.1) (2024.2.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.22)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec->torch>=2->whisperx==3.1.1) (3.9.5)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.1)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.58.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.8.1)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.3.7)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.0.8)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.0.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.1.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (4.52.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.1.2)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.13.1)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (6.8.2)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (2.0.30)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->pyannote.metrics>=3.2->pyannote.audio==3.1.1->whisperx==3.1.1) (3.5.0)\n","Requirement already satisfied: primePy>=1.3 in /usr/local/lib/python3.10/dist-packages (from torch-pitch-shift>=1.2.2->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (1.3)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=5.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.5.4)\n","Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==1.0.0->whisperx==3.1.1) (10.0)\n","Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.10/dist-packages (from hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.18.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec->torch>=2->whisperx==3.1.1) (4.0.3)\n","Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (1.3.5)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (0.41.1)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa>=0.6.0->torch-audiomentations>=0.11.0->pyannote.audio==3.1.1->whisperx==3.1.1) (4.2.2)\n","Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain>=0.5.14->pyannote.audio==3.1.1->whisperx==3.1.1) (0.2.8)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna>=3.1->pyannote.pipeline>=3.0.1->pyannote.audio==3.1.1->whisperx==3.1.1) (3.0.3)\n","Requirement already satisfied: nemo_toolkit[asr]==1.23.0 in /usr/local/lib/python3.10/dist-packages (1.23.0)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.23.2)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.58.1)\n","Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.25.2)\n","Requirement already satisfied: onnx>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.16.1)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (2.8.2)\n","Requirement already satisfied: ruamel.yaml in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.18.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.2.2)\n","Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (67.7.2)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (2.15.2)\n","Requirement already satisfied: text-unidecode in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.3)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (2.3.0+cu121)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (4.66.4)\n","Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (2.3.0)\n","Requirement already satisfied: wget in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (3.2)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.14.1)\n","Requirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.1.7)\n","Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.6.2)\n","Requirement already satisfied: g2p-en in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (2.1.0)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (7.7.1)\n","Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (3.0.4)\n","Requirement already satisfied: kaldi-python-io in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.2.2)\n","Requirement already satisfied: kaldiio in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (2.18.0)\n","Requirement already satisfied: lhotse>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.23.0)\n","Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.10.2.post1)\n","Requirement already satisfied: marshmallow in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (3.21.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (3.7.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (24.0)\n","Requirement already satisfied: pyannote.core in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (5.0.0)\n","Requirement already satisfied: pyannote.metrics in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (3.2.1)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.25.1)\n","Requirement already satisfied: pyloudnorm in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.1.1)\n","Requirement already satisfied: resampy in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.4.3)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.11.4)\n","Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.12.1)\n","Requirement already satisfied: sox in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.5.0)\n","Requirement already satisfied: texterrors in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.4.4)\n","Requirement already satisfied: hydra-core<=1.3.2,>1.3 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.3.2)\n","Requirement already satisfied: omegaconf<=2.3 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (2.3.0)\n","Requirement already satisfied: pytorch-lightning<=2.0.7,>=2.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (2.0.7)\n","Requirement already satisfied: torchmetrics>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.4.0.post0)\n","Requirement already satisfied: transformers>=4.36.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (4.39.3)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.17.0)\n","Requirement already satisfied: webdataset<=0.1.62,>=0.1.48 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.1.62)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (2.19.2)\n","Requirement already satisfied: inflect in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (7.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (2.0.3)\n","Requirement already satisfied: sacremoses>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.1.1)\n","Requirement already satisfied: sentencepiece<1.0.0 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (0.1.99)\n","Requirement already satisfied: youtokentome>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from nemo_toolkit[asr]==1.23.0) (1.0.6)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core<=1.3.2,>1.3->nemo_toolkit[asr]==1.23.0) (4.9.3)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.20.0->nemo_toolkit[asr]==1.23.0) (3.0.1)\n","Requirement already satisfied: click>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.20.0->nemo_toolkit[asr]==1.23.0) (8.1.7)\n","Requirement already satisfied: cytoolz>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.20.0->nemo_toolkit[asr]==1.23.0) (0.12.3)\n","Requirement already satisfied: intervaltree>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.20.0->nemo_toolkit[asr]==1.23.0) (3.1.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.20.0->nemo_toolkit[asr]==1.23.0) (6.0.1)\n","Requirement already satisfied: tabulate>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.20.0->nemo_toolkit[asr]==1.23.0) (0.9.0)\n","Requirement already satisfied: lilcom>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lhotse>=1.20.0->nemo_toolkit[asr]==1.23.0) (1.7)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit[asr]==1.23.0) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit[asr]==1.23.0) (4.4.2)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit[asr]==1.23.0) (1.8.1)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit[asr]==1.23.0) (0.3.7)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit[asr]==1.23.0) (4.12.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit[asr]==1.23.0) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->nemo_toolkit[asr]==1.23.0) (1.0.8)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->nemo_toolkit[asr]==1.23.0) (0.41.1)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.7.0->nemo_toolkit[asr]==1.23.0) (3.20.3)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<=2.0.7,>=2.0->nemo_toolkit[asr]==1.23.0) (2023.6.0)\n","Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<=2.0.7,>=2.0->nemo_toolkit[asr]==1.23.0) (0.11.2)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses>=0.0.43->nemo_toolkit[asr]==1.23.0) (2024.5.15)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nemo_toolkit[asr]==1.23.0) (3.5.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile->nemo_toolkit[asr]==1.23.0) (1.16.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (3.14.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (3.1.4)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->nemo_toolkit[asr]==1.23.0) (12.1.105)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->nemo_toolkit[asr]==1.23.0) (12.5.40)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->nemo_toolkit[asr]==1.23.0) (2.32.3)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->nemo_toolkit[asr]==1.23.0) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.36.0->nemo_toolkit[asr]==1.23.0) (0.4.3)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->nemo_toolkit[asr]==1.23.0) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->nemo_toolkit[asr]==1.23.0) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->nemo_toolkit[asr]==1.23.0) (0.3.8)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->nemo_toolkit[asr]==1.23.0) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->nemo_toolkit[asr]==1.23.0) (0.70.16)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->nemo_toolkit[asr]==1.23.0) (3.9.5)\n","Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from g2p-en->nemo_toolkit[asr]==1.23.0) (3.8.1)\n","Requirement already satisfied: distance>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from g2p-en->nemo_toolkit[asr]==1.23.0) (0.1.3)\n","Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect->nemo_toolkit[asr]==1.23.0) (2.7.2)\n","Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->nemo_toolkit[asr]==1.23.0) (5.5.6)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->nemo_toolkit[asr]==1.23.0) (0.2.0)\n","Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->nemo_toolkit[asr]==1.23.0) (5.7.1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->nemo_toolkit[asr]==1.23.0) (3.6.6)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->nemo_toolkit[asr]==1.23.0) (7.34.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->nemo_toolkit[asr]==1.23.0) (3.0.11)\n","Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer->nemo_toolkit[asr]==1.23.0) (3.9.3)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nemo_toolkit[asr]==1.23.0) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nemo_toolkit[asr]==1.23.0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nemo_toolkit[asr]==1.23.0) (4.52.4)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nemo_toolkit[asr]==1.23.0) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nemo_toolkit[asr]==1.23.0) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nemo_toolkit[asr]==1.23.0) (3.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->nemo_toolkit[asr]==1.23.0) (1.16.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nemo_toolkit[asr]==1.23.0) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nemo_toolkit[asr]==1.23.0) (2024.1)\n","Requirement already satisfied: sortedcontainers>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pyannote.core->nemo_toolkit[asr]==1.23.0) (2.4.0)\n","Requirement already satisfied: pyannote.database>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics->nemo_toolkit[asr]==1.23.0) (5.1.0)\n","Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from pyannote.metrics->nemo_toolkit[asr]==1.23.0) (0.6.2)\n","Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from pyloudnorm->nemo_toolkit[asr]==1.23.0) (0.18.3)\n","Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from ruamel.yaml->nemo_toolkit[asr]==1.23.0) (0.2.8)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo_toolkit[asr]==1.23.0) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo_toolkit[asr]==1.23.0) (1.64.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo_toolkit[asr]==1.23.0) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo_toolkit[asr]==1.23.0) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo_toolkit[asr]==1.23.0) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo_toolkit[asr]==1.23.0) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->nemo_toolkit[asr]==1.23.0) (3.0.3)\n","Requirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from texterrors->nemo_toolkit[asr]==1.23.0) (2.12.0)\n","Requirement already satisfied: plac in /usr/local/lib/python3.10/dist-packages (from texterrors->nemo_toolkit[asr]==1.23.0) (1.4.3)\n","Requirement already satisfied: loguru in /usr/local/lib/python3.10/dist-packages (from texterrors->nemo_toolkit[asr]==1.23.0) (0.7.2)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from texterrors->nemo_toolkit[asr]==1.23.0) (2.4.0)\n","Requirement already satisfied: Levenshtein in /usr/local/lib/python3.10/dist-packages (from texterrors->nemo_toolkit[asr]==1.23.0) (0.25.1)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nemo_toolkit[asr]==1.23.0) (0.4.0)\n","Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nemo_toolkit[asr]==1.23.0) (3.1.43)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->nemo_toolkit[asr]==1.23.0) (4.2.2)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nemo_toolkit[asr]==1.23.0) (5.9.5)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->nemo_toolkit[asr]==1.23.0) (2.4.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->nemo_toolkit[asr]==1.23.0) (1.3.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile->nemo_toolkit[asr]==1.23.0) (2.22)\n","Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.10.1->lhotse>=1.20.0->nemo_toolkit[asr]==1.23.0) (0.12.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]==1.23.0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]==1.23.0) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]==1.23.0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]==1.23.0) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]==1.23.0) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->nemo_toolkit[asr]==1.23.0) (4.0.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]==1.23.0) (4.0.11)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->nemo_toolkit[asr]==1.23.0) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->nemo_toolkit[asr]==1.23.0) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->nemo_toolkit[asr]==1.23.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->nemo_toolkit[asr]==1.23.0) (1.3.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[asr]==1.23.0) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->nemo_toolkit[asr]==1.23.0) (6.3.3)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.19.1)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (3.0.45)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (4.9.0)\n","Requirement already satisfied: typer>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==1.23.0) (0.12.3)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect->nemo_toolkit[asr]==1.23.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect->nemo_toolkit[asr]==1.23.0) (2.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.36.0->nemo_toolkit[asr]==1.23.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.36.0->nemo_toolkit[asr]==1.23.0) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.36.0->nemo_toolkit[asr]==1.23.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.36.0->nemo_toolkit[asr]==1.23.0) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->nemo_toolkit[asr]==1.23.0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->nemo_toolkit[asr]==1.23.0) (2.1.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (6.5.5)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->nemo_toolkit[asr]==1.23.0) (5.0.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.8.4)\n","Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (24.0.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (23.1.0)\n","Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (5.7.2)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (5.10.4)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (6.5.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (1.6.0)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (1.8.3)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.18.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.20.0)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (1.1.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.2.13)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->nemo_toolkit[asr]==1.23.0) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->nemo_toolkit[asr]==1.23.0) (3.2.2)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==1.23.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==1.23.0) (13.7.1)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.2.4)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (4.9.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (4.12.3)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (6.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.7.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.4)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.3.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.8.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.10.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (1.5.1)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (1.3.0)\n","Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (2.19.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (4.19.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==1.23.0) (3.0.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (21.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.18.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.1->pyannote.database>=4.0.1->pyannote.metrics->nemo_toolkit[asr]==1.23.0) (0.1.2)\n","Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (1.24.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (2.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (0.5.1)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (1.8.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->nemo_toolkit[asr]==1.23.0) (1.2.1)\n","Collecting demucs\n","  Cloning https://github.com/facebookresearch/demucs to /tmp/pip-install-y5sr8hgl/demucs_073775df6db146c7afa666c7958cb526\n","  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/demucs /tmp/pip-install-y5sr8hgl/demucs_073775df6db146c7afa666c7958cb526\n","  Resolved https://github.com/facebookresearch/demucs to commit e976d93ecc3865e5757426930257e200846a520a\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting git+https://github.com/oliverguhr/deepmultilingualpunctuation.git\n","  Cloning https://github.com/oliverguhr/deepmultilingualpunctuation.git to /tmp/pip-req-build-h78n6eid\n","  Running command git clone --filter=blob:none --quiet https://github.com/oliverguhr/deepmultilingualpunctuation.git /tmp/pip-req-build-h78n6eid\n","  Resolved https://github.com/oliverguhr/deepmultilingualpunctuation.git to commit 5a0dd7f4fd56687f59405aa8eba1144393d8b74b\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from deepmultilingualpunctuation==1.0.1) (4.39.3)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from deepmultilingualpunctuation==1.0.1) (2.3.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (4.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (12.5.40)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (2.32.3)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers->deepmultilingualpunctuation==1.0.1) (4.66.4)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepmultilingualpunctuation==1.0.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepmultilingualpunctuation==1.0.1) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepmultilingualpunctuation==1.0.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->deepmultilingualpunctuation==1.0.1) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->deepmultilingualpunctuation==1.0.1) (1.3.0)\n","Collecting git+https://github.com/MahmoudAshraf97/ctc-forced-aligner.git\n","  Cloning https://github.com/MahmoudAshraf97/ctc-forced-aligner.git to /tmp/pip-req-build-w3r0i9jm\n","  Running command git clone --filter=blob:none --quiet https://github.com/MahmoudAshraf97/ctc-forced-aligner.git /tmp/pip-req-build-w3r0i9jm\n","  Resolved https://github.com/MahmoudAshraf97/ctc-forced-aligner.git to commit 27a3f246cf9b7bbd5bf3d4da54a33f36606f75e7\n","  Running command git submodule update --init --recursive -q\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from ctc-forced-aligner==0.2) (3.8.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from ctc-forced-aligner==0.2) (2.3.0+cu121)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from ctc-forced-aligner==0.2) (2.3.0+cu121)\n","Requirement already satisfied: transformers>=4.34 in /usr/local/lib/python3.10/dist-packages (from ctc-forced-aligner==0.2) (4.39.3)\n","Requirement already satisfied: Unidecode in /usr/local/lib/python3.10/dist-packages (from ctc-forced-aligner==0.2) (1.3.8)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (2.32.3)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.34->ctc-forced-aligner==0.2) (4.66.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->ctc-forced-aligner==0.2) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->ctc-forced-aligner==0.2) (1.4.2)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (4.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (12.1.105)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->ctc-forced-aligner==0.2) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->ctc-forced-aligner==0.2) (12.5.40)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->ctc-forced-aligner==0.2) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34->ctc-forced-aligner==0.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34->ctc-forced-aligner==0.2) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34->ctc-forced-aligner==0.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.34->ctc-forced-aligner==0.2) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->ctc-forced-aligner==0.2) (1.3.0)\n"]}],"source":["!pip install git+https://github.com/m-bain/whisperX.git@78dcfaab51005aa703ee21375f81ed31bc248560\n","!pip install --no-build-isolation nemo_toolkit[asr]==1.23.0\n","!pip install --no-deps git+https://github.com/facebookresearch/demucs#egg=demucs\n","!pip install git+https://github.com/oliverguhr/deepmultilingualpunctuation.git\n","!pip install git+https://github.com/MahmoudAshraf97/ctc-forced-aligner.git\n","!pip install -qq pyannote.audio==3.1.1"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12203,"status":"ok","timestamp":1717520508442,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"YzhncHP0ytbQ","outputId":"b83acba5-53a7-43a7-d65a-cd5233b6228d"},"outputs":[{"output_type":"stream","name":"stderr","text":["[NeMo W 2024-06-04 17:01:57 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n","      torchaudio.set_audio_backend(\"soundfile\")\n","    \n"]}],"source":["import os\n","import wget\n","from omegaconf import OmegaConf\n","import json\n","import shutil\n","import torch\n","import torchaudio\n","from nemo.collections.asr.models.msdd_models import NeuralDiarizer\n","from deepmultilingualpunctuation import PunctuationModel\n","import re\n","import logging\n","import nltk\n","from whisperx.utils import LANGUAGES, TO_LANGUAGE_CODE\n","from ctc_forced_aligner import (\n","    load_alignment_model,\n","    generate_emissions,\n","    preprocess_text,\n","    get_alignments,\n","    get_spans,\n","    postprocess_results,\n",")"]},{"cell_type":"markdown","metadata":{"id":"jbsUt3SwyhjD"},"source":["# Helper Functions"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1717520508444,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"Se6Hc7CZygxu"},"outputs":[],"source":["punct_model_langs = [\n","    \"en\",\n","    \"fr\",\n","    \"de\",\n","    \"es\",\n","    \"it\",\n","    \"nl\",\n","    \"pt\",\n","    \"bg\",\n","    \"pl\",\n","    \"cs\",\n","    \"sk\",\n","    \"sl\",\n","]\n","langs_to_iso = {\n","    \"af\": \"afr\",\n","    \"am\": \"amh\",\n","    \"ar\": \"ara\",\n","    \"as\": \"asm\",\n","    \"az\": \"aze\",\n","    \"ba\": \"bak\",\n","    \"be\": \"bel\",\n","    \"bg\": \"bul\",\n","    \"bn\": \"ben\",\n","    \"bo\": \"tib\",\n","    \"br\": \"bre\",\n","    \"bs\": \"bos\",\n","    \"ca\": \"cat\",\n","    \"cs\": \"cze\",\n","    \"cy\": \"wel\",\n","    \"da\": \"dan\",\n","    \"de\": \"ger\",\n","    \"el\": \"gre\",\n","    \"en\": \"eng\",\n","    \"es\": \"spa\",\n","    \"et\": \"est\",\n","    \"eu\": \"baq\",\n","    \"fa\": \"per\",\n","    \"fi\": \"fin\",\n","    \"fo\": \"fao\",\n","    \"fr\": \"fre\",\n","    \"gl\": \"glg\",\n","    \"gu\": \"guj\",\n","    \"ha\": \"hau\",\n","    \"haw\": \"haw\",\n","    \"he\": \"heb\",\n","    \"hi\": \"hin\",\n","    \"hr\": \"hrv\",\n","    \"ht\": \"hat\",\n","    \"hu\": \"hun\",\n","    \"hy\": \"arm\",\n","    \"id\": \"ind\",\n","    \"is\": \"ice\",\n","    \"it\": \"ita\",\n","    \"ja\": \"jpn\",\n","    \"jw\": \"jav\",\n","    \"ka\": \"geo\",\n","    \"kk\": \"kaz\",\n","    \"km\": \"khm\",\n","    \"kn\": \"kan\",\n","    \"ko\": \"kor\",\n","    \"la\": \"lat\",\n","    \"lb\": \"ltz\",\n","    \"ln\": \"lin\",\n","    \"lo\": \"lao\",\n","    \"lt\": \"lit\",\n","    \"lv\": \"lav\",\n","    \"mg\": \"mlg\",\n","    \"mi\": \"mao\",\n","    \"mk\": \"mac\",\n","    \"ml\": \"mal\",\n","    \"mn\": \"mon\",\n","    \"mr\": \"mar\",\n","    \"ms\": \"may\",\n","    \"mt\": \"mlt\",\n","    \"my\": \"bur\",\n","    \"ne\": \"nep\",\n","    \"nl\": \"dut\",\n","    \"nn\": \"nno\",\n","    \"no\": \"nor\",\n","    \"oc\": \"oci\",\n","    \"pa\": \"pan\",\n","    \"pl\": \"pol\",\n","    \"ps\": \"pus\",\n","    \"pt\": \"por\",\n","    \"ro\": \"rum\",\n","    \"ru\": \"rus\",\n","    \"sa\": \"san\",\n","    \"sd\": \"snd\",\n","    \"si\": \"sin\",\n","    \"sk\": \"slo\",\n","    \"sl\": \"slv\",\n","    \"sn\": \"sna\",\n","    \"so\": \"som\",\n","    \"sq\": \"alb\",\n","    \"sr\": \"srp\",\n","    \"su\": \"sun\",\n","    \"sv\": \"swe\",\n","    \"sw\": \"swa\",\n","    \"ta\": \"tam\",\n","    \"te\": \"tel\",\n","    \"tg\": \"tgk\",\n","    \"th\": \"tha\",\n","    \"tk\": \"tuk\",\n","    \"tl\": \"tgl\",\n","    \"tr\": \"tur\",\n","    \"tt\": \"tat\",\n","    \"uk\": \"ukr\",\n","    \"ur\": \"urd\",\n","    \"uz\": \"uzb\",\n","    \"vi\": \"vie\",\n","    \"yi\": \"yid\",\n","    \"yo\": \"yor\",\n","    \"yue\": \"yue\",\n","    \"zh\": \"chi\",\n","}\n","\n","\n","whisper_langs = sorted(LANGUAGES.keys()) + sorted(\n","    [k.title() for k in TO_LANGUAGE_CODE.keys()]\n",")\n","\n","\n","def create_config(output_dir):\n","    DOMAIN_TYPE = \"telephonic\"  # Can be meeting, telephonic, or general based on domain type of the audio file\n","    CONFIG_FILE_NAME = f\"diar_infer_{DOMAIN_TYPE}.yaml\"\n","    CONFIG_URL = f\"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/{CONFIG_FILE_NAME}\"\n","    MODEL_CONFIG = os.path.join(output_dir, CONFIG_FILE_NAME)\n","    if not os.path.exists(MODEL_CONFIG):\n","        MODEL_CONFIG = wget.download(CONFIG_URL, output_dir)\n","\n","    config = OmegaConf.load(MODEL_CONFIG)\n","\n","    data_dir = os.path.join(output_dir, \"data\")\n","    os.makedirs(data_dir, exist_ok=True)\n","\n","    meta = {\n","        \"audio_filepath\": os.path.join(output_dir, \"mono_file.wav\"),\n","        \"offset\": 0,\n","        \"duration\": None,\n","        \"label\": \"infer\",\n","        \"text\": \"-\",\n","        \"rttm_filepath\": None,\n","        \"uem_filepath\": None,\n","    }\n","    with open(os.path.join(data_dir, \"input_manifest.json\"), \"w\") as fp:\n","        json.dump(meta, fp)\n","        fp.write(\"\\n\")\n","\n","    pretrained_vad = \"vad_multilingual_marblenet\"\n","    pretrained_speaker_model = \"titanet_large\"\n","    config.num_workers = 0  # Workaround for multiprocessing hanging with ipython issue\n","    config.diarizer.manifest_filepath = os.path.join(data_dir, \"input_manifest.json\")\n","    config.diarizer.out_dir = (\n","        output_dir  # Directory to store intermediate files and prediction outputs\n","    )\n","\n","    config.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n","    config.diarizer.oracle_vad = (\n","        False  # compute VAD provided with model_path to vad config\n","    )\n","    config.diarizer.clustering.parameters.oracle_num_speakers = False\n","\n","    # Here, we use our in-house pretrained NeMo VAD model\n","    config.diarizer.vad.model_path = pretrained_vad\n","    config.diarizer.vad.parameters.onset = 0.8\n","    config.diarizer.vad.parameters.offset = 0.6\n","    config.diarizer.vad.parameters.pad_offset = -0.05\n","    config.diarizer.msdd_model.model_path = (\n","        \"diar_msdd_telephonic\"  # Telephonic speaker diarization model\n","    )\n","\n","    return config\n","\n","\n","def get_word_ts_anchor(s, e, option=\"start\"):\n","    if option == \"end\":\n","        return e\n","    elif option == \"mid\":\n","        return (s + e) / 2\n","    return s\n","\n","\n","def get_words_speaker_mapping(wrd_ts, spk_ts, word_anchor_option=\"start\"):\n","    s, e, sp = spk_ts[0]\n","    wrd_pos, turn_idx = 0, 0\n","    wrd_spk_mapping = []\n","    for wrd_dict in wrd_ts:\n","        ws, we, wrd = (\n","            int(wrd_dict[\"start\"] * 1000),\n","            int(wrd_dict[\"end\"] * 1000),\n","            wrd_dict[\"text\"],\n","        )\n","        wrd_pos = get_word_ts_anchor(ws, we, word_anchor_option)\n","        while wrd_pos > float(e):\n","            turn_idx += 1\n","            turn_idx = min(turn_idx, len(spk_ts) - 1)\n","            s, e, sp = spk_ts[turn_idx]\n","            if turn_idx == len(spk_ts) - 1:\n","                e = get_word_ts_anchor(ws, we, option=\"end\")\n","        wrd_spk_mapping.append(\n","            {\"word\": wrd, \"start_time\": ws, \"end_time\": we, \"speaker\": sp}\n","        )\n","    return wrd_spk_mapping\n","\n","\n","sentence_ending_punctuations = \".?!\"\n","\n","\n","def get_first_word_idx_of_sentence(word_idx, word_list, speaker_list, max_words):\n","    is_word_sentence_end = (\n","        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n","    )\n","    left_idx = word_idx\n","    while (\n","        left_idx > 0\n","        and word_idx - left_idx < max_words\n","        and speaker_list[left_idx - 1] == speaker_list[left_idx]\n","        and not is_word_sentence_end(left_idx - 1)\n","    ):\n","        left_idx -= 1\n","\n","    return left_idx if left_idx == 0 or is_word_sentence_end(left_idx - 1) else -1\n","\n","\n","def get_last_word_idx_of_sentence(word_idx, word_list, max_words):\n","    is_word_sentence_end = (\n","        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n","    )\n","    right_idx = word_idx\n","    while (\n","        right_idx < len(word_list) - 1\n","        and right_idx - word_idx < max_words\n","        and not is_word_sentence_end(right_idx)\n","    ):\n","        right_idx += 1\n","\n","    return (\n","        right_idx\n","        if right_idx == len(word_list) - 1 or is_word_sentence_end(right_idx)\n","        else -1\n","    )\n","\n","\n","def get_realigned_ws_mapping_with_punctuation(\n","    word_speaker_mapping, max_words_in_sentence=50\n","):\n","    is_word_sentence_end = (\n","        lambda x: x >= 0\n","        and word_speaker_mapping[x][\"word\"][-1] in sentence_ending_punctuations\n","    )\n","    wsp_len = len(word_speaker_mapping)\n","\n","    words_list, speaker_list = [], []\n","    for k, line_dict in enumerate(word_speaker_mapping):\n","        word, speaker = line_dict[\"word\"], line_dict[\"speaker\"]\n","        words_list.append(word)\n","        speaker_list.append(speaker)\n","\n","    k = 0\n","    while k < len(word_speaker_mapping):\n","        line_dict = word_speaker_mapping[k]\n","        if (\n","            k < wsp_len - 1\n","            and speaker_list[k] != speaker_list[k + 1]\n","            and not is_word_sentence_end(k)\n","        ):\n","            left_idx = get_first_word_idx_of_sentence(\n","                k, words_list, speaker_list, max_words_in_sentence\n","            )\n","            right_idx = (\n","                get_last_word_idx_of_sentence(\n","                    k, words_list, max_words_in_sentence - k + left_idx - 1\n","                )\n","                if left_idx > -1\n","                else -1\n","            )\n","            if min(left_idx, right_idx) == -1:\n","                k += 1\n","                continue\n","\n","            spk_labels = speaker_list[left_idx : right_idx + 1]\n","            mod_speaker = max(set(spk_labels), key=spk_labels.count)\n","            if spk_labels.count(mod_speaker) < len(spk_labels) // 2:\n","                k += 1\n","                continue\n","\n","            speaker_list[left_idx : right_idx + 1] = [mod_speaker] * (\n","                right_idx - left_idx + 1\n","            )\n","            k = right_idx\n","\n","        k += 1\n","\n","    k, realigned_list = 0, []\n","    while k < len(word_speaker_mapping):\n","        line_dict = word_speaker_mapping[k].copy()\n","        line_dict[\"speaker\"] = speaker_list[k]\n","        realigned_list.append(line_dict)\n","        k += 1\n","\n","    return realigned_list\n","\n","\n","def get_sentences_speaker_mapping(word_speaker_mapping, spk_ts):\n","    sentence_checker = nltk.tokenize.PunktSentenceTokenizer().text_contains_sentbreak\n","    s, e, spk = spk_ts[0]\n","    prev_spk = spk\n","\n","    snts = []\n","    snt = {\"speaker\": f\"Speaker {spk}\", \"start_time\": s, \"end_time\": e, \"text\": \"\"}\n","\n","    for wrd_dict in word_speaker_mapping:\n","        wrd, spk = wrd_dict[\"word\"], wrd_dict[\"speaker\"]\n","        s, e = wrd_dict[\"start_time\"], wrd_dict[\"end_time\"]\n","        if spk != prev_spk or sentence_checker(snt[\"text\"] + \" \" + wrd):\n","            snts.append(snt)\n","            snt = {\n","                \"speaker\": f\"Speaker {spk}\",\n","                \"start_time\": s,\n","                \"end_time\": e,\n","                \"text\": \"\",\n","            }\n","        else:\n","            snt[\"end_time\"] = e\n","        snt[\"text\"] += wrd + \" \"\n","        prev_spk = spk\n","\n","    snts.append(snt)\n","    return snts\n","\n","\n","def get_speaker_aware_transcript(sentences_speaker_mapping, f):\n","    previous_speaker = sentences_speaker_mapping[0][\"speaker\"]\n","    f.write(f\"{previous_speaker}: \")\n","\n","    for sentence_dict in sentences_speaker_mapping:\n","        speaker = sentence_dict[\"speaker\"]\n","        sentence = sentence_dict[\"text\"]\n","\n","        # If this speaker doesn't match the previous one, start a new paragraph\n","        if speaker != previous_speaker:\n","            f.write(f\"\\n\\n{speaker}: \")\n","            previous_speaker = speaker\n","\n","        # No matter what, write the current sentence\n","        f.write(sentence + \" \")\n","\n","\n","def format_timestamp(\n","    milliseconds: float, always_include_hours: bool = False, decimal_marker: str = \".\"\n","):\n","    assert milliseconds >= 0, \"non-negative timestamp expected\"\n","\n","    hours = milliseconds // 3_600_000\n","    milliseconds -= hours * 3_600_000\n","\n","    minutes = milliseconds // 60_000\n","    milliseconds -= minutes * 60_000\n","\n","    seconds = milliseconds // 1_000\n","    milliseconds -= seconds * 1_000\n","\n","    hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n","    return (\n","        f\"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}\"\n","    )\n","\n","\n","def write_srt(transcript, file):\n","    \"\"\"\n","    Write a transcript to a file in SRT format.\n","\n","    \"\"\"\n","    for i, segment in enumerate(transcript, start=1):\n","        # write srt lines\n","        print(\n","            f\"{i}\\n\"\n","            f\"{format_timestamp(segment['start_time'], always_include_hours=True, decimal_marker=',')} --> \"\n","            f\"{format_timestamp(segment['end_time'], always_include_hours=True, decimal_marker=',')}\\n\"\n","            f\"{segment['speaker']}: {segment['text'].strip().replace('-->', '->')}\\n\",\n","            file=file,\n","            flush=True,\n","        )\n","\n","\n","def find_numeral_symbol_tokens(tokenizer):\n","    numeral_symbol_tokens = [\n","        -1,\n","    ]\n","    for token, token_id in tokenizer.get_vocab().items():\n","        has_numeral_symbol = any(c in \"0123456789%$£\" for c in token)\n","        if has_numeral_symbol:\n","            numeral_symbol_tokens.append(token_id)\n","    return numeral_symbol_tokens\n","\n","\n","def _get_next_start_timestamp(word_timestamps, current_word_index, final_timestamp):\n","    # if current word is the last word\n","    if current_word_index == len(word_timestamps) - 1:\n","        return word_timestamps[current_word_index][\"start\"]\n","\n","    next_word_index = current_word_index + 1\n","    while current_word_index < len(word_timestamps) - 1:\n","        if word_timestamps[next_word_index].get(\"start\") is None:\n","            # if next word doesn't have a start timestamp\n","            # merge it with the current word and delete it\n","            word_timestamps[current_word_index][\"word\"] += (\n","                \" \" + word_timestamps[next_word_index][\"word\"]\n","            )\n","\n","            word_timestamps[next_word_index][\"word\"] = None\n","            next_word_index += 1\n","            if next_word_index == len(word_timestamps):\n","                return final_timestamp\n","\n","        else:\n","            return word_timestamps[next_word_index][\"start\"]\n","\n","\n","def filter_missing_timestamps(\n","    word_timestamps, initial_timestamp=0, final_timestamp=None\n","):\n","    # handle the first and last word\n","    if word_timestamps[0].get(\"start\") is None:\n","        word_timestamps[0][\"start\"] = (\n","            initial_timestamp if initial_timestamp is not None else 0\n","        )\n","        word_timestamps[0][\"end\"] = _get_next_start_timestamp(\n","            word_timestamps, 0, final_timestamp\n","        )\n","\n","    result = [\n","        word_timestamps[0],\n","    ]\n","\n","    for i, ws in enumerate(word_timestamps[1:], start=1):\n","        # if ws doesn't have a start and end\n","        # use the previous end as start and next start as end\n","        if ws.get(\"start\") is None and ws.get(\"word\") is not None:\n","            ws[\"start\"] = word_timestamps[i - 1][\"end\"]\n","            ws[\"end\"] = _get_next_start_timestamp(word_timestamps, i, final_timestamp)\n","\n","        if ws[\"word\"] is not None:\n","            result.append(ws)\n","    return result\n","\n","\n","def cleanup(path: str):\n","    \"\"\"path could either be relative or absolute.\"\"\"\n","    # check if file or directory exists\n","    if os.path.isfile(path) or os.path.islink(path):\n","        # remove file\n","        os.remove(path)\n","    elif os.path.isdir(path):\n","        # remove directory and all its content\n","        shutil.rmtree(path)\n","    else:\n","        raise ValueError(\"Path {} is not a file or dir.\".format(path))\n","\n","\n","def process_language_arg(language: str, model_name: str):\n","    \"\"\"\n","    Process the language argument to make sure it's valid and convert language names to language codes.\n","    \"\"\"\n","    if language is not None:\n","        language = language.lower()\n","    if language not in LANGUAGES:\n","        if language in TO_LANGUAGE_CODE:\n","            language = TO_LANGUAGE_CODE[language]\n","        else:\n","            raise ValueError(f\"Unsupported language: {language}\")\n","\n","    if model_name.endswith(\".en\") and language != \"en\":\n","        if language is not None:\n","            logging.warning(\n","                f\"{model_name} is an English-only model but received '{language}'; using English instead.\"\n","            )\n","        language = \"en\"\n","    return language\n","\n","\n","def transcribe_batched(\n","    audio_file: str,\n","    language: str,\n","    batch_size: int,\n","    model_name: str,\n","    compute_dtype: str,\n","    suppress_numerals: bool,\n","    device: str,\n","):\n","    import whisperx\n","\n","    # Faster Whisper batched\n","    whisper_model = whisperx.load_model(\n","        model_name,\n","        device,\n","        compute_type=compute_dtype,\n","        asr_options={\"suppress_numerals\": suppress_numerals},\n","    )\n","    audio = whisperx.load_audio(audio_file)\n","    result = whisper_model.transcribe(audio, language=language, batch_size=batch_size)\n","    del whisper_model\n","    torch.cuda.empty_cache()\n","    return result[\"segments\"], result[\"language\"], audio"]},{"cell_type":"markdown","metadata":{"id":"B7qWQb--1Xcw"},"source":["# Options"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":36321,"status":"ok","timestamp":1717520438270,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"dIxG1EQE5_gG","outputId":"f193ca81-466e-410e-877b-4237d690f6cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/Shareddrives/CS224S/CS224S_Final_Project/data\n"," all_annotateds\t\t        old_organization\n"," all_annotations\t        outputs\n"," all_audio\t\t        pyannote_minibaseline_dataset.pkl\n"," an4_diarize_test.rttm\t       'PyAnnote Results.gsheet'\n"," an4_diarize_test.wav\t        pyannote_uem_file\n"," audio_files_with_empty_rttms   sample_converted_noheader_withfilename.rttm\n"," database.yml\t\t        splits\n"," error.log\t\t        Splits\n"," lightning_logs\t\t        temp_outputs\n"," lst_files\n"]}],"source":["## Load the dataset\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd drive/Shareddrives/CS224S/CS224S_Final_Project/data\n","!ls"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1717520508444,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"7R3vlxJN7q3h"},"outputs":[],"source":["# Load pairs of the .wav file and the .rtttm file here!\n","# Then start running this as a loop\n","\n","from pyannote.database.util import load_rttm"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":401,"status":"ok","timestamp":1717520518822,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"Eus2olXwXqku"},"outputs":[],"source":["from pyannote.metrics.diarization import DiarizationErrorRate\n","\n","def inference_on_one_sample(audio_path, rttm_path, label):\n","  # Whether to enable music removal from speech, helps increase diarization quality but uses alot of ram\n","  enable_stemming = True\n","  # (choose from 'tiny.en', 'tiny', 'base.en', 'base', 'small.en', 'small', 'medium.en', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large')\n","  whisper_model_name = \"large-v2\"\n","  # replaces numerical digits with their pronounciation, increases diarization accuracy\n","  suppress_numerals = True\n","  batch_size = 8\n","  language = None  # autodetect language\n","  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","  if enable_stemming:\n","    # Isolate vocals from the rest of the audio\n","\n","    return_code = os.system(\n","        f'python3 -m demucs.separate -n htdemucs --two-stems=vocals \"{audio_path}\" -o \"temp_outputs\"'\n","    )\n","\n","    if return_code != 0:\n","        logging.warning(\"Source splitting failed, using original audio file.\")\n","        vocal_target = audio_path\n","    else:\n","        vocal_target = os.path.join(\n","            \"temp_outputs\",\n","            \"htdemucs\",\n","            os.path.splitext(os.path.basename(audio_path))[0],\n","            \"vocals.wav\",\n","        )\n","  else:\n","    vocal_target = audio_path\n","\n","  compute_type = \"float16\"\n","\n","  whisper_results, language, audio_waveform = transcribe_batched(\n","    vocal_target,\n","    language,\n","    batch_size,\n","    whisper_model_name,\n","    compute_type,\n","    suppress_numerals,\n","    device,\n","  )\n","\n","  alignment_model, alignment_tokenizer, alignment_dictionary = load_alignment_model(\n","    device,\n","    dtype=torch.float16 if device == \"cuda\" else torch.float32,\n","  )\n","\n","  audio_waveform = (\n","    torch.from_numpy(audio_waveform)\n","    .to(alignment_model.dtype)\n","    .to(alignment_model.device)\n","  )\n","\n","  emissions, stride = generate_emissions(\n","    alignment_model, audio_waveform, batch_size=batch_size\n","  )\n","\n","  del alignment_model\n","  torch.cuda.empty_cache()\n","\n","  full_transcript = \"\".join(segment[\"text\"] for segment in whisper_results)\n","\n","  tokens_starred, text_starred = preprocess_text(\n","    full_transcript,\n","    romanize=True,\n","    language=langs_to_iso[language],\n","  )\n","\n","  segments, blank_id = get_alignments(\n","    emissions,\n","    tokens_starred,\n","    alignment_dictionary,\n","  )\n","\n","  spans = get_spans(tokens_starred, segments, alignment_tokenizer.decode(blank_id))\n","\n","  word_timestamps = postprocess_results(text_starred, spans, stride)\n","  ROOT = os.getcwd()\n","  temp_path = os.path.join(ROOT, \"temp_outputs\")\n","  os.makedirs(temp_path, exist_ok=True)\n","  torchaudio.save(\n","    os.path.join(temp_path, \"mono_file.wav\"),\n","    audio_waveform.cpu().unsqueeze(0).float(),\n","    16000,\n","    channels_first=True,\n","  )\n","  # Initialize NeMo MSDD diarization model\n","  msdd_model = NeuralDiarizer(cfg=create_config(temp_path)).to(\"cuda\")\n","  msdd_model.diarize()\n","  del msdd_model\n","  torch.cuda.empty_cache()\n","\n","  # Reading timestamps <> Speaker Labels mapping\n","\n","  speaker_ts = []\n","\n","  with open(os.path.join(temp_path, \"pred_rttms\", \"mono_file.rttm\"), \"r\") as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        line_list = line.split(\" \")\n","        s = int(float(line_list[5]) * 1000)\n","        e = s + int(float(line_list[8]) * 1000)\n","        speaker_ts.append([s, e, int(line_list[11].split(\"_\")[-1])])\n","\n","  wsm = get_words_speaker_mapping(word_timestamps, speaker_ts, \"start\")\n","\n","  if language in punct_model_langs:\n","    # restoring punctuation in the transcript to help realign the sentences\n","    punct_model = PunctuationModel(model=\"kredor/punctuate-all\")\n","\n","    words_list = list(map(lambda x: x[\"word\"], wsm))\n","\n","    labled_words = punct_model.predict(words_list,chunk_size=230)\n","\n","    ending_puncts = \".?!\"\n","    model_puncts = \".,;:!?\"\n","\n","    # We don't want to punctuate U.S.A. with a period. Right?\n","    is_acronym = lambda x: re.fullmatch(r\"\\b(?:[a-zA-Z]\\.){2,}\", x)\n","\n","    for word_dict, labeled_tuple in zip(wsm, labled_words):\n","        word = word_dict[\"word\"]\n","        if (\n","            word\n","            and labeled_tuple[1] in ending_puncts\n","            and (word[-1] not in model_puncts or is_acronym(word))\n","        ):\n","            word += labeled_tuple[1]\n","            if word.endswith(\"..\"):\n","                word = word.rstrip(\".\")\n","            word_dict[\"word\"] = word\n","  else:\n","    logging.warning(\n","        f\"Punctuation restoration is not available for {language} language. Using the original punctuation.\"\n","    )\n","\n","  print(\"RTTM labels \", load_rttm(rttm_path).keys())\n","  reference = load_rttm(rttm_path)[label]\n","  hypothesis = load_rttm(os.path.join(temp_path, \"pred_rttms/mono_file.rttm\"))['mono_file']\n","\n","  value = metric(reference, hypothesis, detailed=True)\n","  print(value)\n","\n","  return value"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":793},"executionInfo":{"elapsed":3137,"status":"error","timestamp":1717520644757,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"oqNCpkkVYYT4","outputId":"24e10014-23d3-4751-f3f6-4b082053f2a0"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"output_type":"stream","name":"stdout","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Failed to load audio: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n/content/an4_diarize_test.wav: No such file or directory\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisperx/audio.py\u001b[0m in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     60\u001b[0m         ]\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             raise CalledProcessError(retcode, process.args,\n\u001b[0m\u001b[1;32m    527\u001b[0m                                      output=stdout, stderr=stderr)\n","\u001b[0;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-nostdin', '-threads', '0', '-i', '/content/an4_diarize_test.wav', '-f', 's16le', '-ac', '1', '-acodec', 'pcm_s16le', '-ar', '16000', '-']' returned non-zero exit status 1.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-30790834e155>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiarizationErrorRate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minference_on_one_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/an4_diarize_test.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/an4_diarize_test.rttm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'an4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-bfd4972330ca>\u001b[0m in \u001b[0;36minference_on_one_sample\u001b[0;34m(audio_path, rttm_path, label)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0mcompute_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"float16\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m   whisper_results, language, audio_waveform = transcribe_batched(\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mvocal_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-aaad2e5508c2>\u001b[0m in \u001b[0;36mtranscribe_batched\u001b[0;34m(audio_file, language, batch_size, model_name, compute_dtype, suppress_numerals, device)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0masr_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"suppress_numerals\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msuppress_numerals\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     )\n\u001b[0;32m--> 501\u001b[0;31m     \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisperx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhisper_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mwhisper_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisperx/audio.py\u001b[0m in \u001b[0;36mload_audio\u001b[0;34m(file, sr)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalledProcessError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to load audio: {e.stderr.decode()}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m32768.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Failed to load audio: ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n  libavutil      56. 70.100 / 56. 70.100\n  libavcodec     58.134.100 / 58.134.100\n  libavformat    58. 76.100 / 58. 76.100\n  libavdevice    58. 13.100 / 58. 13.100\n  libavfilter     7.110.100 /  7.110.100\n  libswscale      5.  9.100 /  5.  9.100\n  libswresample   3.  9.100 /  3.  9.100\n  libpostproc    55.  9.100 / 55.  9.100\n/content/an4_diarize_test.wav: No such file or directory\n"]}],"source":["metric = DiarizationErrorRate()\n","\n","inference_on_one_sample('/content/an4_diarize_test.wav', '/content/an4_diarize_test.rttm', 'an4')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"aborted","timestamp":1717520095723,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"SlHB6dplgIYZ"},"outputs":[],"source":["reference = load_rttm('/content/fixed_speaker_labels.rttm')['<1001lv02>']\n","hypothesis = load_rttm('/content/sample_output_pred.rttm')['mono_file']\n","\n","value = metric(reference, hypothesis, detailed=True)\n","print(value)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19,"status":"aborted","timestamp":1717520602329,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"pQv4jy40bM4Q"},"outputs":[],"source":["import os\n","\n","# Example usage\n","directory_to_crawl = 'all_audio/'\n","\n","values = []\n","diarization_error_rates = []\n","\n","metric = DiarizationErrorRate()\n","\n","for root, _, files in os.walk(directory_to_crawl):\n","        for file in files:\n","            file_path = os.path.join(root, file)\n","            print(file_path)\n","            label = '<' + file_path.replace('.wav', '') + '>'\n","            rttm_file = 'all_annotations/rttm_dir_fixed/' + file_path.replace('.wav', '.rttm').split('/')[-1]\n","            print(\"RTTM file \", rttm_file)\n","\n","            value = inference_on_one_sample(file_path, rttm_file, file_path.replace('.wav', '').split('/')[-1])\n","            values.append(value)\n","            diarization_error_rates.append(value['diarization error rate'])\n","\n","import numpy as np\n","\n","print(\"Mean Diarization Error Across Dataset: \", np.mean(diarization_error_rates))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":220,"status":"ok","timestamp":1717042546684,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"t8eA9UkJjdpu","outputId":"12444a03-0a9f-4f8c-b35d-82a2afa5d994"},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'correct': 125.85799999999956, 'confusion': 0.410000000000025, 'total': 566.0479999999993, 'missed detection': 439.77999999999975, 'false alarm': 0.022000000000048203, 'diarization error rate': 0.7776937644864046}, {'correct': 53.53999999999982, 'confusion': 0.5799999999999557, 'total': 568.0049999999983, 'missed detection': 513.8849999999985, 'false alarm': 0.0, 'diarization error rate': 0.9057402663708946}, {'correct': 65.28399999999971, 'confusion': 1.0959999999999894, 'total': 319.8729999999997, 'missed detection': 253.493, 'false alarm': 0.22000000000002728, 'diarization error rate': 0.7965942733522375}, {'correct': 88.2699999999999, 'confusion': 2.3100000000000733, 'total': 557.4859999999985, 'missed detection': 466.90599999999847, 'false alarm': 0.0, 'diarization error rate': 0.8416641852889576}, {'correct': 186.0399999999999, 'confusion': 0.8200000000000536, 'total': 555.9509999999985, 'missed detection': 369.0909999999986, 'false alarm': 0.15999999999996817, 'diarization error rate': 0.6656539874917027}, {'correct': 154.76199999999994, 'confusion': 15.552999999999816, 'total': 555.6119999999981, 'missed detection': 385.2969999999984, 'false alarm': 1.9249999999998977, 'diarization error rate': 0.7249213479910431}, {'correct': 69.8559999999996, 'confusion': 9.903999999999854, 'total': 554.2109999999979, 'missed detection': 474.45099999999843, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.8742067551889086}, {'correct': 52.081999999999724, 'confusion': 2.0779999999999035, 'total': 567.4049999999984, 'missed detection': 513.2449999999988, 'false alarm': 0.0, 'diarization error rate': 0.9082101849648841}, {'correct': 89.0290000000002, 'confusion': 0.8860000000000241, 'total': 567.8689999999989, 'missed detection': 477.95399999999864, 'false alarm': 0.0049999999999954525, 'diarization error rate': 0.8432314495068398}]\n"]}],"source":["print(values)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717042534682,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"s1EV5JvRjfVy","outputId":"b59f4b0e-6e7e-4d7d-dc43-de39b4f5ba50"},"outputs":[{"name":"stdout","output_type":"stream","text":["9\n"]}],"source":["print(len(values))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":415,"status":"error","timestamp":1717520674454,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"A6DqT_Iuy-s-","outputId":"689e50be-6901-4b2a-a3d2-324f829f72ad"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'files' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-3c656308947b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"]}],"source":["print(files[24:])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":12656,"status":"error","timestamp":1717044485458,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"V12m8EMGj9W_","outputId":"887c9266-e86b-4fda-9786-809972820c8b"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n"]},{"name":"stdout","output_type":"stream","text":["all_audio/5003lv06.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5003lv06.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (0.91) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:48:10 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:48:10 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:48:10 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:48:10 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:48:11 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:48:11 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:48:11 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:11 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:48:11 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:48:12 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:48:12 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:48:12 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:48:12 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:48:12 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:48:12 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:48:12 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:48:12 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:48:12 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:13 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:48:13 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:48:13 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:48:13 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:48:13 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:13 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:48:13 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 150.82it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:13 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 04:48:13 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:48:13 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:48:13 collections:446] Dataset loaded with 1 items, total duration of  0.01 hours.\n","[NeMo I 2024-05-30 04:48:13 collections:448] # 1 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 1/1 [00:00<00:00,  4.16it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:13 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:13 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 27.00it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:48:13 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:48:13 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:48:13 collections:446] Dataset loaded with 12 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 04:48:13 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 15.99it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:13 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:48:13 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:48:13 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:48:13 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:48:13 collections:446] Dataset loaded with 12 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 04:48:13 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 25.06it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:14 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:48:14 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:48:14 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:48:14 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:48:14 collections:446] Dataset loaded with 12 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 04:48:14 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 23.64it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:14 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:48:14 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:48:14 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:48:14 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:48:14 collections:446] Dataset loaded with 14 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 04:48:14 collections:448] # 14 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 20.93it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:14 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:48:14 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:48:14 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:14 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:48:14 collections:446] Dataset loaded with 16 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 04:48:14 collections:448] # 16 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[5/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 19.85it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:14 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00, 10.25it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:14 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:48:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:14 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:48:14 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:48:14 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:48:14 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:48:14 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:48:14 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:48:14 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:48:14 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 108.25it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:14 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:48:14 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:48:14 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:48:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:14 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:48:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:14 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:48:14 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:14 msdd_models:1431]   \n","    \n"]},{"ename":"KeyError","evalue":"'5003lv06'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-9cb529f78862>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RTTM file \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrttm_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filepath\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_on_one_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrttm_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mdiarization_error_rates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diarization error rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-fa5ac1853aea>\u001b[0m in \u001b[0;36minference_on_one_sample\u001b[0;34m(audio_path, rttm_path, label)\u001b[0m\n\u001b[1;32m    138\u001b[0m     )\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m   \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_rttm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrttm_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m   \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_rttm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pred_rttms/mono_file.rttm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mono_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '5003lv06'"]}],"source":["for file in files[24:]:\n","  file_path = os.path.join(root, file)\n","  print(file_path)\n","  label = '<' + file_path.replace('.wav', '') + '>'\n","  rttm_file = 'all_annotations/rttm_dir_fixed/' + file_path.replace('.wav', '.rttm').split('/')[-1]\n","  print(\"RTTM file \", rttm_file)\n","  print(\"filepath\")\n","  value = inference_on_one_sample(file_path, rttm_file, file_path.replace('.wav', '').split('/')[-1])\n","  values.append(value)\n","  diarization_error_rates.append(value['diarization error rate'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"cgRFVOJf0-Lb","outputId":"2ed068bb-b83f-4f0e-abaa-279e7790ae8c"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n"]},{"name":"stdout","output_type":"stream","text":["all_audio/5002lv06.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5002lv06.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (1.00) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:48:58 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:48:58 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:48:58 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:48:58 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:48:59 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:48:59 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:48:59 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:48:59 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:48:59 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:48:59 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:48:59 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:49:00 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:49:00 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:49:00 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:49:00 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:49:01 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:49:01 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:49:01 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:01 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:49:01 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:49:01 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:49:01 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:49:01 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:01 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:49:01 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 17.13it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:01 vad_utils:107] The prepared manifest file exists. Overwriting!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:01 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:49:01 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:01 collections:446] Dataset loaded with 7 items, total duration of  0.09 hours.\n","[NeMo I 2024-05-30 04:49:01 collections:448] # 7 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 7/7 [00:01<00:00,  4.90it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:03 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:05 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:05 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:49:05 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:49:05 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:05 collections:446] Dataset loaded with 86 items, total duration of  0.01 hours.\n","[NeMo I 2024-05-30 04:49:05 collections:448] # 86 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.27it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:06 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:49:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:49:06 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:49:06 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:06 collections:446] Dataset loaded with 91 items, total duration of  0.01 hours.\n","[NeMo I 2024-05-30 04:49:06 collections:448] # 91 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.46it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:06 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:49:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:49:06 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:49:06 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:06 collections:446] Dataset loaded with 100 items, total duration of  0.01 hours.\n","[NeMo I 2024-05-30 04:49:06 collections:448] # 100 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  5.84it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:07 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:49:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:49:07 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:49:07 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:07 collections:446] Dataset loaded with 112 items, total duration of  0.01 hours.\n","[NeMo I 2024-05-30 04:49:07 collections:448] # 112 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  6.27it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:07 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:49:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:49:07 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:49:07 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:07 collections:446] Dataset loaded with 151 items, total duration of  0.02 hours.\n","[NeMo I 2024-05-30 04:49:07 collections:448] # 151 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  7.24it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:07 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:08 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:49:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:08 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:49:08 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:49:08 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:49:08 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:49:08 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:49:08 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:49:08 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:49:08 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 84.55it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:08 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:49:08 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:49:08 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:49:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:08 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:49:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:08 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:49:08 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:08 msdd_models:1431]   \n","    \n","{'correct': 33.256999999999934, 'confusion': 2.6629999999999763, 'total': 192.1859999999999, 'missed detection': 156.26599999999996, 'false alarm': 3.8599999999999, 'diarization error rate': 0.8470388061565355}\n","all_audio/5003lv02.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5003lv02.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (0.91) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:49:32 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:49:32 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:49:32 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:49:32 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:49:33 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:49:33 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:49:33 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:33 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:49:33 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:49:34 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:49:34 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:49:34 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:49:34 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:49:34 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:49:34 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:49:34 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:49:34 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:49:34 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:34 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:49:34 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:49:34 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:49:34 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:49:34 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:34 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:49:34 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 17.83it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:34 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 04:49:34 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:49:34 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:34 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 04:49:34 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 12/12 [00:02<00:00,  4.73it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:37 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:42 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:49:42 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:49:42 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:42 collections:446] Dataset loaded with 117 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 04:49:42 collections:448] # 117 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  4.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:43 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:49:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:49:43 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:49:43 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:43 collections:446] Dataset loaded with 135 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 04:49:43 collections:448] # 135 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  6.84it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:43 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:49:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:49:43 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:49:43 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:43 collections:446] Dataset loaded with 162 items, total duration of  0.04 hours.\n","[NeMo I 2024-05-30 04:49:43 collections:448] # 162 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  5.06it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:44 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:49:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:49:44 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:49:44 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:44 collections:446] Dataset loaded with 214 items, total duration of  0.04 hours.\n","[NeMo I 2024-05-30 04:49:44 collections:448] # 214 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  6.14it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:44 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:49:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:49:44 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:49:44 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:49:44 collections:446] Dataset loaded with 317 items, total duration of  0.04 hours.\n","[NeMo I 2024-05-30 04:49:44 collections:448] # 317 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 5/5 [00:01<00:00,  4.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:46 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:46 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:49:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:46 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:49:46 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:49:46 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:49:46 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:49:46 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:49:46 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:49:46 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:49:46 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 72.49it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:46 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:49:46 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:49:46 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:49:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:46 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:49:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:46 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:49:46 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:49:46 msdd_models:1431]   \n","    \n","{'correct': 85.66099999999963, 'confusion': 1.9790000000000134, 'total': 560.6979999999988, 'missed detection': 473.0579999999992, 'false alarm': 0.0, 'diarization error rate': 0.8472243525034872}\n","all_audio/5008lv06.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5008lv06.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: it (0.99) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:50:01 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:50:01 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:50:01 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:50:01 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:50:03 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:50:03 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:50:03 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:03 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:50:03 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:50:03 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:50:03 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:50:04 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:50:04 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:50:04 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:50:04 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:50:04 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:50:04 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:50:04 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:04 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:50:04 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:50:04 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:50:04 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:50:04 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:04 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:50:04 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 54.62it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:04 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 04:50:04 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:50:04 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:04 collections:446] Dataset loaded with 4 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 04:50:04 collections:448] # 4 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 4/4 [00:00<00:00,  4.26it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:05 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:07 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:50:07 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:50:07 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:07 collections:446] Dataset loaded with 62 items, total duration of  0.01 hours.\n","[NeMo I 2024-05-30 04:50:07 collections:448] # 62 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  4.21it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:07 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:50:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:50:07 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:50:07 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:07 collections:446] Dataset loaded with 66 items, total duration of  0.01 hours.\n","[NeMo I 2024-05-30 04:50:07 collections:448] # 66 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  8.27it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:07 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:50:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:50:07 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:50:07 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:07 collections:446] Dataset loaded with 71 items, total duration of  0.01 hours.\n","[NeMo I 2024-05-30 04:50:07 collections:448] # 71 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:08 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:50:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:50:08 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:50:08 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:08 collections:446] Dataset loaded with 84 items, total duration of  0.01 hours.\n","[NeMo I 2024-05-30 04:50:08 collections:448] # 84 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  7.34it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:08 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:50:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:50:08 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:50:08 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:08 collections:446] Dataset loaded with 118 items, total duration of  0.01 hours.\n","[NeMo I 2024-05-30 04:50:08 collections:448] # 118 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  5.90it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:08 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  6.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:09 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:50:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:09 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:50:09 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:50:09 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:50:09 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:50:09 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:50:09 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:50:09 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:50:09 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 69.13it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:09 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:50:09 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:50:09 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:50:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:09 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:50:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:09 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:50:09 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:09 msdd_models:1431]   \n","    \n","{'correct': 25.498000000000026, 'confusion': 5.6019999999999905, 'total': 166.8699999999999, 'missed detection': 135.76999999999987, 'false alarm': 1.259999999999991, 'diarization error rate': 0.854749205968718}\n","all_audio/5011lv05.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5011lv05.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: fr (0.95) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:50:42 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:50:42 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:50:42 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:50:42 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:50:43 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:50:43 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:50:43 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:43 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:50:43 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:50:44 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:50:44 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:50:44 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:50:44 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:50:44 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:50:44 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:50:44 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:50:44 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:50:44 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:44 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:50:45 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:50:45 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:50:45 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:50:45 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:45 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:50:45 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 24.52it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:45 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 04:50:45 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:50:45 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:45 collections:446] Dataset loaded with 10 items, total duration of  0.14 hours.\n","[NeMo I 2024-05-30 04:50:45 collections:448] # 10 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 10/10 [00:02<00:00,  4.58it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:47 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:51 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:51 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:50:51 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:50:51 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:51 collections:446] Dataset loaded with 258 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 04:50:51 collections:448] # 258 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 5/5 [00:01<00:00,  4.88it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:52 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:50:52 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:50:52 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:50:52 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:52 collections:446] Dataset loaded with 282 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:50:52 collections:448] # 282 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.26it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:53 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:50:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:50:53 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:50:53 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:53 collections:446] Dataset loaded with 326 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:50:53 collections:448] # 326 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.49it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:55 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:50:55 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:50:55 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:50:55 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:55 collections:446] Dataset loaded with 411 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 04:50:55 collections:448] # 411 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  5.30it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:56 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:50:56 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:50:56 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:50:56 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:50:56 collections:446] Dataset loaded with 598 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 04:50:56 collections:448] # 598 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 10/10 [00:01<00:00,  5.88it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:58 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:58 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:50:58 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:58 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:50:58 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:50:58 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:50:58 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:50:58 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:50:58 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:50:58 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:50:58 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 37.95it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:58 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:50:58 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:50:58 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:50:58 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:58 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:50:58 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:58 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:50:58 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:50:58 msdd_models:1431]   \n","    \n","{'correct': 152.2369999999995, 'confusion': 10.84299999999985, 'total': 453.71399999999875, 'missed detection': 290.6339999999994, 'false alarm': 1.7799999999999727, 'diarization error rate': 0.6683880153576924}\n","all_audio/5003lv04.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5003lv04.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (0.99) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:51:29 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:51:29 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:51:29 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:51:29 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:51:30 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:51:30 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:51:30 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:30 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:51:30 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:51:31 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:51:31 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:51:31 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:51:31 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:51:31 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:51:31 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:51:31 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:51:31 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:51:31 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:31 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:51:32 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:51:32 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:51:32 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:51:32 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:32 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:51:32 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 18.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:32 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 04:51:32 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:51:32 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:51:32 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 04:51:32 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 12/12 [00:02<00:00,  4.94it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:34 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:39 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.75it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:39 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:51:39 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:51:39 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:51:39 collections:446] Dataset loaded with 211 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:51:39 collections:448] # 211 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.04it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:40 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:51:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:51:40 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:51:40 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:51:40 collections:446] Dataset loaded with 248 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:51:40 collections:448] # 248 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.12it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:41 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:51:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:51:41 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:51:41 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:51:41 collections:446] Dataset loaded with 295 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:51:41 collections:448] # 295 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.59it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:42 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:51:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:51:42 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:51:42 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:51:42 collections:446] Dataset loaded with 380 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 04:51:42 collections:448] # 380 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.70it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:43 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:51:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:43 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:51:43 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:51:43 collections:446] Dataset loaded with 566 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 04:51:43 collections:448] # 566 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[5/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:45 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:45 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:51:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:45 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:51:45 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:51:45 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:51:45 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:51:45 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:51:45 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:51:45 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:51:45 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 52.64it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:45 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:51:45 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:51:45 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:51:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:45 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:51:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:45 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:51:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:51:45 msdd_models:1431]   \n","    \n","{'correct': 137.74600000000024, 'confusion': 14.614000000000008, 'total': 551.2119999999992, 'missed detection': 398.851999999999, 'false alarm': 0.0, 'diarization error rate': 0.7501034084889292}\n","all_audio/5002lv04.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5002lv04.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (1.00) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:52:19 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:52:19 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:52:19 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:52:19 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:52:20 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:52:20 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:52:20 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:20 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:52:20 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:52:20 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:52:20 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:52:21 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:52:21 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:52:21 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:52:21 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:52:21 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:52:21 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:52:21 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:21 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:52:21 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:52:21 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:52:21 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:52:21 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:21 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:52:21 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 21.30it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:21 vad_utils:107] The prepared manifest file exists. Overwriting!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:21 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:52:21 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:52:21 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 04:52:21 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 12/12 [00:02<00:00,  4.88it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:24 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:29 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:52:29 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:52:29 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:52:29 collections:446] Dataset loaded with 236 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 04:52:29 collections:448] # 236 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:30 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:52:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:52:30 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:52:30 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:52:30 collections:446] Dataset loaded with 243 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 04:52:30 collections:448] # 243 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.81it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:31 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:31 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:52:31 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:52:31 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:52:31 collections:446] Dataset loaded with 255 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 04:52:31 collections:448] # 255 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.12it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:32 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:52:32 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:52:32 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:52:32 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:52:32 collections:446] Dataset loaded with 283 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 04:52:32 collections:448] # 283 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.00it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:32 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:52:32 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:52:32 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:52:32 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:52:32 collections:446] Dataset loaded with 361 items, total duration of  0.04 hours.\n","[NeMo I 2024-05-30 04:52:32 collections:448] # 361 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.73it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:34 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.00it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:34 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:52:34 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:34 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:52:34 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:52:34 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:52:34 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:52:34 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:52:34 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:52:34 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:52:34 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 64.36it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:34 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:52:34 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:52:34 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:52:34 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:34 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:52:34 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:34 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:52:34 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:52:34 msdd_models:1431]   \n","    \n","{'correct': 90.77599999999995, 'confusion': 1.9209999999999923, 'total': 556.4699999999982, 'missed detection': 463.7729999999983, 'false alarm': 1.8029999999999973, 'diarization error rate': 0.8401117760166762}\n","all_audio/5002lv01.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5002lv01.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (0.90) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:53:08 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:53:08 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:53:08 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:53:08 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:53:09 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:53:09 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:53:09 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:09 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:53:09 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:53:09 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:53:09 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:53:10 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:53:10 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:53:10 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:53:10 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:53:10 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:53:10 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:53:10 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:10 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:53:10 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:53:10 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:53:10 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:53:10 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:10 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:53:10 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 17.25it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:10 vad_utils:107] The prepared manifest file exists. Overwriting!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:10 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:53:10 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:53:10 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 04:53:10 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 12/12 [00:02<00:00,  4.02it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:13 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:18 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:18 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:53:18 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:53:18 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:53:18 collections:446] Dataset loaded with 183 items, total duration of  0.02 hours.\n","[NeMo I 2024-05-30 04:53:18 collections:448] # 183 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  4.42it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:19 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:53:19 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:53:19 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:53:19 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:53:19 collections:446] Dataset loaded with 190 items, total duration of  0.02 hours.\n","[NeMo I 2024-05-30 04:53:19 collections:448] # 190 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  4.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:20 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:53:20 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:53:20 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:53:20 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:53:20 collections:446] Dataset loaded with 203 items, total duration of  0.02 hours.\n","[NeMo I 2024-05-30 04:53:20 collections:448] # 203 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  6.60it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:20 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:53:20 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:53:20 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:53:20 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:53:20 collections:446] Dataset loaded with 227 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 04:53:20 collections:448] # 227 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.91it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:21 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:53:21 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:53:21 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:53:21 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:53:21 collections:446] Dataset loaded with 291 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 04:53:21 collections:448] # 291 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.10it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:22 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:22 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:53:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:22 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:53:22 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:53:22 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:53:22 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:53:22 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:53:22 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:53:22 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:53:22 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 83.33it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:22 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:53:22 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:53:22 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:53:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:22 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:53:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:22 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:53:22 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:22 msdd_models:1431]   \n","    \n","{'correct': 64.18000000000063, 'confusion': 0.9509999999999081, 'total': 302.619999999999, 'missed detection': 237.4889999999984, 'false alarm': 11.308999999999976, 'diarization error rate': 0.8252891414975848}\n","all_audio/5003lv05.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5003lv05.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (0.93) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:53:51 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:53:51 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:53:51 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:53:51 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:53:52 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:53:52 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:53:52 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:52 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:53:52 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:53:53 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:53:53 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:53:54 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:53:54 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:53:54 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:53:54 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:53:54 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:53:54 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:53:54 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:54 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:53:54 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:53:54 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:53:54 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:53:54 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:54 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:53:54 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:54 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 04:53:54 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:53:54 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:53:54 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 04:53:54 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 12/12 [00:02<00:00,  4.93it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:53:56 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:01 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:54:01 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:02 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:54:02 collections:446] Dataset loaded with 182 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 04:54:02 collections:448] # 182 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[1/5] extract embeddings: 100%|██████████| 3/3 [00:00<00:00,  4.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:02 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:54:02 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:54:02 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:54:02 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:54:02 collections:446] Dataset loaded with 217 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:54:02 collections:448] # 217 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.30it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:03 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:54:03 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:54:03 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:54:03 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:54:03 collections:446] Dataset loaded with 255 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:54:03 collections:448] # 255 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.90it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:04 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:54:04 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:54:04 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:54:04 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:54:04 collections:446] Dataset loaded with 342 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:54:04 collections:448] # 342 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.72it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:05 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:54:05 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:54:05 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:54:05 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:54:05 collections:446] Dataset loaded with 522 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 04:54:05 collections:448] # 522 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  5.82it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:07 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:07 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:54:07 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:07 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:54:07 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:54:07 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:54:07 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:54:07 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:54:07 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:54:07 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:54:07 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 38.62it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:07 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:54:07 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:54:07 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:54:07 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:07 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:54:07 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:07 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:54:07 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:07 msdd_models:1431]   \n","    \n","{'correct': 135.85299999999975, 'confusion': 2.5469999999999473, 'total': 509.3449999999989, 'missed detection': 370.94499999999914, 'false alarm': 2.339999999999918, 'diarization error rate': 0.7378731508113359}\n","all_audio/5011lv01.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5011lv01.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: fr (0.83) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:54:50 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:54:50 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:54:50 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:54:50 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:54:51 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:54:51 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:54:51 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:51 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:54:51 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:54:52 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:54:52 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:54:53 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:54:53 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:54:53 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:54:53 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:54:53 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:54:53 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:54:53 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:53 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:54:53 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:54:53 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:54:53 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:54:53 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:53 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:54:53 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 22.09it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:53 vad_utils:107] The prepared manifest file exists. Overwriting!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:53 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:54:53 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:54:53 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 04:54:53 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 12/12 [00:02<00:00,  4.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:54:56 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:00 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:01 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:55:01 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:55:01 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:55:01 collections:446] Dataset loaded with 327 items, total duration of  0.09 hours.\n","[NeMo I 2024-05-30 04:55:01 collections:448] # 327 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  4.76it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:02 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:55:02 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:55:02 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:55:02 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:55:02 collections:446] Dataset loaded with 387 items, total duration of  0.10 hours.\n","[NeMo I 2024-05-30 04:55:02 collections:448] # 387 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  5.64it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:03 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:55:03 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:55:03 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:55:03 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:55:03 collections:446] Dataset loaded with 460 items, total duration of  0.10 hours.\n","[NeMo I 2024-05-30 04:55:03 collections:448] # 460 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 8/8 [00:01<00:00,  5.45it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:05 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:55:05 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:55:05 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:55:05 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:55:05 collections:446] Dataset loaded with 611 items, total duration of  0.11 hours.\n","[NeMo I 2024-05-30 04:55:05 collections:448] # 611 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 10/10 [00:01<00:00,  5.01it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:07 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:55:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:07 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:55:07 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:55:07 collections:446] Dataset loaded with 932 items, total duration of  0.12 hours.\n","[NeMo I 2024-05-30 04:55:07 collections:448] # 932 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[5/5] extract embeddings: 100%|██████████| 15/15 [00:02<00:00,  5.43it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:10 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  1.27it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:10 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:55:10 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:10 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:55:10 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:55:10 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:55:10 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:55:10 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:55:10 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:55:11 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:55:11 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 39.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:11 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:55:11 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:55:11 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:55:11 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:11 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:55:11 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:11 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:55:11 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:11 msdd_models:1431]   \n","    \n","{'correct': 249.58099999999956, 'confusion': 6.618999999999834, 'total': 524.679999999998, 'missed detection': 268.4799999999986, 'false alarm': 0.22000000000002728, 'diarization error rate': 0.5247369825417388}\n","all_audio/5002lv02.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5002lv02.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (1.00) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:55:43 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:55:43 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:55:43 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:55:43 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:55:44 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:55:44 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:55:44 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:44 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:55:44 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:55:45 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:55:45 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:55:45 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:55:45 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:55:45 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:55:45 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:55:45 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:55:45 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:55:45 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:45 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:55:45 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:55:45 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:55:45 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:55:45 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:45 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:55:45 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 21.92it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:46 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 04:55:46 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:55:46 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:55:46 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 04:55:46 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 12/12 [00:02<00:00,  4.89it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:48 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:53 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:53 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:55:53 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:55:53 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:55:53 collections:446] Dataset loaded with 255 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 04:55:53 collections:448] # 255 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.22it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:54 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:55:54 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:55:54 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:55:54 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:55:54 collections:446] Dataset loaded with 262 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 04:55:54 collections:448] # 262 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.04it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:55 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:55:55 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:55:55 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:55:55 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:55:55 collections:446] Dataset loaded with 282 items, total duration of  0.04 hours.\n","[NeMo I 2024-05-30 04:55:55 collections:448] # 282 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.01it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:56 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:55:56 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:55:56 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:55:56 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:55:56 collections:446] Dataset loaded with 311 items, total duration of  0.04 hours.\n","[NeMo I 2024-05-30 04:55:56 collections:448] # 311 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:57 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:55:57 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:55:57 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:55:57 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:55:57 collections:446] Dataset loaded with 408 items, total duration of  0.04 hours.\n","[NeMo I 2024-05-30 04:55:57 collections:448] # 408 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[5/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  5.61it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:59 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:59 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:55:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:59 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:55:59 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:55:59 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:55:59 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:55:59 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:55:59 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:55:59 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:55:59 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 65.19it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:59 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:55:59 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:55:59 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:55:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:59 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:55:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:59 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:55:59 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:55:59 msdd_models:1431]   \n","    \n","{'correct': 107.89500000000001, 'confusion': 1.7999999999999403, 'total': 565.8949999999991, 'missed detection': 456.19999999999914, 'false alarm': 0.42499999999999716, 'diarization error rate': 0.8100884439692873}\n","all_audio/5003lv01.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5003lv01.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (0.79) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:56:28 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:56:28 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:56:28 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:56:28 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:56:29 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:56:29 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:56:29 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:29 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:56:29 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:56:30 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:56:30 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:56:30 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:56:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:56:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:56:30 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:56:30 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:56:30 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:56:30 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:30 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:56:30 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:56:30 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:56:30 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:56:30 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:30 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:56:30 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 21.71it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:30 vad_utils:107] The prepared manifest file exists. Overwriting!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:30 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:56:30 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:56:30 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 04:56:30 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 12/12 [00:02<00:00,  5.00it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:33 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:38 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.65it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:38 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:56:38 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:56:38 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:56:38 collections:446] Dataset loaded with 215 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:56:38 collections:448] # 215 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.84it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:39 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:56:39 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:56:39 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:56:39 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:56:39 collections:446] Dataset loaded with 255 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 04:56:39 collections:448] # 255 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 4/4 [00:01<00:00,  3.84it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:40 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:56:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:56:40 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:56:40 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:56:40 collections:446] Dataset loaded with 309 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 04:56:40 collections:448] # 309 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.20it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:41 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:56:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:41 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:56:41 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:56:41 collections:446] Dataset loaded with 412 items, total duration of  0.08 hours.\n","[NeMo I 2024-05-30 04:56:41 collections:448] # 412 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[4/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  5.63it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:42 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:56:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:56:43 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:56:43 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:56:43 collections:446] Dataset loaded with 627 items, total duration of  0.08 hours.\n","[NeMo I 2024-05-30 04:56:43 collections:448] # 627 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 10/10 [00:01<00:00,  5.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:45 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.99it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:45 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:56:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:45 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:56:45 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:56:45 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:56:45 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:56:45 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:56:45 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:56:45 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:56:45 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 46.65it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:45 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:56:45 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:56:45 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:56:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:45 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:56:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:45 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:56:45 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:56:45 msdd_models:1431]   \n","    \n","{'correct': 170.80000000000013, 'confusion': 0.2400000000000091, 'total': 500.1079999999996, 'missed detection': 329.0679999999995, 'false alarm': 0.0, 'diarization error rate': 0.6584737696657517}\n","all_audio/5003lv03.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5003lv03.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (0.97) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:57:16 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:57:16 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:57:16 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:57:16 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:57:17 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:57:17 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:57:17 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:17 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:57:17 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:57:18 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:57:18 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:57:18 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:57:18 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:57:18 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:57:18 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:57:18 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:57:18 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:57:18 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:18 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:57:18 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:57:18 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:57:18 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:57:18 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:18 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:57:18 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 21.43it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:18 vad_utils:107] The prepared manifest file exists. Overwriting!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:19 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:57:19 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:57:19 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 04:57:19 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 12/12 [00:02<00:00,  4.88it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:21 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:26 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:26 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:57:26 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:57:26 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:57:26 collections:446] Dataset loaded with 199 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:57:26 collections:448] # 199 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.51it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:27 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:57:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:57:27 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:57:27 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:57:27 collections:446] Dataset loaded with 236 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:57:27 collections:448] # 236 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.01it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:28 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:57:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:57:28 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:28 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:57:28 collections:446] Dataset loaded with 283 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:57:28 collections:448] # 283 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.33it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:29 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:57:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:57:29 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:57:29 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:57:29 collections:446] Dataset loaded with 368 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 04:57:29 collections:448] # 368 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.37it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:30 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:57:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:57:30 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:57:30 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:57:30 collections:446] Dataset loaded with 567 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 04:57:30 collections:448] # 567 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  5.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:32 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:32 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:57:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:32 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:57:32 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:57:32 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:57:32 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:57:32 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:57:32 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:57:32 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:57:32 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 59.23it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:32 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:57:32 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:57:32 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:57:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:32 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:57:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:32 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:57:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:57:32 msdd_models:1431]   \n","    \n","{'correct': 152.69299999999978, 'confusion': 2.147000000000027, 'total': 566.9709999999985, 'missed detection': 412.1309999999987, 'false alarm': 0.0, 'diarization error rate': 0.7306864019500113}\n","all_audio/5008lv04.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5008lv04.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: it (0.93) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:58:16 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:58:16 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:58:16 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:58:16 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:58:17 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:58:17 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:58:17 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:17 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:58:17 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:58:18 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:58:18 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:58:18 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:58:18 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:58:18 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:58:18 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:58:18 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:58:18 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:58:18 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:18 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:58:18 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:58:18 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:58:18 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:58:18 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:18 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:58:18 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 20.22it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:18 vad_utils:107] The prepared manifest file exists. Overwriting!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:18 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:58:18 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:58:18 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 04:58:18 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 12/12 [00:02<00:00,  4.89it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:21 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:26 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:26 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:58:26 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:58:26 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:58:26 collections:446] Dataset loaded with 237 items, total duration of  0.04 hours.\n","[NeMo I 2024-05-30 04:58:26 collections:448] # 237 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.50it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:27 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:58:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:58:27 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:27 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:58:27 collections:446] Dataset loaded with 258 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 04:58:27 collections:448] # 258 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[2/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.72it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:28 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:58:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:58:28 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:58:28 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:58:28 collections:446] Dataset loaded with 290 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 04:58:28 collections:448] # 290 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.39it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:29 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:58:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:58:29 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:58:29 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:58:29 collections:446] Dataset loaded with 355 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 04:58:29 collections:448] # 355 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.91it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:30 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:58:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:58:30 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:58:30 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:58:30 collections:446] Dataset loaded with 506 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 04:58:30 collections:448] # 506 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 8/8 [00:01<00:00,  5.48it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:32 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:32 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:58:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:32 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:58:32 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:58:32 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:58:32 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:58:32 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:58:32 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:58:32 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:58:32 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 53.62it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:32 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:58:32 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:58:32 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:58:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:32 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:58:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:32 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:58:32 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:58:32 msdd_models:1431]   \n","    \n","{'correct': 118.17799999999951, 'confusion': 15.877999999999915, 'total': 566.4959999999983, 'missed detection': 432.4399999999989, 'false alarm': 0.8540000000000418, 'diarization error rate': 0.7928952719877991}\n","all_audio/5011lv02.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5011lv02.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: fr (0.47) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 04:59:15 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 04:59:15 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:59:15 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 04:59:15 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:59:16 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 04:59:16 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 04:59:16 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:16 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:59:16 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:59:17 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 04:59:17 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:59:18 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 04:59:18 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:59:18 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 04:59:18 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:59:18 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:59:18 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 04:59:18 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:18 features:289] PADDING: 16\n","[NeMo I 2024-05-30 04:59:18 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 04:59:18 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 04:59:18 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:59:18 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:18 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:59:18 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 18.84it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:18 vad_utils:107] The prepared manifest file exists. Overwriting!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:18 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 04:59:18 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:59:18 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 04:59:18 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 12/12 [00:02<00:00,  4.99it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:20 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:25 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 04:59:25 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:59:25 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:59:25 collections:446] Dataset loaded with 378 items, total duration of  0.10 hours.\n","[NeMo I 2024-05-30 04:59:25 collections:448] # 378 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  4.29it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:27 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:59:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 04:59:27 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:59:27 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:59:27 collections:446] Dataset loaded with 433 items, total duration of  0.10 hours.\n","[NeMo I 2024-05-30 04:59:27 collections:448] # 433 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  4.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:28 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:59:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 04:59:28 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:59:28 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:59:28 collections:446] Dataset loaded with 507 items, total duration of  0.11 hours.\n","[NeMo I 2024-05-30 04:59:28 collections:448] # 507 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/5] extract embeddings: 100%|██████████| 8/8 [00:01<00:00,  4.70it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:30 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:59:30 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 04:59:30 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:59:30 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:59:30 collections:446] Dataset loaded with 657 items, total duration of  0.11 hours.\n","[NeMo I 2024-05-30 04:59:30 collections:448] # 657 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 11/11 [00:02<00:00,  5.16it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:32 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 04:59:32 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 04:59:32 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 04:59:32 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 04:59:32 collections:446] Dataset loaded with 977 items, total duration of  0.12 hours.\n","[NeMo I 2024-05-30 04:59:32 collections:448] # 977 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 16/16 [00:02<00:00,  5.65it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:35 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  1.22it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:36 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:59:36 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:36 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 04:59:36 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 04:59:36 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 04:59:36 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 04:59:36 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 04:59:36 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 04:59:36 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 04:59:36 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 26.79it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:36 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 04:59:36 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 04:59:36 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 04:59:36 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:36 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:59:36 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:36 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 04:59:36 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 04:59:36 msdd_models:1431]   \n","    \n","{'correct': 230.08499999999964, 'confusion': 31.994999999999635, 'total': 567.3679999999976, 'missed detection': 305.2879999999983, 'false alarm': 0.0, 'diarization error rate': 0.5944695506267527}\n","all_audio/5011lv04.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5011lv04.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: fr (0.95) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 05:00:22 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 05:00:22 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:00:22 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 05:00:22 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:00:23 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 05:00:23 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 05:00:23 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:23 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:00:23 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:00:24 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:00:24 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:00:24 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 05:00:24 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:00:24 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 05:00:24 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:00:24 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:00:24 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:00:24 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:24 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:00:24 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:00:24 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 05:00:24 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:00:24 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:24 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:00:24 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 22.10it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:25 vad_utils:107] The prepared manifest file exists. Overwriting!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:25 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 05:00:25 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:00:25 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 05:00:25 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 12/12 [00:02<00:00,  4.66it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:27 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:32 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:33 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 05:00:33 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:00:33 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:00:33 collections:446] Dataset loaded with 381 items, total duration of  0.09 hours.\n","[NeMo I 2024-05-30 05:00:33 collections:448] # 381 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  4.23it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:34 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:00:34 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 05:00:34 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:00:34 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:00:34 collections:446] Dataset loaded with 443 items, total duration of  0.10 hours.\n","[NeMo I 2024-05-30 05:00:34 collections:448] # 443 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  4.85it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:36 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:00:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 05:00:36 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:00:36 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:00:36 collections:446] Dataset loaded with 517 items, total duration of  0.11 hours.\n","[NeMo I 2024-05-30 05:00:36 collections:448] # 517 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  5.28it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:37 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:00:37 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 05:00:37 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:00:38 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:00:38 collections:446] Dataset loaded with 664 items, total duration of  0.11 hours.\n","[NeMo I 2024-05-30 05:00:38 collections:448] # 664 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 11/11 [00:02<00:00,  5.03it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:40 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:00:40 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 05:00:40 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:00:40 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:00:40 collections:446] Dataset loaded with 991 items, total duration of  0.12 hours.\n","[NeMo I 2024-05-30 05:00:40 collections:448] # 991 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 16/16 [00:02<00:00,  5.50it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:43 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  1.19it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:44 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:00:44 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:44 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 05:00:44 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 05:00:44 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 05:00:44 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 05:00:44 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 05:00:44 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 05:00:44 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 05:00:44 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 31.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:44 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 05:00:44 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:00:44 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:00:44 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:44 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:00:44 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:44 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:00:44 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:00:44 msdd_models:1431]   \n","    \n","{'correct': 246.49199999999954, 'confusion': 21.967999999999744, 'total': 560.7749999999978, 'missed detection': 292.3149999999985, 'false alarm': 1.2800000000000864, 'diarization error rate': 0.5627265837457083}\n","all_audio/5011lv03.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5011lv03.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: fr (0.98) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 05:01:30 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 05:01:30 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:01:30 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 05:01:30 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:01:32 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 05:01:32 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 05:01:32 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:32 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:01:32 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:01:32 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:01:32 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:01:33 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 05:01:33 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:01:33 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 05:01:33 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:01:33 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:01:33 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:01:33 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:33 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:01:33 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:01:33 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 05:01:33 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:01:33 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:33 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:01:33 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 21.35it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:33 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 05:01:33 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 05:01:33 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:01:33 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 05:01:33 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 12/12 [00:02<00:00,  4.85it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:36 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:40 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 05:01:41 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:01:41 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:01:41 collections:446] Dataset loaded with 398 items, total duration of  0.11 hours.\n","[NeMo I 2024-05-30 05:01:41 collections:448] # 398 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  4.66it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:42 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:01:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 05:01:42 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:01:42 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:01:42 collections:446] Dataset loaded with 461 items, total duration of  0.12 hours.\n","[NeMo I 2024-05-30 05:01:42 collections:448] # 461 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 8/8 [00:01<00:00,  5.27it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:44 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:01:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 05:01:44 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:01:44 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:01:44 collections:446] Dataset loaded with 556 items, total duration of  0.12 hours.\n","[NeMo I 2024-05-30 05:01:44 collections:448] # 556 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  4.90it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:46 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:01:46 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:46 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:01:46 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:01:46 collections:446] Dataset loaded with 726 items, total duration of  0.13 hours.\n","[NeMo I 2024-05-30 05:01:46 collections:448] # 726 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[4/5] extract embeddings: 100%|██████████| 12/12 [00:02<00:00,  5.46it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:48 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:01:48 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 05:01:48 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:01:48 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:01:48 collections:446] Dataset loaded with 1094 items, total duration of  0.14 hours.\n","[NeMo I 2024-05-30 05:01:48 collections:448] # 1094 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 18/18 [00:03<00:00,  5.65it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:52 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:52 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:01:52 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:52 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 05:01:52 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 05:01:52 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 05:01:52 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 05:01:52 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 05:01:52 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 05:01:52 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 05:01:52 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 19.92it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:52 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 05:01:52 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:01:52 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:01:52 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:52 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:01:52 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:52 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:01:53 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:01:53 msdd_models:1431]   \n","    \n","{'correct': 267.8929999999996, 'confusion': 18.726999999999684, 'total': 554.684999999997, 'missed detection': 268.06499999999767, 'false alarm': 8.779999999999973, 'diarization error rate': 0.532864598826359}\n","all_audio/5008lv03.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5008lv03.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: it (1.00) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 05:02:31 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 05:02:31 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:02:31 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 05:02:31 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:02:32 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 05:02:32 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 05:02:32 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:32 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:02:32 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:02:33 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:02:33 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:02:33 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 05:02:33 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:02:33 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 05:02:33 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:02:33 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:02:33 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:02:33 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:33 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:02:33 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:02:33 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 05:02:33 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:02:33 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:34 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:02:34 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 18.84it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:34 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 05:02:34 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 05:02:34 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:02:34 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 05:02:34 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 12/12 [00:02<00:00,  4.76it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:36 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:41 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 05:02:41 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:02:41 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:02:41 collections:446] Dataset loaded with 217 items, total duration of  0.04 hours.\n","[NeMo I 2024-05-30 05:02:41 collections:448] # 217 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.63it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:42 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:02:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 05:02:42 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:02:42 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:02:42 collections:446] Dataset loaded with 244 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 05:02:42 collections:448] # 244 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.86it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:43 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:02:43 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 05:02:43 clustering_diarizer:343] Extracting embeddings for Diarization\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:43 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:02:43 collections:446] Dataset loaded with 277 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 05:02:43 collections:448] # 277 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.41it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:44 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:02:44 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 05:02:44 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:02:44 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:02:44 collections:446] Dataset loaded with 342 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 05:02:44 collections:448] # 342 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.94it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:45 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:02:45 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 05:02:45 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:02:45 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:02:45 collections:446] Dataset loaded with 502 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 05:02:45 collections:448] # 502 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 8/8 [00:01<00:00,  5.61it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:47 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:47 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:02:47 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:47 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 05:02:47 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 05:02:47 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 05:02:47 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 05:02:47 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 05:02:47 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 05:02:47 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 05:02:47 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 57.55it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:47 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 05:02:47 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:02:47 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:02:47 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:47 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:02:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:48 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:02:48 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:02:48 msdd_models:1431]   \n","    \n","{'correct': 129.8999999999997, 'confusion': 7.660000000000082, 'total': 567.5029999999982, 'missed detection': 429.94299999999845, 'false alarm': 0.0, 'diarization error rate': 0.7711025316165728}\n","all_audio/5008lv01.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5008lv01.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: es (0.49) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 05:03:24 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 05:03:24 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:03:24 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 05:03:24 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:03:25 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 05:03:25 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 05:03:25 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:25 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:03:26 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:03:26 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:03:26 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:03:27 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 05:03:27 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:03:27 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 05:03:27 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:03:27 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:03:27 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:03:27 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:27 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:03:27 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:03:27 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 05:03:27 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:03:27 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:27 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:03:27 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 19.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:27 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 05:03:27 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 05:03:27 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:03:27 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 05:03:27 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 12/12 [00:02<00:00,  4.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:30 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:34 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.61it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:35 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 05:03:35 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:03:35 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:03:35 collections:446] Dataset loaded with 220 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 05:03:35 collections:448] # 220 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.71it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:36 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:03:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 05:03:36 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:03:36 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:03:36 collections:446] Dataset loaded with 249 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 05:03:36 collections:448] # 249 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.40it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:37 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:03:37 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:37 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:03:37 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:03:37 collections:446] Dataset loaded with 292 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 05:03:37 collections:448] # 292 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.86it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:37 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:03:37 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 05:03:37 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:03:37 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:03:37 collections:446] Dataset loaded with 364 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 05:03:37 collections:448] # 364 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  6.06it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:38 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:03:38 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 05:03:38 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:03:39 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:03:39 collections:446] Dataset loaded with 538 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 05:03:39 collections:448] # 538 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 9/9 [00:01<00:00,  6.31it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:40 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:40 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:03:40 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:40 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 05:03:40 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 05:03:40 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 05:03:40 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 05:03:40 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 05:03:40 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 05:03:41 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 05:03:41 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 50.38it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:41 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 05:03:41 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:03:41 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:03:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:41 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:03:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:41 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:03:41 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:03:41 msdd_models:1431]   \n","    \n","{'correct': 144.51900000000012, 'confusion': 2.940999999999832, 'total': 567.0249999999995, 'missed detection': 419.56499999999954, 'false alarm': 0.0, 'diarization error rate': 0.7451276398747846}\n","all_audio/5002lv03.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5002lv03.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (0.99) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 05:04:15 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 05:04:15 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:04:15 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 05:04:15 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:04:16 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 05:04:16 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 05:04:16 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:16 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:04:16 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:04:16 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:04:16 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:04:17 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 05:04:17 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:04:17 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 05:04:17 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:04:17 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:04:17 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:04:17 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:17 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:04:17 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:04:17 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 05:04:17 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:04:17 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:17 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:04:17 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 19.93it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:17 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 05:04:17 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 05:04:17 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:04:17 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 05:04:17 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 12/12 [00:02<00:00,  4.08it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:20 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:25 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:25 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 05:04:25 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:04:25 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:04:25 collections:446] Dataset loaded with 231 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 05:04:25 collections:448] # 231 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.98it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:26 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:04:26 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 05:04:26 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:04:26 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:04:26 collections:446] Dataset loaded with 240 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 05:04:26 collections:448] # 240 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.44it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:27 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:04:27 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 05:04:27 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:04:27 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:04:27 collections:446] Dataset loaded with 250 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 05:04:27 collections:448] # 250 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.22it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:28 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:04:28 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 05:04:28 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:04:28 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:04:28 collections:446] Dataset loaded with 281 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 05:04:28 collections:448] # 281 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.16it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:29 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:04:29 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 05:04:29 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:04:29 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:04:29 collections:446] Dataset loaded with 339 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 05:04:29 collections:448] # 339 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 6/6 [00:00<00:00,  6.31it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:30 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:30 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:04:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:30 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 05:04:30 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 05:04:30 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 05:04:30 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 05:04:30 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 05:04:30 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 05:04:30 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 05:04:30 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 64.66it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:30 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 05:04:30 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:04:30 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:04:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:30 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:04:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:30 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:04:30 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:04:30 msdd_models:1431]   \n","    \n","{'correct': 85.40200000000014, 'confusion': 3.6779999999999404, 'total': 561.8279999999984, 'missed detection': 472.7479999999983, 'false alarm': 0.0, 'diarization error rate': 0.847992624077119}\n","all_audio/5002lv05.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5002lv05.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: de (1.00) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 05:05:04 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 05:05:04 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:05:04 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 05:05:04 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:05:05 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 05:05:05 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 05:05:05 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:05 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:05:05 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:05:06 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:05:06 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:05:07 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 05:05:07 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:05:07 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 05:05:07 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:05:07 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:05:07 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:05:07 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:07 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:05:07 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:05:07 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 05:05:07 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:05:07 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:07 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:05:07 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 20.97it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:07 vad_utils:107] The prepared manifest file exists. Overwriting!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:07 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 05:05:07 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:05:07 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 05:05:07 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 12/12 [00:02<00:00,  4.83it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:09 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:14 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:15 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 05:05:15 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:05:15 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:05:15 collections:446] Dataset loaded with 205 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 05:05:15 collections:448] # 205 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.31it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:16 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:05:16 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 05:05:16 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:05:16 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:05:16 collections:446] Dataset loaded with 212 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 05:05:16 collections:448] # 212 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.75it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:16 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:05:16 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 05:05:16 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:05:16 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:05:16 collections:446] Dataset loaded with 228 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 05:05:16 collections:448] # 228 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  5.59it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:17 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:05:17 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 05:05:17 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:05:17 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:05:17 collections:446] Dataset loaded with 261 items, total duration of  0.03 hours.\n","[NeMo I 2024-05-30 05:05:17 collections:448] # 261 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  6.52it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:18 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:05:18 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 05:05:18 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:05:18 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:05:18 collections:446] Dataset loaded with 350 items, total duration of  0.04 hours.\n","[NeMo I 2024-05-30 05:05:18 collections:448] # 350 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.78it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:19 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.21it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:19 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:05:19 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:19 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 05:05:19 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 05:05:19 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 05:05:19 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 05:05:19 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 05:05:19 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 05:05:20 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 05:05:20 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 58.85it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:20 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 05:05:20 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:05:20 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:05:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:20 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:05:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:20 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:05:20 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:20 msdd_models:1431]   \n","    \n","{'correct': 89.3970000000001, 'confusion': 3.5829999999997284, 'total': 567.4379999999983, 'missed detection': 474.4579999999984, 'false alarm': 0.0, 'diarization error rate': 0.8424550347350717}\n","all_audio/5008lv05.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5008lv05.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: it (0.90) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 05:05:55 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 05:05:55 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:05:55 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 05:05:55 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:05:56 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 05:05:56 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 05:05:56 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:56 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:05:56 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:05:57 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:05:57 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:05:57 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 05:05:57 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:05:57 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 05:05:57 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:05:57 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:05:57 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:05:57 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:57 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:05:57 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:05:57 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 05:05:57 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:05:57 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:57 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:05:57 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 17.80it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:05:57 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 05:05:58 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 05:05:58 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:05:58 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 05:05:58 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 12/12 [00:02<00:00,  4.47it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:00 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:05 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:05 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 05:06:05 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:06:05 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:06:05 collections:446] Dataset loaded with 270 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 05:06:05 collections:448] # 270 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.05it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:06 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:06:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 05:06:06 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:06:06 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:06:06 collections:446] Dataset loaded with 304 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 05:06:06 collections:448] # 304 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.30it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:07 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:06:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:07 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:06:07 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:06:07 collections:446] Dataset loaded with 360 items, total duration of  0.08 hours.\n","[NeMo I 2024-05-30 05:06:07 collections:448] # 360 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[3/5] extract embeddings: 100%|██████████| 6/6 [00:01<00:00,  5.46it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:08 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:06:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 05:06:08 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:06:08 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:06:08 collections:446] Dataset loaded with 459 items, total duration of  0.08 hours.\n","[NeMo I 2024-05-30 05:06:08 collections:448] # 459 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 8/8 [00:01<00:00,  5.91it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:10 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:06:10 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 05:06:10 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:06:10 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:06:10 collections:446] Dataset loaded with 698 items, total duration of  0.09 hours.\n","[NeMo I 2024-05-30 05:06:10 collections:448] # 698 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 11/11 [00:02<00:00,  5.28it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:12 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00,  1.73it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:12 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:06:12 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:12 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 05:06:12 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 05:06:12 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 05:06:12 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 05:06:12 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 05:06:12 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 05:06:13 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 05:06:13 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 53.33it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:13 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 05:06:13 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:06:13 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:06:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:13 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:06:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:13 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:06:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:13 msdd_models:1431]   \n","    \n","{'correct': 164.33299999999963, 'confusion': 26.226999999999663, 'total': 567.4249999999982, 'missed detection': 376.86499999999893, 'false alarm': 0.0, 'diarization error rate': 0.7103881570251572}\n","all_audio/5008lv02.wav\n","RTTM file  all_annotations/rttm_dir_fixed/5008lv02.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: it (0.99) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 05:06:56 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 05:06:56 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:06:56 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 05:06:56 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:06:57 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 05:06:57 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 05:06:57 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:57 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:06:57 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:06:57 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:06:57 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:06:58 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 05:06:58 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:06:58 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 05:06:58 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:06:58 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:06:58 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:06:58 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:58 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:06:58 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:06:58 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 05:06:58 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:06:58 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:58 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:06:58 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 19.76it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:06:58 vad_utils:107] The prepared manifest file exists. Overwriting!\n","[NeMo I 2024-05-30 05:06:58 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 05:06:58 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:06:58 collections:446] Dataset loaded with 12 items, total duration of  0.16 hours.\n","[NeMo I 2024-05-30 05:06:58 collections:448] # 12 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 12/12 [00:02<00:00,  4.83it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:01 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:05 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.68it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:06 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 05:07:06 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:07:06 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:07:06 collections:446] Dataset loaded with 251 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 05:07:06 collections:448] # 251 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.34it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:07 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:07:07 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 05:07:07 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:07:07 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:07:07 collections:446] Dataset loaded with 279 items, total duration of  0.05 hours.\n","[NeMo I 2024-05-30 05:07:07 collections:448] # 279 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.83it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:08 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:07:08 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 05:07:08 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:07:08 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:07:08 collections:446] Dataset loaded with 319 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 05:07:08 collections:448] # 319 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 5/5 [00:00<00:00,  5.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:09 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:07:09 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 05:07:09 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:07:09 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:07:09 collections:446] Dataset loaded with 403 items, total duration of  0.06 hours.\n","[NeMo I 2024-05-30 05:07:09 collections:448] # 403 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["[4/5] extract embeddings: 100%|██████████| 7/7 [00:01<00:00,  5.87it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:10 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:07:10 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 05:07:10 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:07:10 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:07:10 collections:446] Dataset loaded with 584 items, total duration of  0.07 hours.\n","[NeMo I 2024-05-30 05:07:10 collections:448] # 584 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 10/10 [00:01<00:00,  5.70it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:12 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.11it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:12 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:07:12 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:12 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 05:07:12 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 05:07:12 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 05:07:12 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 05:07:12 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 05:07:12 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 05:07:12 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 05:07:12 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 52.90it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:12 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 05:07:12 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:07:12 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:07:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:13 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:07:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:13 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:07:13 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:13 msdd_models:1431]   \n","    \n","{'correct': 149.67499999999944, 'confusion': 10.644999999999861, 'total': 557.4939999999986, 'missed detection': 397.1739999999992, 'false alarm': 0.0, 'diarization error rate': 0.731521774225373}\n","all_audio/4012nl406.wav\n","RTTM file  all_annotations/rttm_dir_fixed/4012nl406.rttm\n","filepath\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n","INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../../../../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Detected language: nl (0.94) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n","[NeMo I 2024-05-30 05:07:27 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 05:07:27 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:07:27 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 05:07:27 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:07:28 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 05:07:28 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 05:07:28 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:28 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:07:28 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:07:29 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 05:07:29 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:07:29 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 05:07:29 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:07:29 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 05:07:29 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:07:29 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:07:29 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 05:07:29 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:29 features:289] PADDING: 16\n","[NeMo I 2024-05-30 05:07:29 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 05:07:29 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 05:07:29 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:07:29 clustering_diarizer:411] Deleting previous clustering diarizer outputs.\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:29 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:07:29 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 25.98it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:29 vad_utils:107] The prepared manifest file exists. Overwriting!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:30 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 05:07:30 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:07:30 collections:446] Dataset loaded with 10 items, total duration of  0.13 hours.\n","[NeMo I 2024-05-30 05:07:30 collections:448] # 10 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["vad: 100%|██████████| 10/10 [00:02<00:00,  4.92it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:32 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                               "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:36 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00,  2.55it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 05:07:36 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:07:36 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:07:36 collections:446] Dataset loaded with 2 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 05:07:36 collections:448] # 2 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 21.27it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:36 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:07:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 05:07:36 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:07:36 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:07:36 collections:446] Dataset loaded with 2 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 05:07:36 collections:448] # 2 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 53.90it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:36 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:07:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 05:07:36 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:07:36 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:07:36 collections:446] Dataset loaded with 2 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 05:07:36 collections:448] # 2 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 56.89it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:36 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:07:36 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 05:07:36 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:07:36 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:07:36 collections:446] Dataset loaded with 3 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 05:07:36 collections:448] # 3 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 20.79it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:37 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 05:07:37 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 05:07:37 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 05:07:37 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 05:07:37 collections:446] Dataset loaded with 4 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 05:07:37 collections:448] # 4 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 39.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:37 clustering_diarizer:389] Saved embedding files to /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["clustering: 100%|██████████| 1/1 [00:00<00:00, 11.44it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:37 clustering_diarizer:464] Outputs are saved in /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:07:37 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:37 msdd_models:960] Loading embedding pickle file of scale:0 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 05:07:37 msdd_models:960] Loading embedding pickle file of scale:1 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 05:07:37 msdd_models:960] Loading embedding pickle file of scale:2 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 05:07:37 msdd_models:960] Loading embedding pickle file of scale:3 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 05:07:37 msdd_models:960] Loading embedding pickle file of scale:4 at /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 05:07:37 msdd_models:938] Loading cluster label file from /content/drive/Shareddrives/CS224S/CS224S_Final_Project/data/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 05:07:37 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 05:07:37 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 74.66it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:37 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 05:07:37 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 05:07:37 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 05:07:37 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:37 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:07:37 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:37 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 05:07:37 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 05:07:37 msdd_models:1431]   \n","    \n"]},{"ename":"KeyError","evalue":"'4012nl406'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-73-6e87e8d6a21e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RTTM file \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrttm_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filepath\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minference_on_one_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrttm_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mdiarization_error_rates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diarization error rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-fa5ac1853aea>\u001b[0m in \u001b[0;36minference_on_one_sample\u001b[0;34m(audio_path, rttm_path, label)\u001b[0m\n\u001b[1;32m    138\u001b[0m     )\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m   \u001b[0mreference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_rttm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrttm_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m   \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_rttm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pred_rttms/mono_file.rttm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mono_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: '4012nl406'"]}],"source":["for file in files[25:]:\n","  file_path = os.path.join(root, file)\n","  print(file_path)\n","  label = '<' + file_path.replace('.wav', '') + '>'\n","  rttm_file = 'all_annotations/rttm_dir_fixed/' + file_path.replace('.wav', '.rttm').split('/')[-1]\n","  print(\"RTTM file \", rttm_file)\n","  print(\"filepath\")\n","  value = inference_on_one_sample(file_path, rttm_file, file_path.replace('.wav', '').split('/')[-1])\n","  values.append(value)\n","  diarization_error_rates.append(value['diarization error rate'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1717044490768,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"S_yRs4nUz9sg","outputId":"15154b2e-8629-4802-eac5-7eb848e55e5b"},"outputs":[{"name":"stdout","output_type":"stream","text":["23\n"]}],"source":["print(len(values))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":173,"status":"ok","timestamp":1717044422565,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"WmHO10Cv0KXT","outputId":"459c7033-49a4-4ea9-958e-db86c18e94e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Most recent values:  [{'correct': 125.85799999999956, 'confusion': 0.410000000000025, 'total': 566.0479999999993, 'missed detection': 439.77999999999975, 'false alarm': 0.022000000000048203, 'diarization error rate': 0.7776937644864046}, {'correct': 53.53999999999982, 'confusion': 0.5799999999999557, 'total': 568.0049999999983, 'missed detection': 513.8849999999985, 'false alarm': 0.0, 'diarization error rate': 0.9057402663708946}, {'correct': 65.28399999999971, 'confusion': 1.0959999999999894, 'total': 319.8729999999997, 'missed detection': 253.493, 'false alarm': 0.22000000000002728, 'diarization error rate': 0.7965942733522375}, {'correct': 88.2699999999999, 'confusion': 2.3100000000000733, 'total': 557.4859999999985, 'missed detection': 466.90599999999847, 'false alarm': 0.0, 'diarization error rate': 0.8416641852889576}, {'correct': 186.0399999999999, 'confusion': 0.8200000000000536, 'total': 555.9509999999985, 'missed detection': 369.0909999999986, 'false alarm': 0.15999999999996817, 'diarization error rate': 0.6656539874917027}, {'correct': 154.76199999999994, 'confusion': 15.552999999999816, 'total': 555.6119999999981, 'missed detection': 385.2969999999984, 'false alarm': 1.9249999999998977, 'diarization error rate': 0.7249213479910431}, {'correct': 69.8559999999996, 'confusion': 9.903999999999854, 'total': 554.2109999999979, 'missed detection': 474.45099999999843, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.8742067551889086}, {'correct': 52.081999999999724, 'confusion': 2.0779999999999035, 'total': 567.4049999999984, 'missed detection': 513.2449999999988, 'false alarm': 0.0, 'diarization error rate': 0.9082101849648841}, {'correct': 89.0290000000002, 'confusion': 0.8860000000000241, 'total': 567.8689999999989, 'missed detection': 477.95399999999864, 'false alarm': 0.0049999999999954525, 'diarization error rate': 0.8432314495068398}, {'correct': 29.58600000000003, 'confusion': 2.8740000000000805, 'total': 538.362999999999, 'missed detection': 505.9029999999989, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.945304562163447}, {'correct': 181.73699999999937, 'confusion': 1.5829999999999416, 'total': 562.1549999999984, 'missed detection': 378.8349999999991, 'false alarm': 0.0, 'diarization error rate': 0.676713717746885}, {'correct': 218.01799999999983, 'confusion': 1.6280000000000427, 'total': 567.9459999999989, 'missed detection': 348.299999999999, 'false alarm': 0.023999999999887223, 'diarization error rate': 0.6161712557179725}, {'correct': 113.2299999999999, 'confusion': 4.6499999999997925, 'total': 515.5189999999983, 'missed detection': 397.63899999999853, 'false alarm': 0.0, 'diarization error rate': 0.7803572710220179}, {'correct': 218.43899999999934, 'confusion': 2.1409999999998988, 'total': 564.6549999999982, 'missed detection': 344.0749999999989, 'false alarm': 1.9300000000000637, 'diarization error rate': 0.6165640966607929}, {'correct': 240.11499999999987, 'confusion': 7.234999999999822, 'total': 568.0929999999979, 'missed detection': 320.74299999999823, 'false alarm': 0.0, 'diarization error rate': 0.5773315284645283}, {'correct': 119.43699999999971, 'confusion': 3.0829999999998696, 'total': 339.1799999999992, 'missed detection': 216.65999999999966, 'false alarm': 0.0, 'diarization error rate': 0.647865440179256}, {'correct': 55.83999999999974, 'confusion': 1.0600000000000165, 'total': 567.3979999999988, 'missed detection': 510.4979999999989, 'false alarm': 0.0, 'diarization error rate': 0.901585835692054}, {'correct': 1.0600000000000067, 'confusion': 0.21999999999999886, 'total': 77.20299999999997, 'missed detection': 75.92299999999997, 'false alarm': 0.0, 'diarization error rate': 0.9862699636024507}, {'correct': 107.65100000000012, 'confusion': 6.848999999999847, 'total': 568.0629999999983, 'missed detection': 453.5629999999982, 'false alarm': 0.0, 'diarization error rate': 0.8104946106329747}, {'correct': 73.01699999999985, 'confusion': 12.483000000000088, 'total': 567.4609999999971, 'missed detection': 481.96099999999706, 'false alarm': 0.0, 'diarization error rate': 0.8713268400824016}, {'correct': 2.5599999999999987, 'confusion': 0.0, 'total': 96.22599999999991, 'missed detection': 93.66599999999993, 'false alarm': 0.0, 'diarization error rate': 0.9733959636688629}, {'correct': 73.01699999999985, 'confusion': 12.483000000000088, 'total': 567.4609999999971, 'missed detection': 481.96099999999706, 'false alarm': 0.0, 'diarization error rate': 0.8713268400824016}, {'correct': 2.5599999999999987, 'confusion': 0.0, 'total': 96.22599999999991, 'missed detection': 93.66599999999993, 'false alarm': 0.0, 'diarization error rate': 0.9733959636688629}]\n"]}],"source":["print(\"Most recent values: \", values)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":171,"status":"ok","timestamp":1717044441915,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"yKkegyph0ux3","outputId":"8531d22e-02f4-4ce4-df78-f5c07b25a7ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mean Diarization Error Across Dataset:  0.80808783060986\n"]}],"source":["print(\"Mean Diarization Error Across Dataset: \", np.mean([x['diarization error rate'] for x in values]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":199,"status":"ok","timestamp":1717043514151,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"N7oL084puvHT","outputId":"d93eb5b1-c825-4dc2-d48d-73c52d293a71"},"outputs":[{"name":"stdout","output_type":"stream","text":["14\n"]}],"source":["print(len(values))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":520,"status":"ok","timestamp":1717043517257,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"riVAkLSluy6e","outputId":"12d4881d-c950-43fd-ed31-c48834dea39a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[{'correct': 125.85799999999956, 'confusion': 0.410000000000025, 'total': 566.0479999999993, 'missed detection': 439.77999999999975, 'false alarm': 0.022000000000048203, 'diarization error rate': 0.7776937644864046}, {'correct': 53.53999999999982, 'confusion': 0.5799999999999557, 'total': 568.0049999999983, 'missed detection': 513.8849999999985, 'false alarm': 0.0, 'diarization error rate': 0.9057402663708946}, {'correct': 65.28399999999971, 'confusion': 1.0959999999999894, 'total': 319.8729999999997, 'missed detection': 253.493, 'false alarm': 0.22000000000002728, 'diarization error rate': 0.7965942733522375}, {'correct': 88.2699999999999, 'confusion': 2.3100000000000733, 'total': 557.4859999999985, 'missed detection': 466.90599999999847, 'false alarm': 0.0, 'diarization error rate': 0.8416641852889576}, {'correct': 186.0399999999999, 'confusion': 0.8200000000000536, 'total': 555.9509999999985, 'missed detection': 369.0909999999986, 'false alarm': 0.15999999999996817, 'diarization error rate': 0.6656539874917027}, {'correct': 154.76199999999994, 'confusion': 15.552999999999816, 'total': 555.6119999999981, 'missed detection': 385.2969999999984, 'false alarm': 1.9249999999998977, 'diarization error rate': 0.7249213479910431}, {'correct': 69.8559999999996, 'confusion': 9.903999999999854, 'total': 554.2109999999979, 'missed detection': 474.45099999999843, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.8742067551889086}, {'correct': 52.081999999999724, 'confusion': 2.0779999999999035, 'total': 567.4049999999984, 'missed detection': 513.2449999999988, 'false alarm': 0.0, 'diarization error rate': 0.9082101849648841}, {'correct': 89.0290000000002, 'confusion': 0.8860000000000241, 'total': 567.8689999999989, 'missed detection': 477.95399999999864, 'false alarm': 0.0049999999999954525, 'diarization error rate': 0.8432314495068398}, {'correct': 29.58600000000003, 'confusion': 2.8740000000000805, 'total': 538.362999999999, 'missed detection': 505.9029999999989, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.945304562163447}, {'correct': 181.73699999999937, 'confusion': 1.5829999999999416, 'total': 562.1549999999984, 'missed detection': 378.8349999999991, 'false alarm': 0.0, 'diarization error rate': 0.676713717746885}, {'correct': 218.01799999999983, 'confusion': 1.6280000000000427, 'total': 567.9459999999989, 'missed detection': 348.299999999999, 'false alarm': 0.023999999999887223, 'diarization error rate': 0.6161712557179725}, {'correct': 113.2299999999999, 'confusion': 4.6499999999997925, 'total': 515.5189999999983, 'missed detection': 397.63899999999853, 'false alarm': 0.0, 'diarization error rate': 0.7803572710220179}, {'correct': 218.43899999999934, 'confusion': 2.1409999999998988, 'total': 564.6549999999982, 'missed detection': 344.0749999999989, 'false alarm': 1.9300000000000637, 'diarization error rate': 0.6165640966607929}]\n"]}],"source":["print(values)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gjn0Fbovx2-g"},"outputs":[],"source":["values = [{'correct': 125.85799999999956, 'confusion': 0.410000000000025, 'total': 566.0479999999993, 'missed detection': 439.77999999999975, 'false alarm': 0.022000000000048203, 'diarization error rate': 0.7776937644864046}, {'correct': 53.53999999999982, 'confusion': 0.5799999999999557, 'total': 568.0049999999983, 'missed detection': 513.8849999999985, 'false alarm': 0.0, 'diarization error rate': 0.9057402663708946}, {'correct': 65.28399999999971, 'confusion': 1.0959999999999894, 'total': 319.8729999999997, 'missed detection': 253.493, 'false alarm': 0.22000000000002728, 'diarization error rate': 0.7965942733522375}, {'correct': 88.2699999999999, 'confusion': 2.3100000000000733, 'total': 557.4859999999985, 'missed detection': 466.90599999999847, 'false alarm': 0.0, 'diarization error rate': 0.8416641852889576}, {'correct': 186.0399999999999, 'confusion': 0.8200000000000536, 'total': 555.9509999999985, 'missed detection': 369.0909999999986, 'false alarm': 0.15999999999996817, 'diarization error rate': 0.6656539874917027}, {'correct': 154.76199999999994, 'confusion': 15.552999999999816, 'total': 555.6119999999981, 'missed detection': 385.2969999999984, 'false alarm': 1.9249999999998977, 'diarization error rate': 0.7249213479910431}, {'correct': 69.8559999999996, 'confusion': 9.903999999999854, 'total': 554.2109999999979, 'missed detection': 474.45099999999843, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.8742067551889086}, {'correct': 52.081999999999724, 'confusion': 2.0779999999999035, 'total': 567.4049999999984, 'missed detection': 513.2449999999988, 'false alarm': 0.0, 'diarization error rate': 0.9082101849648841}, {'correct': 89.0290000000002, 'confusion': 0.8860000000000241, 'total': 567.8689999999989, 'missed detection': 477.95399999999864, 'false alarm': 0.0049999999999954525, 'diarization error rate': 0.8432314495068398}, {'correct': 29.58600000000003, 'confusion': 2.8740000000000805, 'total': 538.362999999999, 'missed detection': 505.9029999999989, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.945304562163447}, {'correct': 181.73699999999937, 'confusion': 1.5829999999999416, 'total': 562.1549999999984, 'missed detection': 378.8349999999991, 'false alarm': 0.0, 'diarization error rate': 0.676713717746885}, {'correct': 218.01799999999983, 'confusion': 1.6280000000000427, 'total': 567.9459999999989, 'missed detection': 348.299999999999, 'false alarm': 0.023999999999887223, 'diarization error rate': 0.6161712557179725}, {'correct': 113.2299999999999, 'confusion': 4.6499999999997925, 'total': 515.5189999999983, 'missed detection': 397.63899999999853, 'false alarm': 0.0, 'diarization error rate': 0.7803572710220179}, {'correct': 218.43899999999934, 'confusion': 2.1409999999998988, 'total': 564.6549999999982, 'missed detection': 344.0749999999989, 'false alarm': 1.9300000000000637, 'diarization error rate': 0.6165640966607929}]\n"]},{"cell_type":"code","source":["values = [{'correct': 125.85799999999956, 'confusion': 0.410000000000025, 'total': 566.0479999999993, 'missed detection': 439.77999999999975, 'false alarm': 0.022000000000048203, 'diarization error rate': 0.7776937644864046}, {'correct': 53.53999999999982, 'confusion': 0.5799999999999557, 'total': 568.0049999999983, 'missed detection': 513.8849999999985, 'false alarm': 0.0, 'diarization error rate': 0.9057402663708946}, {'correct': 65.28399999999971, 'confusion': 1.0959999999999894, 'total': 319.8729999999997, 'missed detection': 253.493, 'false alarm': 0.22000000000002728, 'diarization error rate': 0.7965942733522375}, {'correct': 88.2699999999999, 'confusion': 2.3100000000000733, 'total': 557.4859999999985, 'missed detection': 466.90599999999847, 'false alarm': 0.0, 'diarization error rate': 0.8416641852889576}, {'correct': 186.0399999999999, 'confusion': 0.8200000000000536, 'total': 555.9509999999985, 'missed detection': 369.0909999999986, 'false alarm': 0.15999999999996817, 'diarization error rate': 0.6656539874917027}, {'correct': 154.76199999999994, 'confusion': 15.552999999999816, 'total': 555.6119999999981, 'missed detection': 385.2969999999984, 'false alarm': 1.9249999999998977, 'diarization error rate': 0.7249213479910431}, {'correct': 69.8559999999996, 'confusion': 9.903999999999854, 'total': 554.2109999999979, 'missed detection': 474.45099999999843, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.8742067551889086}, {'correct': 52.081999999999724, 'confusion': 2.0779999999999035, 'total': 567.4049999999984, 'missed detection': 513.2449999999988, 'false alarm': 0.0, 'diarization error rate': 0.9082101849648841}, {'correct': 89.0290000000002, 'confusion': 0.8860000000000241, 'total': 567.8689999999989, 'missed detection': 477.95399999999864, 'false alarm': 0.0049999999999954525, 'diarization error rate': 0.8432314495068398}, {'correct': 29.58600000000003, 'confusion': 2.8740000000000805, 'total': 538.362999999999, 'missed detection': 505.9029999999989, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.945304562163447}, {'correct': 181.73699999999937, 'confusion': 1.5829999999999416, 'total': 562.1549999999984, 'missed detection': 378.8349999999991, 'false alarm': 0.0, 'diarization error rate': 0.676713717746885}, {'correct': 218.01799999999983, 'confusion': 1.6280000000000427, 'total': 567.9459999999989, 'missed detection': 348.299999999999, 'false alarm': 0.023999999999887223, 'diarization error rate': 0.6161712557179725}, {'correct': 113.2299999999999, 'confusion': 4.6499999999997925, 'total': 515.5189999999983, 'missed detection': 397.63899999999853, 'false alarm': 0.0, 'diarization error rate': 0.7803572710220179}, {'correct': 218.43899999999934, 'confusion': 2.1409999999998988, 'total': 564.6549999999982, 'missed detection': 344.0749999999989, 'false alarm': 1.9300000000000637, 'diarization error rate': 0.6165640966607929}, {'correct': 240.11499999999987, 'confusion': 7.234999999999822, 'total': 568.0929999999979, 'missed detection': 320.74299999999823, 'false alarm': 0.0, 'diarization error rate': 0.5773315284645283}, {'correct': 119.43699999999971, 'confusion': 3.0829999999998696, 'total': 339.1799999999992, 'missed detection': 216.65999999999966, 'false alarm': 0.0, 'diarization error rate': 0.647865440179256}, {'correct': 55.83999999999974, 'confusion': 1.0600000000000165, 'total': 567.3979999999988, 'missed detection': 510.4979999999989, 'false alarm': 0.0, 'diarization error rate': 0.901585835692054}, {'correct': 1.0600000000000067, 'confusion': 0.21999999999999886, 'total': 77.20299999999997, 'missed detection': 75.92299999999997, 'false alarm': 0.0, 'diarization error rate': 0.9862699636024507}, {'correct': 107.65100000000012, 'confusion': 6.848999999999847, 'total': 568.0629999999983, 'missed detection': 453.5629999999982, 'false alarm': 0.0, 'diarization error rate': 0.8104946106329747}, {'correct': 73.01699999999985, 'confusion': 12.483000000000088, 'total': 567.4609999999971, 'missed detection': 481.96099999999706, 'false alarm': 0.0, 'diarization error rate': 0.8713268400824016}, {'correct': 2.5599999999999987, 'confusion': 0.0, 'total': 96.22599999999991, 'missed detection': 93.66599999999993, 'false alarm': 0.0, 'diarization error rate': 0.9733959636688629}, {'correct': 73.01699999999985, 'confusion': 12.483000000000088, 'total': 567.4609999999971, 'missed detection': 481.96099999999706, 'false alarm': 0.0, 'diarization error rate': 0.8713268400824016}, {'correct': 2.5599999999999987, 'confusion': 0.0, 'total': 96.22599999999991, 'missed detection': 93.66599999999993, 'false alarm': 0.0, 'diarization error rate': 0.9733959636688629}, {'correct': 33.256999999999934, 'confusion': 2.6629999999999763, 'total': 192.1859999999999, 'missed detection': 156.26599999999996, 'false alarm': 3.8599999999999, 'diarization error rate': 0.8470388061565355}, {'correct': 85.66099999999963, 'confusion': 1.9790000000000134, 'total': 560.6979999999988, 'missed detection': 473.0579999999992, 'false alarm': 0.0, 'diarization error rate': 0.8472243525034872}, {'correct': 25.498000000000026, 'confusion': 5.6019999999999905, 'total': 166.8699999999999, 'missed detection': 135.76999999999987, 'false alarm': 1.259999999999991, 'diarization error rate': 0.854749205968718}, {'correct': 152.2369999999995, 'confusion': 10.84299999999985, 'total': 453.71399999999875, 'missed detection': 290.6339999999994, 'false alarm': 1.7799999999999727, 'diarization error rate': 0.6683880153576924}, {'correct': 137.74600000000024, 'confusion': 14.614000000000008, 'total': 551.2119999999992, 'missed detection': 398.851999999999, 'false alarm': 0.0, 'diarization error rate': 0.7501034084889292}, {'correct': 90.77599999999995, 'confusion': 1.9209999999999923, 'total': 556.4699999999982, 'missed detection': 463.7729999999983, 'false alarm': 1.8029999999999973, 'diarization error rate': 0.8401117760166762}, {'correct': 64.18000000000063, 'confusion': 0.9509999999999081, 'total': 302.619999999999, 'missed detection': 237.4889999999984, 'false alarm': 11.308999999999976, 'diarization error rate': 0.8252891414975848}, {'correct': 135.85299999999975, 'confusion': 2.5469999999999473, 'total': 509.3449999999989, 'missed detection': 370.94499999999914, 'false alarm': 2.339999999999918, 'diarization error rate': 0.7378731508113359}, {'correct': 249.58099999999956, 'confusion': 6.618999999999834, 'total': 524.679999999998, 'missed detection': 268.4799999999986, 'false alarm': 0.22000000000002728, 'diarization error rate': 0.5247369825417388}, {'correct': 107.89500000000001, 'confusion': 1.7999999999999403, 'total': 565.8949999999991, 'missed detection': 456.19999999999914, 'false alarm': 0.42499999999999716, 'diarization error rate': 0.8100884439692873}, {'correct': 170.80000000000013, 'confusion': 0.2400000000000091, 'total': 500.1079999999996, 'missed detection': 329.0679999999995, 'false alarm': 0.0, 'diarization error rate': 0.6584737696657517}, {'correct': 152.69299999999978, 'confusion': 2.147000000000027, 'total': 566.9709999999985, 'missed detection': 412.1309999999987, 'false alarm': 0.0, 'diarization error rate': 0.7306864019500113}, {'correct': 118.17799999999951, 'confusion': 15.877999999999915, 'total': 566.4959999999983, 'missed detection': 432.4399999999989, 'false alarm': 0.8540000000000418, 'diarization error rate': 0.7928952719877991}, {'correct': 230.08499999999964, 'confusion': 31.994999999999635, 'total': 567.3679999999976, 'missed detection': 305.2879999999983, 'false alarm': 0.0, 'diarization error rate': 0.5944695506267527}, {'correct': 246.49199999999954, 'confusion': 21.967999999999744, 'total': 560.7749999999978, 'missed detection': 292.3149999999985, 'false alarm': 1.2800000000000864, 'diarization error rate': 0.5627265837457083}, {'correct': 267.8929999999996, 'confusion': 18.726999999999684, 'total': 554.684999999997, 'missed detection': 268.06499999999767, 'false alarm': 8.779999999999973, 'diarization error rate': 0.532864598826359}, {'correct': 129.8999999999997, 'confusion': 7.660000000000082, 'total': 567.5029999999982, 'missed detection': 429.94299999999845, 'false alarm': 0.0, 'diarization error rate': 0.7711025316165728}, {'correct': 144.51900000000012, 'confusion': 2.940999999999832, 'total': 567.0249999999995, 'missed detection': 419.56499999999954, 'false alarm': 0.0, 'diarization error rate': 0.7451276398747846}, {'correct': 85.40200000000014, 'confusion': 3.6779999999999404, 'total': 561.8279999999984, 'missed detection': 472.7479999999983, 'false alarm': 0.0, 'diarization error rate': 0.847992624077119}, {'correct': 89.3970000000001, 'confusion': 3.5829999999997284, 'total': 567.4379999999983, 'missed detection': 474.4579999999984, 'false alarm': 0.0, 'diarization error rate': 0.8424550347350717}, {'correct': 164.33299999999963, 'confusion': 26.226999999999663, 'total': 567.4249999999982, 'missed detection': 376.86499999999893, 'false alarm': 0.0, 'diarization error rate': 0.7103881570251572}, {'correct': 149.67499999999944, 'confusion': 10.644999999999861, 'total': 557.4939999999986, 'missed detection': 397.1739999999992, 'false alarm': 0.0, 'diarization error rate': 0.731521774225373}, {'correct': 149.67499999999944, 'confusion': 10.644999999999861, 'total': 557.4939999999986, 'missed detection': 397.1739999999992, 'false alarm': 0.0, 'diarization error rate': 0.731521774225373}, {'correct': 66.30499999999991, 'confusion': 10.015000000000029, 'total': 242.7569999999995, 'missed detection': 166.43699999999953, 'false alarm': 0.0, 'diarization error rate': 0.7268667844799528}, {'correct': 220.3669999999998, 'confusion': 15.312999999999901, 'total': 566.0709999999978, 'missed detection': 330.390999999998, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.6109551628682607}, {'correct': 150.3310000000001, 'confusion': 3.548999999999893, 'total': 567.4229999999981, 'missed detection': 413.542999999998, 'false alarm': 0.0, 'diarization error rate': 0.7350636121553045}, {'correct': 130.25599999999955, 'confusion': 18.643999999999995, 'total': 442.37499999999784, 'missed detection': 293.4749999999983, 'false alarm': 0.0, 'diarization error rate': 0.7055529810680979}, {'correct': 206.94999999999948, 'confusion': 3.289999999999951, 'total': 561.9449999999982, 'missed detection': 351.7049999999989, 'false alarm': 0.0, 'diarization error rate': 0.6317255247399657}, {'correct': 164.0189999999995, 'confusion': 35.593999999999724, 'total': 567.9529999999966, 'missed detection': 368.33999999999725, 'false alarm': 0.5170000000000528, 'diarization error rate': 0.7121205451859564}, {'correct': 212.424, 'confusion': 3.0259999999999785, 'total': 566.9349999999982, 'missed detection': 351.48499999999825, 'false alarm': 0.2699999999999818, 'diarization error rate': 0.6257877887235738}, {'correct': 207.3109999999997, 'confusion': 14.693999999999697, 'total': 554.7589999999968, 'missed detection': 332.7539999999975, 'false alarm': 1.4650000000000318, 'diarization error rate': 0.6289451816013787}, {'correct': 133.00199999999995, 'confusion': 15.49799999999991, 'total': 565.6389999999973, 'missed detection': 417.13899999999745, 'false alarm': 0.0, 'diarization error rate': 0.7648641624781874}, {'correct': 182.73599999999976, 'confusion': 12.999000000000152, 'total': 561.0409999999979, 'missed detection': 365.30599999999805, 'false alarm': 0.5450000000000017, 'diarization error rate': 0.6752625922169674}, {'correct': 130.98099999999965, 'confusion': 5.698999999999857, 'total': 567.9679999999988, 'missed detection': 431.2879999999994, 'false alarm': 0.0, 'diarization error rate': 0.7693866555862304}, {'correct': 180.0539999999993, 'confusion': 39.30599999999947, 'total': 568.0959999999968, 'missed detection': 348.73599999999806, 'false alarm': 0.0, 'diarization error rate': 0.6830570889427133}, {'correct': 175.78799999999953, 'confusion': 49.28199999999945, 'total': 568.0679999999975, 'missed detection': 342.99799999999846, 'false alarm': 5.464999999999918, 'diarization error rate': 0.7001714583465353}, {'correct': 212.81299999999948, 'confusion': 18.946999999999726, 'total': 564.8209999999967, 'missed detection': 333.0609999999976, 'false alarm': 2.80499999999995, 'diarization error rate': 0.6281866290382251}, {'correct': 181.15299999999917, 'confusion': 22.78699999999941, 'total': 567.5879999999969, 'missed detection': 363.6479999999983, 'false alarm': 0.0, 'diarization error rate': 0.6808371565290313}, {'correct': 177.19499999999982, 'confusion': 14.364999999999753, 'total': 564.994999999998, 'missed detection': 373.4349999999984, 'false alarm': 2.0449999999999875, 'diarization error rate': 0.6899972566128896}, {'correct': 197.30299999999966, 'confusion': 9.096999999999838, 'total': 562.4329999999977, 'missed detection': 356.03299999999825, 'false alarm': 0.0, 'diarization error rate': 0.6491973266149027}, {'correct': 199.60499999999985, 'confusion': 3.464999999999961, 'total': 567.8699999999985, 'missed detection': 364.79999999999876, 'false alarm': 0.10000000000002274, 'diarization error rate': 0.6486783947030125}, {'correct': 91.88499999999956, 'confusion': 22.014999999999844, 'total': 558.0909999999976, 'missed detection': 444.1909999999982, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.8356092465207288}, {'correct': 173.04599999999957, 'confusion': 3.933999999999884, 'total': 568.1079999999987, 'missed detection': 391.12799999999925, 'false alarm': 0.0, 'diarization error rate': 0.6953994662986616}, {'correct': 91.88499999999956, 'confusion': 22.014999999999844, 'total': 558.0909999999976, 'missed detection': 444.1909999999982, 'false alarm': 0.13999999999998636, 'diarization error rate': 0.8356092465207288}, {'correct': 173.04599999999957, 'confusion': 3.933999999999884, 'total': 568.1079999999987, 'missed detection': 391.12799999999925, 'false alarm': 0.0, 'diarization error rate': 0.6953994662986616}, {'correct': 103.87500000000037, 'confusion': 0.024999999999977263, 'total': 558.2259999999986, 'missed detection': 454.3259999999984, 'false alarm': 0.0, 'diarization error rate': 0.8139194519782301}, {'correct': 5.705, 'confusion': 0.29500000000000015, 'total': 113.97999999999993, 'missed detection': 107.97999999999993, 'false alarm': 0.0, 'diarization error rate': 0.9499473591858221}, {'correct': 63.8979999999999, 'confusion': 2.4619999999999607, 'total': 566.9299999999987, 'missed detection': 500.56999999999886, 'false alarm': 0.7100000000000364, 'diarization error rate': 0.8885435591695623}, {'correct': 77.49400000000004, 'confusion': 2.5660000000000407, 'total': 567.860999999999, 'missed detection': 487.8009999999989, 'false alarm': 0.0, 'diarization error rate': 0.8635335055585783}, {'correct': 104.89499999999936, 'confusion': 2.2749999999999417, 'total': 568.0729999999984, 'missed detection': 460.90299999999917, 'false alarm': 0.0, 'diarization error rate': 0.8153494357239306}, {'correct': 21.501999999999992, 'confusion': 0.49800000000000466, 'total': 565.4409999999999, 'missed detection': 543.4409999999999, 'false alarm': 0.0, 'diarization error rate': 0.9619730440488045}]\n"],"metadata":{"id":"P0kSIYD0yrhS","executionInfo":{"status":"ok","timestamp":1717520537970,"user_tz":420,"elapsed":278,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["print(len(values))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rs3SOguyytcp","executionInfo":{"status":"ok","timestamp":1717513677525,"user_tz":420,"elapsed":221,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"}},"outputId":"497b3a40-defb-4fc7-c7bc-03b1dfe9568d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["74\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":273,"status":"error","timestamp":1717520652885,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"RwRyftXwu0wE","outputId":"1dbcd66d-1d84-498e-f7ed-81369bca1c34"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'files' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-00e61edd360f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m74\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mrttm_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'all_annotations/rttm_dir/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.rttm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'files' is not defined"]}],"source":["for file in files[74:]:\n","  file_path = os.path.join(root, file)\n","  print(file_path)\n","  label = '<' + file_path.replace('.wav', '') + '>'\n","  rttm_file = 'all_annotations/rttm_dir/' + file_path.replace('.wav', '.rttm').split('/')[-1]\n","  print(\"RTTM file \", rttm_file)\n","\n","  value = inference_on_one_sample(file_path, rttm_file, '<' + file_path.replace('.wav', '' + '>').split('/')[-1])\n","  values.append(value)\n","  diarization_error_rates.append(value['diarization error rate'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162,"status":"ok","timestamp":1717042950046,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"_USX4HM9vCEH","outputId":"80ca6bdb-11d4-43f9-ec2b-2495c72c363a"},"outputs":[{"name":"stdout","output_type":"stream","text":["14\n"]}],"source":["print(len(values))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"elapsed":187,"status":"error","timestamp":1717038214501,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"rQlCiwrAAj9w","outputId":"48c571bb-a759-4699-f4a7-f041ea25c2b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["all_audio/1001lv01.wav\n"]},{"ename":"NameError","evalue":"name 'run_inference_on_one_example' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-bfffb2a77af1>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_inference_on_one_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.rttm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mdiarization_error_rates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diarization error rate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'run_inference_on_one_example' is not defined"]}],"source":["import os\n","\n","# Example usage\n","directory_to_crawl = 'all_audio/'\n","\n","# Try and get the mean Diarization Error Rate here\n","\n","values = []\n","diarization_error_rates = []\n","for root, _, files in os.walk(directory_to_crawl):\n","        for file in files:\n","            file_path = os.path.join(root, file)\n","            print(file_path)\n","            value = run_inference_on_one_example(file_path, file_path.replace('.wav', '.rttm'))\n","            values.append(value)\n","            diarization_error_rates.append(value['diarization error rate'])\n","\n","import numpy as np\n","\n","print(\"Mean Diarization Error Across Dataset: \", np.mean(diarization_error_rates))"]},{"cell_type":"markdown","metadata":{"id":"h-cY1ZEy2KVI"},"source":["# Processing"]},{"cell_type":"markdown","metadata":{"id":"7ZS4xXmE2NGP"},"source":["## Separating music from speech using Demucs\n","\n","---\n","\n","By isolating the vocals from the rest of the audio, it becomes easier to identify and track individual speakers based on the spectral and temporal characteristics of their speech signals. Source separation is just one of many techniques that can be used as a preprocessing step to help improve the accuracy and reliability of the overall diarization process."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1717029107999,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"HKcgQUrAzsJZ","outputId":"70b2d3c7-fe08-4108-a2c5-8d494e330f4a"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:root:Source splitting failed, using original audio file.\n"]}],"source":["if enable_stemming:\n","    # Isolate vocals from the rest of the audio\n","\n","    return_code = os.system(\n","        f'python3 -m demucs.separate -n htdemucs --two-stems=vocals \"{audio_path}\" -o \"temp_outputs\"'\n","    )\n","\n","    if return_code != 0:\n","        logging.warning(\"Source splitting failed, using original audio file.\")\n","        vocal_target = audio_path\n","    else:\n","        vocal_target = os.path.join(\n","            \"temp_outputs\",\n","            \"htdemucs\",\n","            os.path.splitext(os.path.basename(audio_path))[0],\n","            \"vocals.wav\",\n","        )\n","else:\n","    vocal_target = audio_path"]},{"cell_type":"markdown","metadata":{"id":"UYg9VWb22Tz8"},"source":["## Transcriping audio using Whisper and realligning timestamps using Wav2Vec2\n","---\n","This code uses two different open-source models to transcribe speech and perform forced alignment on the resulting transcription.\n","\n","The first model is called OpenAI Whisper, which is a speech recognition model that can transcribe speech with high accuracy. The code loads the whisper model and uses it to transcribe the vocal_target file.\n","\n","The output of the transcription process is a set of text segments with corresponding timestamps indicating when each segment was spoken.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PAzJIKE_fW79"},"outputs":[],"source":["import wget\n","\n","data_dir = '.'\n","\n","an4_audio_url = \"https://nemo-public.s3.us-east-2.amazonaws.com/an4_diarize_test.wav\"\n","an4_audio = wget.download(an4_audio_url, data_dir)\n","\n","an4_rttm_url = \"https://nemo-public.s3.us-east-2.amazonaws.com/an4_diarize_test.rttm\"\n","an4_rttm = wget.download(an4_rttm_url, data_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6855,"status":"ok","timestamp":1717029117921,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"5-VKFn530oTl","outputId":"7938db59-cf8d-4cda-b354-0d3fe53d00a8"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.7. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../root/.cache/torch/whisperx-vad-segmentation.bin`\n"]},{"name":"stdout","output_type":"stream","text":["No language specified, language will be first be detected for each audio file (increases inference time).\n","Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n","Model was trained with torch 1.10.0+cu102, yours is 2.3.0+cu121. Bad things might happen unless you revert torch to 1.x.\n","Warning: audio is shorter than 30s, language detection may be inaccurate.\n","Detected language: en (0.99) in first 30s of audio...\n","Suppressing numeral and symbol tokens\n"]}],"source":["compute_type = \"float16\"\n","# or run on GPU with INT8\n","# compute_type = \"int8_float16\"\n","# or run on CPU with INT8\n","# compute_type = \"int8\"\n","\n","whisper_results, language, audio_waveform = transcribe_batched(\n","    vocal_target,\n","    language,\n","    batch_size,\n","    whisper_model_name,\n","    compute_type,\n","    suppress_numerals,\n","    device,\n",")"]},{"cell_type":"markdown","metadata":{"id":"HQxlKOcMTpNL"},"source":["## Aligning the transcription with the original audio using Wav2Vec2\n","---\n","The second model used is called wav2vec2, which is a large-scale neural network that is designed to learn representations of speech that are useful for a variety of speech processing tasks, including speech recognition and alignment.\n","\n","The code loads the wav2vec2 alignment model and uses it to align the transcription segments with the original audio signal contained in the vocal_target file. This process involves finding the exact timestamps in the audio signal where each segment was spoken and aligning the text accordingly.\n","\n","By combining the outputs of the two models, the code produces a fully aligned transcription of the speech contained in the vocal_target file. This aligned transcription can be useful for a variety of speech processing tasks, such as speaker diarization, sentiment analysis, and language identification.\n","\n","If there's no Wav2Vec2 model available for your language, word timestamps generated by whisper will be used instead."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLIZdrrvTpNL"},"outputs":[],"source":["alignment_model, alignment_tokenizer, alignment_dictionary = load_alignment_model(\n","    device,\n","    dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",")\n","\n","audio_waveform = (\n","    torch.from_numpy(audio_waveform)\n","    .to(alignment_model.dtype)\n","    .to(alignment_model.device)\n",")\n","\n","emissions, stride = generate_emissions(\n","    alignment_model, audio_waveform, batch_size=batch_size\n",")\n","\n","del alignment_model\n","torch.cuda.empty_cache()\n","\n","full_transcript = \"\".join(segment[\"text\"] for segment in whisper_results)\n","\n","tokens_starred, text_starred = preprocess_text(\n","    full_transcript,\n","    romanize=True,\n","    language=langs_to_iso[language],\n",")\n","\n","segments, blank_id = get_alignments(\n","    emissions,\n","    tokens_starred,\n","    alignment_dictionary,\n",")\n","\n","spans = get_spans(tokens_starred, segments, alignment_tokenizer.decode(blank_id))\n","\n","word_timestamps = postprocess_results(text_starred, spans, stride)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AoDJeE-JTpNM"},"outputs":[],"source":["ROOT = os.getcwd()\n","temp_path = os.path.join(ROOT, \"temp_outputs\")\n","os.makedirs(temp_path, exist_ok=True)\n","torchaudio.save(\n","    os.path.join(temp_path, \"mono_file.wav\"),\n","    audio_waveform.cpu().unsqueeze(0).float(),\n","    16000,\n","    channels_first=True,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309},"executionInfo":{"elapsed":1868,"status":"ok","timestamp":1717029144465,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"3UGnK1_ugBVp","outputId":"38f6bf59-5b3b-44e1-a00f-c1a1d39ffad5"},"outputs":[{"data":{"text/html":["\n","                <audio  controls=\"controls\" >\n","                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n","                    Your browser does not support the audio element.\n","                </audio>\n","              "],"text/plain":["<IPython.lib.display.Audio object>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 2000x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import IPython\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import librosa\n","\n","sr = 16000\n","signal, sr = librosa.load(an4_audio,sr=sr)\n","\n","fig,ax = plt.subplots(1,1)\n","fig.set_figwidth(20)\n","fig.set_figheight(2)\n","plt.plot(np.arange(len(signal)),signal,'gray')\n","fig.suptitle('Reference merged an4 audio', fontsize=16)\n","plt.xlabel('time (secs)', fontsize=18)\n","ax.margins(x=0)\n","plt.ylabel('signal strength', fontsize=16);\n","a,_ = plt.xticks();plt.xticks(a,a/sr);\n","\n","IPython.display.Audio(an4_audio)"]},{"cell_type":"markdown","metadata":{"id":"D1gkViCf2-CV"},"source":["## Speaker Diarization using NeMo MSDD Model\n","---\n","This code uses a model called Nvidia NeMo MSDD (Multi-scale Diarization Decoder) to perform speaker diarization on an audio signal. Speaker diarization is the process of separating an audio signal into different segments based on who is speaking at any given time."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5208,"status":"ok","timestamp":1717029153393,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"C7jIpBCH02RL","outputId":"7229c7a1-6d07-4c46-da70-3c5bf59c1428"},"outputs":[{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:38 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n","[NeMo I 2024-05-30 00:32:38 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 00:32:38 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n","[NeMo I 2024-05-30 00:32:38 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 00:32:39 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: true\n","    \n","[NeMo W 2024-05-30 00:32:39 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    \n","[NeMo W 2024-05-30 00:32:39 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    emb_dir: null\n","    sample_rate: 16000\n","    num_spks: 2\n","    soft_label_thres: 0.5\n","    labels: null\n","    batch_size: 15\n","    emb_batch_size: 0\n","    shuffle: false\n","    seq_eval_mode: false\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:39 features:289] PADDING: 16\n","[NeMo I 2024-05-30 00:32:39 features:289] PADDING: 16\n","[NeMo I 2024-05-30 00:32:40 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n","[NeMo I 2024-05-30 00:32:40 features:289] PADDING: 16\n","[NeMo I 2024-05-30 00:32:40 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n","[NeMo I 2024-05-30 00:32:40 cloud:58] Found existing object /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 00:32:40 cloud:64] Re-using file from: /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n","[NeMo I 2024-05-30 00:32:40 common:924] Instantiating model from pre-trained checkpoint\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 00:32:40 modelPT:165] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n","    Train config : \n","    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: true\n","    is_tarred: false\n","    tarred_audio_filepaths: null\n","    tarred_shard_strategy: scatter\n","    augmentor:\n","      shift:\n","        prob: 0.5\n","        min_shift_ms: -10.0\n","        max_shift_ms: 10.0\n","      white_noise:\n","        prob: 0.5\n","        min_level: -90\n","        max_level: -46\n","        norm: true\n","      noise:\n","        prob: 0.5\n","        manifest_path: /manifests/noise_0_1_musan_fs.json\n","        min_snr_db: 0\n","        max_snr_db: 30\n","        max_gain_db: 300.0\n","        norm: true\n","      gain:\n","        prob: 0.5\n","        min_gain_dbfs: -10.0\n","        max_gain_dbfs: 10.0\n","        norm: true\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 00:32:40 modelPT:172] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n","    Validation config : \n","    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 256\n","    shuffle: false\n","    val_loss_idx: 0\n","    num_workers: 16\n","    pin_memory: true\n","    \n","[NeMo W 2024-05-30 00:32:40 modelPT:178] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n","    Test config : \n","    manifest_filepath: null\n","    sample_rate: 16000\n","    labels:\n","    - background\n","    - speech\n","    batch_size: 128\n","    shuffle: false\n","    test_loss_idx: 0\n","    \n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:40 features:289] PADDING: 16\n","[NeMo I 2024-05-30 00:32:41 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /root/.cache/torch/NeMo/NeMo_1.23.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n","[NeMo I 2024-05-30 00:32:41 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n","[NeMo I 2024-05-30 00:32:41 msdd_models:865] Clustering Parameters: {\n","        \"oracle_num_speakers\": false,\n","        \"max_num_speakers\": 8,\n","        \"enhanced_count_thres\": 80,\n","        \"max_rp_threshold\": 0.25,\n","        \"sparse_search_volume\": 30,\n","        \"maj_vote_spk_count\": false,\n","        \"chunk_cluster_count\": 50,\n","        \"embeddings_per_chunk\": 10000\n","    }\n","[NeMo I 2024-05-30 00:32:41 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 00:32:41 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n"]},{"name":"stderr","output_type":"stream","text":["splitting manifest: 100%|██████████| 1/1 [00:00<00:00, 648.77it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:41 classification_models:273] Perform streaming frame-level VAD\n","[NeMo I 2024-05-30 00:32:41 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 00:32:41 collections:446] Dataset loaded with 1 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 00:32:41 collections:448] # 1 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","vad: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:41 clustering_diarizer:250] Generating predictions with overlapping input segments\n"]},{"name":"stderr","output_type":"stream","text":["\n","                                                       "]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:41 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"]},{"name":"stderr","output_type":"stream","text":["creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 27.20it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /content/temp_outputs/speaker_outputs/subsegments_scale0.json\n","[NeMo I 2024-05-30 00:32:41 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 00:32:41 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 00:32:41 collections:446] Dataset loaded with 5 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 00:32:41 collections:448] # 5 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 10.71it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:41 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 00:32:41 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /content/temp_outputs/speaker_outputs/subsegments_scale1.json\n","[NeMo I 2024-05-30 00:32:41 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 00:32:42 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 00:32:42 collections:446] Dataset loaded with 7 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 00:32:42 collections:448] # 7 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 22.20it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 00:32:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /content/temp_outputs/speaker_outputs/subsegments_scale2.json\n","[NeMo I 2024-05-30 00:32:42 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 00:32:42 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 00:32:42 collections:446] Dataset loaded with 8 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 00:32:42 collections:448] # 8 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 20.82it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 00:32:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /content/temp_outputs/speaker_outputs/subsegments_scale3.json\n","[NeMo I 2024-05-30 00:32:42 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 00:32:42 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 00:32:42 collections:446] Dataset loaded with 11 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 00:32:42 collections:448] # 11 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[4/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 16.86it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n","[NeMo I 2024-05-30 00:32:42 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /content/temp_outputs/speaker_outputs/subsegments_scale4.json\n","[NeMo I 2024-05-30 00:32:42 clustering_diarizer:343] Extracting embeddings for Diarization\n","[NeMo I 2024-05-30 00:32:42 collections:445] Filtered duration for loading collection is  0.00 hours.\n","[NeMo I 2024-05-30 00:32:42 collections:446] Dataset loaded with 17 items, total duration of  0.00 hours.\n","[NeMo I 2024-05-30 00:32:42 collections:448] # 17 files loaded accounting to # 1 labels\n"]},{"name":"stderr","output_type":"stream","text":["\n","[5/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00, 17.42it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:42 clustering_diarizer:389] Saved embedding files to /content/temp_outputs/speaker_outputs/embeddings\n"]},{"name":"stderr","output_type":"stream","text":["\n","clustering: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:42 clustering_diarizer:464] Outputs are saved in /content/temp_outputs directory\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 00:32:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:42 msdd_models:960] Loading embedding pickle file of scale:0 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n","[NeMo I 2024-05-30 00:32:42 msdd_models:960] Loading embedding pickle file of scale:1 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n","[NeMo I 2024-05-30 00:32:42 msdd_models:960] Loading embedding pickle file of scale:2 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n","[NeMo I 2024-05-30 00:32:42 msdd_models:960] Loading embedding pickle file of scale:3 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n","[NeMo I 2024-05-30 00:32:42 msdd_models:960] Loading embedding pickle file of scale:4 at /content/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n","[NeMo I 2024-05-30 00:32:42 msdd_models:938] Loading cluster label file from /content/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n","[NeMo I 2024-05-30 00:32:42 collections:761] Filtered duration for loading collection is 0.000000.\n","[NeMo I 2024-05-30 00:32:42 collections:764] Total 1 session files loaded accounting to # 1 audio clips\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:00<00:00, 24.71it/s]"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:42 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n","[NeMo I 2024-05-30 00:32:42 speaker_utils:93] Number of files to diarize: 1\n","[NeMo I 2024-05-30 00:32:42 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["\n","[NeMo W 2024-05-30 00:32:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:42 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 00:32:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:42 speaker_utils:93] Number of files to diarize: 1\n"]},{"name":"stderr","output_type":"stream","text":["[NeMo W 2024-05-30 00:32:42 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"]},{"name":"stdout","output_type":"stream","text":["[NeMo I 2024-05-30 00:32:42 msdd_models:1431]   \n","    \n"]}],"source":["# Initialize NeMo MSDD diarization model\n","msdd_model = NeuralDiarizer(cfg=create_config(temp_path)).to(\"cuda\")\n","msdd_model.diarize()\n","\n","#del msdd_model\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1717029275052,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"SecHomg06zc_","outputId":"5e24378f-497c-45a0-9636-713aca6fbcbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]}],"source":["from pyannote.metrics.diarization import DiarizationErrorRate\n","from pyannote.core import Annotation\n","\n","metric = DiarizationErrorRate()\n","reference = Annotation('an4_diarize_test.rttm')\n","hypothesis = Annotation('mono_file.rttm')\n","\n","value = metric(reference, hypothesis)\n","print(value)"]},{"cell_type":"markdown","metadata":{"id":"NmkZYaDAEOAg"},"source":["## Mapping Speakers to Sentences According to Timestamps"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":786,"status":"ok","timestamp":1717029183265,"user":{"displayName":"Nandita Naik","userId":"09297468728223070570"},"user_tz":420},"id":"E65LUGQe02zw","outputId":"4c5cdbf6-046c-4801-d5e7-4727ded3f079"},"outputs":[{"name":"stdout","output_type":"stream","text":["Lines:  ['SPEAKER mono_file 1   0.300   2.540 <NA> <NA> speaker_0 <NA> <NA>\\n', 'SPEAKER mono_file 1   3.180   1.970 <NA> <NA> speaker_1 <NA> <NA>\\n']\n"]}],"source":["# Reading timestamps <> Speaker Labels mapping\n","\n","speaker_ts = []\n","\n","with open(os.path.join(temp_path, \"pred_rttms\", \"mono_file.rttm\"), \"r\") as f:\n","    lines = f.readlines()\n","    print(\"Lines: \", lines)\n","    for line in lines:\n","        line_list = line.split(\" \")\n","        s = int(float(line_list[5]) * 1000)\n","        e = s + int(float(line_list[8]) * 1000)\n","        speaker_ts.append([s, e, int(line_list[11].split(\"_\")[-1])])\n","\n","wsm = get_words_speaker_mapping(word_timestamps, speaker_ts, \"start\")"]},{"cell_type":"markdown","metadata":{"id":"8Ruxc8S1EXtW"},"source":["## Realligning Speech segments using Punctuation\n","---\n","\n","This code provides a method for disambiguating speaker labels in cases where a sentence is split between two different speakers. It uses punctuation markings to determine the dominant speaker for each sentence in the transcription.\n","\n","```\n","Speaker A: It's got to come from somewhere else. Yeah, that one's also fun because you know the lows are\n","Speaker B: going to suck, right? So it's actually it hits you on both sides.\n","```\n","\n","For example, if a sentence is split between two speakers, the code takes the mode of speaker labels for each word in the sentence, and uses that speaker label for the whole sentence. This can help to improve the accuracy of speaker diarization, especially in cases where the Whisper model may not take fine utterances like \"hmm\" and \"yeah\" into account, but the Diarization Model (Nemo) may include them, leading to inconsistent results.\n","\n","The code also handles cases where one speaker is giving a monologue while other speakers are making occasional comments in the background. It ignores the comments and assigns the entire monologue to the speaker who is speaking the majority of the time. This provides a robust and reliable method for realigning speech segments to their respective speakers based on punctuation in the transcription."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pgfC5hA41BXu"},"outputs":[],"source":["if language in punct_model_langs:\n","    # restoring punctuation in the transcript to help realign the sentences\n","    punct_model = PunctuationModel(model=\"kredor/punctuate-all\")\n","\n","    words_list = list(map(lambda x: x[\"word\"], wsm))\n","\n","    labled_words = punct_model.predict(words_list,chunk_size=230)\n","\n","    ending_puncts = \".?!\"\n","    model_puncts = \".,;:!?\"\n","\n","    # We don't want to punctuate U.S.A. with a period. Right?\n","    is_acronym = lambda x: re.fullmatch(r\"\\b(?:[a-zA-Z]\\.){2,}\", x)\n","\n","    for word_dict, labeled_tuple in zip(wsm, labled_words):\n","        word = word_dict[\"word\"]\n","        if (\n","            word\n","            and labeled_tuple[1] in ending_puncts\n","            and (word[-1] not in model_puncts or is_acronym(word))\n","        ):\n","            word += labeled_tuple[1]\n","            if word.endswith(\"..\"):\n","                word = word.rstrip(\".\")\n","            word_dict[\"word\"] = word\n","\n","else:\n","    logging.warning(\n","        f\"Punctuation restoration is not available for {language} language. Using the original punctuation.\"\n","    )\n","\n","wsm = get_realigned_ws_mapping_with_punctuation(wsm)\n","ssm = get_sentences_speaker_mapping(wsm, speaker_ts)"]},{"cell_type":"markdown","metadata":{"id":"vF2QAtLOFvwZ"},"source":["## Cleanup and Exporing the results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nUfg6XbJ5tYS"},"outputs":[],"source":["# Take the number between the RTTM and this other thing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFTyKI6B1MI0"},"outputs":[],"source":["with open(f\"{os.path.splitext(audio_path)[0]}.txt\", \"w\", encoding=\"utf-8-sig\") as f:\n","    get_speaker_aware_transcript(ssm, f)\n","\n","with open(f\"{os.path.splitext(audio_path)[0]}.srt\", \"w\", encoding=\"utf-8-sig\") as srt:\n","    write_srt(ssm, srt)\n","\n","#cleanup(temp_path)"]},{"cell_type":"markdown","metadata":{"id":"c8AlzOQPVGl0"},"source":["## Measure DER using PyAnnote Library"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DQND8oDqXGbo"},"outputs":[],"source":["from pyannote.metrics.diarization import DiarizationErrorRate\n","from pyannote.core import Annotation\n","\n","metric = DiarizationErrorRate()\n","reference = Annotation()\n","hypothesis = Annotation()\n","\n","value = metric(reference, hypothesis)\n","print(value)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["eCmjcOc9yEtQ","jbsUt3SwyhjD"],"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"https://github.com/MahmoudAshraf97/whisper-diarization/blob/main/Whisper_Transcription_%2B_NeMo_Diarization.ipynb","timestamp":1717023502126}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}